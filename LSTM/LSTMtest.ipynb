{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbf55625",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T08:18:36.775125Z",
     "start_time": "2024-03-25T08:18:36.772152Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Hyperparameters"
   ],
   "id": "32cb4fb0fc89a294"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T08:18:39.074353Z",
     "start_time": "2024-03-25T08:18:39.071158Z"
    }
   },
   "outputs": [],
   "source": [
    "# hyper\n",
    "features = ['SOH','voltage_measured', 'current_measured',\n",
    "            'temperature_measured', 'time']\n",
    "batch_size = 1  # 1*len(every_file)\n",
    "input_size = len(features)\n",
    "hidden_size = 128\n",
    "num_layers = 1\n",
    "output_size = 1\n",
    "seq_len = 20   # 预测序列长度\n",
    "epoch = 1000   # 1*len(train_directory)\n",
    "learning_rate = 0.001  # upgrade to adaptive lr?\n",
    "\n",
    "save_path = 'seq{}_.pth'.format(str(seq_len))  # model path\n",
    "train_directory = '../datasets/train/'\n",
    "val_directory = '../datasets/val/'\n",
    "test_directory = '../datasets/alldataset/'"
   ],
   "id": "fb3d6aa9bb4d420b"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 1.Data preprocess"
   ],
   "id": "90cc4ff8117907b2"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1.1 Load Data from mat"
   ],
   "id": "1b6b48cb13c43874"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T08:18:40.918231Z",
     "start_time": "2024-03-25T08:18:40.910325Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(battery_path):\n",
    "    # mat = loadmat('../datasets/BatteryDataset/' + battery_id + '.mat') # MAT PATH ESSENTIAL origin\n",
    "    battery_id = battery_path[-9:-4]\n",
    "    mat = loadmat(battery_path) # MAT PATH ESSENTIAL\n",
    "\n",
    "    counter = 0\n",
    "    dataset = []\n",
    "    capacity_data = []\n",
    "    # print('Total data in dataset: ', len(mat[battery][0, 0]['cycle'][0])) #total cycle\n",
    "\n",
    "    for i in range(len(mat[battery_id][0, 0]['cycle'][0])):\n",
    "        row = mat[battery_id][0, 0]['cycle'][0, i]\n",
    "        if row['type'][0] == 'discharge':\n",
    "            ambient_temperature = row['ambient_temperature'][0][0]\n",
    "            date_time = datetime.datetime(int(row['time'][0][0]),\n",
    "                                          int(row['time'][0][1]),\n",
    "                                          int(row['time'][0][2]),\n",
    "                                          int(row['time'][0][3]),\n",
    "                                          int(row['time'][0][4])) + datetime.timedelta(seconds=int(row['time'][0][5]))\n",
    "            data = row['data']\n",
    "            capacity = data[0][0]['Capacity'][0][0]\n",
    "            for j in range(len(data[0][0]['Voltage_measured'][0])):\n",
    "                voltage_measured = data[0][0]['Voltage_measured'][0][j]\n",
    "                current_measured = data[0][0]['Current_measured'][0][j]\n",
    "                temperature_measured = data[0][0]['Temperature_measured'][0][j]\n",
    "                current_load = data[0][0]['Current_load'][0][j]\n",
    "                voltage_load = data[0][0]['Voltage_load'][0][j]\n",
    "                time = data[0][0]['Time'][0][j]\n",
    "                dataset.append([counter + 1, ambient_temperature, date_time, capacity,\n",
    "                                voltage_measured, current_measured,temperature_measured,\n",
    "                                current_load, voltage_load, time])\n",
    "\n",
    "            capacity_data.append([counter + 1, ambient_temperature, date_time, capacity,\n",
    "                                  voltage_measured, current_measured,temperature_measured,\n",
    "                                  current_load, voltage_load, time])\n",
    "            counter = counter + 1\n",
    "    # print(dataset[0])\n",
    "\n",
    "    return [pd.DataFrame(data=dataset,\n",
    "                         columns=['cycle', 'ambient_temperature', 'datetime','capacity',\n",
    "                                  'voltage_measured','current_measured', 'temperature_measured',\n",
    "                                  'current_load', 'voltage_load', 'time']),\n",
    "            pd.DataFrame(data=capacity_data,\n",
    "                         columns=['cycle', 'ambient_temperature', 'datetime','capacity',\n",
    "                                  'voltage_measured','current_measured', 'temperature_measured',\n",
    "                                  'current_load', 'voltage_load', 'time'])]\n",
    "\n",
    "\n",
    "# test_battery_id0 = 'B0050'\n",
    "# test_battery_id1 = 'B0052'\n",
    "# test_battery_id2 = 'B0055'\n",
    "# test_battery_id3 = 'B0056'\n",
    "# dataset0, capacity0 = load_data(test_directory+ test_battery_id0 + '.mat')\n",
    "# dataset1, capacity1 = load_data(test_directory+ test_battery_id1 + '.mat')\n",
    "# dataset2, capacity2 = load_data(test_directory+ test_battery_id2 + '.mat')\n",
    "# dataset3, capacity3 = load_data(test_directory+ test_battery_id3 + '.mat')\n",
    "# # capacity.to_csv('../datasets/BatteryCSV/{}.csv'.format(test_battery_id), index=False)\n",
    "# # pd.set_option('display.max_columns', 10)\n",
    "# # print(capacity.head(5))\n",
    "# # dataset.describe()\n",
    "#\n",
    "# # 创建一个包含两个子图的 Figure 对象\n",
    "# fig, axs = plt.subplots(2, 2, figsize=(8, 6))\n",
    "# sns.set_style(\"darkgrid\") # 黑色的背景，带有白色网格线\n",
    "# # 在第一个子图中绘制 Sin(x)\n",
    "# axs[0, 0].plot(capacity0['cycle'], capacity0['capacity'])\n",
    "# axs[0, 0].set_title('Discharge {}'.format(test_battery_id0))\n",
    "# axs[0, 0].set_xlabel('cycle')\n",
    "# axs[0, 0].set_xlabel('Capacity')\n",
    "# # 在第二个子图中绘制 Cos(x)\n",
    "# axs[0, 1].plot(capacity1['cycle'], capacity1['capacity'])\n",
    "# axs[0, 1].set_title('Discharge {}'.format(test_battery_id1))\n",
    "# axs[0, 1].set_xlabel('cycle')\n",
    "# axs[0, 1].set_xlabel('Capacity')\n",
    "#\n",
    "# # 在第三个子图中绘制 Cos(x)\n",
    "# axs[1, 0].plot(capacity2['cycle'], capacity2['capacity'])\n",
    "# axs[1, 0].set_title('Discharge {}'.format(test_battery_id2))\n",
    "# axs[1, 0].set_xlabel('cycle')\n",
    "# axs[1, 0].set_xlabel('Capacity')\n",
    "#\n",
    "# # 在第四个子图中绘制 Cos(x)\n",
    "# axs[1, 1].plot(capacity3['cycle'], capacity3['capacity'])\n",
    "# axs[1, 1].set_title('Discharge {}'.format(test_battery_id3))\n",
    "# axs[1, 1].set_xlabel('cycle')\n",
    "# axs[1, 1].set_xlabel('Capacity')\n",
    "#\n",
    "# # 调整布局\n",
    "# plt.tight_layout()\n",
    "# # 显示图像\n",
    "# plt.show()\n"
   ],
   "id": "d1d670f02bac3f38"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1.2 normlize data"
   ],
   "id": "23c57f2ca1b777a9"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T08:18:44.072016Z",
     "start_time": "2024-03-25T08:18:44.066159Z"
    }
   },
   "outputs": [],
   "source": [
    "def norm_data(battery_id):\n",
    "    dataset, capacity = load_data(battery_id)\n",
    "    if capacity['capacity'][0] > capacity['capacity'][1] :\n",
    "        C = capacity['capacity'][0]\n",
    "    else :\n",
    "        C = capacity['capacity'][1]\n",
    "    soh = []\n",
    "    for i in range(len(capacity)):\n",
    "        soh.append([capacity['capacity'][i] / C])\n",
    "    soh = pd.DataFrame(data=soh, columns=['SOH'])\n",
    "\n",
    "    # features for training\n",
    "    attribs=['capacity', 'voltage_measured', 'current_measured',\n",
    "             'temperature_measured', 'current_load', 'voltage_load', 'time']\n",
    "    train_dataset = capacity[attribs]\n",
    "    sc = MinMaxScaler(feature_range=(0,1)) # = (num-min)/(max-min)\n",
    "    train_dataset = sc.fit_transform(train_dataset) # issue：not based on Rated\n",
    "    # print(train_dataset.shape)\n",
    "    # print(soh.shape)\n",
    "    attribs_scaled = pd.DataFrame(data=train_dataset,columns=attribs)\n",
    "    return  pd.concat([capacity['cycle'], attribs_scaled, soh], axis=1)\n",
    "\n",
    "def data_loader(battery_id, seq_len, features):\n",
    "    dataset = norm_data(battery_id)\n",
    "    input_size = len(features)\n",
    "    data_set_train=dataset[features].values\n",
    "    x_train=[]\n",
    "    label=[]\n",
    "    batch = len(data_set_train)\n",
    "    #take the last 10t to predict 10t+1\n",
    "    for i in range (seq_len,batch):\n",
    "        x_train.append(data_set_train[i-seq_len:i,:])\n",
    "        label.append(data_set_train[i,0])\n",
    "\n",
    "    x_train = np.array(x_train)\n",
    "    x_train = np.reshape(x_train,(batch-seq_len,seq_len,input_size)) #(batch,seq_len,input_size)\n",
    "    x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "    label = torch.tensor(label, dtype=torch.float32).view(-1, 1) # (batch,seq_len)取最后一个输出\n",
    "    return x_train, label\n",
    "\n",
    "# # storge\n",
    "# features = ['SOH','voltage_measured', 'current_measured',\n",
    "#             'temperature_measured', 'current_load', 'voltage_load', 'time']\n",
    "# train_data,train_data_real = data_loader('B0005', 10 , features)\n",
    "# train_data,train_data_real\n",
    "# dataset_scaled.to_csv('../datasets/BatteryCSV/B0005norm.csv', index=False)"
   ],
   "id": "f781e64c6c1fab16"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1.3 dataloader"
   ],
   "id": "1bb456ffcaf094eb"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T08:18:45.033432Z",
     "start_time": "2024-03-25T08:18:45.029492Z"
    }
   },
   "outputs": [],
   "source": [
    "class LoadDataset(Dataset):\n",
    "    def __init__(self, root_dir, seq_len, features,  transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.seq_len  = seq_len\n",
    "        self.features = features\n",
    "        self.transform = transform\n",
    "        self.file_list = sorted(os.listdir(root_dir))  # Assumes file names determine order\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        battery_id = self.file_list[idx]\n",
    "        battery_path = os.path.join(self.root_dir, battery_id)\n",
    "        dataset, label = data_loader(battery_path, self.seq_len, self.features)\n",
    "        # if self.transform:\n",
    "        #     dataset = self.transform(dataset)\n",
    "        #     label = self.transform(label)\n",
    "\n",
    "        return dataset, label\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# custom_dataset = LoadDataset(train_directory, seq_len=seq_len, features=features)\n",
    "#\n",
    "# # Create DataLoader\n",
    "# batch_size = 1\n",
    "# dataloader = DataLoader(custom_dataset, batch_size=batch_size)\n",
    "#\n",
    "# for train_data, train_data_real in dataloader:\n",
    "#     # train_data=torch.squeeze(train_data)\n",
    "#     print(train_data.shape)"
   ],
   "id": "6d1d6a4d5fcdd422"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2. training\n",
    "class torch.nn.LSTM(*args, **kwargs)\n",
    "参数有：\n",
    "    input_size：x的特征维度\n",
    "    hidden_size：隐藏层的特征维度\n",
    "    num_layers：lstm隐层的层数，默认为1\n",
    "    bias：False则bihbih=0和bhhbhh=0. 默认为True\n",
    "    batch_first：True则输入输出的数据格式为 (batch, seq_len, feature)\n",
    "    dropout：除最后一层，每一层的输出都进行dropout，默认为: 0\n",
    "    bidirectional：True则为双向lstm默认为False\n",
    "\n",
    "LSTM input(seq_len, batch, input_size)\n",
    "参数有：\n",
    "    batch：每次喂给网络的数据条数，在NLP中就是一次喂给网络多少个句子 !!!\n",
    "    seq_len：序列长度，在NLP中就是句子长度，一般都会用pad_sequence补齐长度!!!\n",
    "    input_size：特征维度，和前面定义网络结构的input_size一致。\n",
    "\n",
    "output,(ht, ct) = net(input)\n",
    "    output: 最后一个状态的隐藏层的神经元输出 size = （seq_Len, batch, num_directions * hidden_size)\n",
    "    ht：最后一个状态的隐含层的状态值\n",
    "    ct：最后一个状态的隐含层的遗忘门值\n",
    "\n"
   ],
   "id": "315bbd24fde4dc2"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T08:18:48.137679Z",
     "start_time": "2024-03-25T08:18:48.129847Z"
    }
   },
   "outputs": [],
   "source": [
    "# net structure\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.lstm3 = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.lstm4 = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out, _ = self.lstm1(x) # shape（seq_Len, batch, num_directions * hidden_size)\n",
    "        out, _ = self.lstm2(out)\n",
    "        out, _ = self.lstm3(out)\n",
    "        out, _ = self.lstm4(out)\n",
    "\n",
    "        out = self.fc(out[:, -1, :])  # 使用最后一个时间步的输出的输入（seq_Len, batch, num_directions * hidden_size)\n",
    "        # print(out.shape)\n",
    "        return out\n"
   ],
   "id": "a25de1dab11ef0a6"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T17:27:12.461668300Z",
     "start_time": "2024-03-18T12:34:37.024881600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU.\n",
      "-------epoch  0 -------\n",
      "train set Loss: 0.2544890487327939\n",
      "val set Loss: 0.16656597455342612\n",
      "-------epoch  1 -------\n",
      "train set Loss: 0.22176036112010478\n",
      "val set Loss: 0.035358903308709465\n",
      "-------epoch  2 -------\n",
      "train set Loss: 0.16206913174130022\n",
      "val set Loss: 0.029704665765166283\n",
      "-------epoch  3 -------\n",
      "train set Loss: 0.1388199324347079\n",
      "val set Loss: 0.07080391049385071\n",
      "-------epoch  4 -------\n",
      "train set Loss: 0.10440354688558727\n",
      "val set Loss: 0.04578728104631106\n",
      "-------epoch  5 -------\n",
      "train set Loss: 0.07244299510493875\n",
      "val set Loss: 0.022380041579405468\n",
      "-------epoch  6 -------\n",
      "train set Loss: 0.09303417288232595\n",
      "val set Loss: 0.05826391854013006\n",
      "-------epoch  7 -------\n",
      "train set Loss: 0.04013777613872662\n",
      "val set Loss: 0.01315513210526357\n",
      "-------epoch  8 -------\n",
      "train set Loss: 0.03277038873173296\n",
      "val set Loss: 0.013117047453609606\n",
      "-------epoch  9 -------\n",
      "train set Loss: 0.026097404191241368\n",
      "val set Loss: 0.007776088508156438\n",
      "-------epoch  10 -------\n",
      "train set Loss: 0.03548657987965271\n",
      "val set Loss: 0.006958906868627916\n",
      "-------epoch  11 -------\n",
      "train set Loss: 0.021718246824166274\n",
      "val set Loss: 0.0036124587253046534\n",
      "-------epoch  12 -------\n",
      "train set Loss: 0.030241276191954967\n",
      "val set Loss: 0.0053195859072729945\n",
      "-------epoch  13 -------\n",
      "train set Loss: 0.026584676479542393\n",
      "val set Loss: 0.011876530013978481\n",
      "-------epoch  14 -------\n",
      "train set Loss: 0.05653678355040029\n",
      "val set Loss: 0.007347179712572445\n",
      "-------epoch  15 -------\n",
      "train set Loss: 0.03322922639315948\n",
      "val set Loss: 0.010396960754102716\n",
      "-------epoch  16 -------\n",
      "train set Loss: 0.018924675498274156\n",
      "val set Loss: 0.0035073364172906927\n",
      "-------epoch  17 -------\n",
      "train set Loss: 0.022668687153491192\n",
      "val set Loss: 0.005237187346210703\n",
      "-------epoch  18 -------\n",
      "train set Loss: 0.018972295329440385\n",
      "val set Loss: 0.0038627286558039486\n",
      "-------epoch  19 -------\n",
      "train set Loss: 0.03354977337497985\n",
      "val set Loss: 0.014452711989482244\n",
      "-------epoch  20 -------\n",
      "train set Loss: 0.018435227152658627\n",
      "val set Loss: 0.0047618134412914515\n",
      "-------epoch  21 -------\n",
      "train set Loss: 0.026330272243358196\n",
      "val set Loss: 0.012243346776813269\n",
      "-------epoch  22 -------\n",
      "train set Loss: 0.019842212122457566\n",
      "val set Loss: 0.007974846288561821\n",
      "-------epoch  23 -------\n",
      "train set Loss: 0.03976364812115207\n",
      "val set Loss: 0.02771218866109848\n",
      "-------epoch  24 -------\n",
      "train set Loss: 0.022235140330158176\n",
      "val set Loss: 0.011334176485737165\n",
      "-------epoch  25 -------\n",
      "train set Loss: 0.03418242687708698\n",
      "val set Loss: 0.024212031314770382\n",
      "-------epoch  26 -------\n",
      "train set Loss: 0.02234055889188312\n",
      "val set Loss: 0.008149973272035519\n",
      "-------epoch  27 -------\n",
      "train set Loss: 0.02993051477649715\n",
      "val set Loss: 0.016058790031820536\n",
      "-------epoch  28 -------\n",
      "train set Loss: 0.019591555257793516\n",
      "val set Loss: 0.008806543347115317\n",
      "-------epoch  29 -------\n",
      "train set Loss: 0.02841092686256161\n",
      "val set Loss: 0.0162309220371147\n",
      "-------epoch  30 -------\n",
      "train set Loss: 0.020042971060611307\n",
      "val set Loss: 0.005234155881529053\n",
      "-------epoch  31 -------\n",
      "train set Loss: 0.027194484964711593\n",
      "val set Loss: 0.012604605328912536\n",
      "-------epoch  32 -------\n",
      "train set Loss: 0.017509521595202387\n",
      "val set Loss: 0.0056057895223299665\n",
      "-------epoch  33 -------\n",
      "train set Loss: 0.02138024651852902\n",
      "val set Loss: 0.010509164887480438\n",
      "-------epoch  34 -------\n",
      "train set Loss: 0.016367305447347463\n",
      "val set Loss: 0.0032288114501473806\n",
      "-------epoch  35 -------\n",
      "train set Loss: 0.020335974398767574\n",
      "val set Loss: 0.00745455330858628\n",
      "-------epoch  36 -------\n",
      "train set Loss: 0.013784071356349159\n",
      "val set Loss: 0.0031741414277348667\n",
      "-------epoch  37 -------\n",
      "train set Loss: 0.016439026337466203\n",
      "val set Loss: 0.006180626980494708\n",
      "-------epoch  38 -------\n",
      "train set Loss: 0.014327306936029344\n",
      "val set Loss: 0.0029551436503728232\n",
      "-------epoch  39 -------\n",
      "train set Loss: 0.01946060189337004\n",
      "val set Loss: 0.007577960243603836\n",
      "-------epoch  40 -------\n",
      "train set Loss: 0.014084019944275496\n",
      "val set Loss: 0.0030808172499140105\n",
      "-------epoch  41 -------\n",
      "train set Loss: 0.017717110621742905\n",
      "val set Loss: 0.007236912167475869\n",
      "-------epoch  42 -------\n",
      "train set Loss: 0.013846507148409728\n",
      "val set Loss: 0.0028966094832867384\n",
      "-------epoch  43 -------\n",
      "train set Loss: 0.017126929386577103\n",
      "val set Loss: 0.006714564592887958\n",
      "-------epoch  44 -------\n",
      "train set Loss: 0.013127679762401385\n",
      "val set Loss: 0.0029166243524135402\n",
      "-------epoch  45 -------\n",
      "train set Loss: 0.015656220038654283\n",
      "val set Loss: 0.006211722405472149\n",
      "-------epoch  46 -------\n",
      "train set Loss: 0.012876699582848232\n",
      "val set Loss: 0.00285793902973334\n",
      "-------epoch  47 -------\n",
      "train set Loss: 0.015632318715506698\n",
      "val set Loss: 0.006388055044226348\n",
      "-------epoch  48 -------\n",
      "train set Loss: 0.012651859804609557\n",
      "val set Loss: 0.002860193654972439\n",
      "-------epoch  49 -------\n",
      "train set Loss: 0.015144998514733743\n",
      "val set Loss: 0.006315122280890743\n",
      "-------epoch  50 -------\n",
      "train set Loss: 0.012428056288481457\n",
      "val set Loss: 0.0028329997730907053\n",
      "-------epoch  51 -------\n",
      "train set Loss: 0.014949895472673233\n",
      "val set Loss: 0.0064393723926817375\n",
      "-------epoch  52 -------\n",
      "train set Loss: 0.01221645710276789\n",
      "val set Loss: 0.0028264384503321103\n",
      "-------epoch  53 -------\n",
      "train set Loss: 0.014462530846358276\n",
      "val set Loss: 0.006218938389793038\n",
      "-------epoch  54 -------\n",
      "train set Loss: 0.011979953226982617\n",
      "val set Loss: 0.002815032101352699\n",
      "-------epoch  55 -------\n",
      "train set Loss: 0.014334752286667935\n",
      "val set Loss: 0.006359468097798526\n",
      "-------epoch  56 -------\n",
      "train set Loss: 0.01177078839711612\n",
      "val set Loss: 0.0028389958849099153\n",
      "-------epoch  57 -------\n",
      "train set Loss: 0.013686842013557908\n",
      "val set Loss: 0.005962542956694961\n",
      "-------epoch  58 -------\n",
      "train set Loss: 0.011611480805877364\n",
      "val set Loss: 0.0028226936216621348\n",
      "-------epoch  59 -------\n",
      "train set Loss: 0.014477552004973405\n",
      "val set Loss: 0.006465611979365349\n",
      "-------epoch  60 -------\n",
      "train set Loss: 0.011461357011576183\n",
      "val set Loss: 0.0029868010412125536\n",
      "-------epoch  61 -------\n",
      "train set Loss: 0.012858445206074976\n",
      "val set Loss: 0.005201811494771391\n",
      "-------epoch  62 -------\n",
      "train set Loss: 0.011356813854072244\n",
      "val set Loss: 0.0029581896330152326\n",
      "-------epoch  63 -------\n",
      "train set Loss: 0.013174710349994711\n",
      "val set Loss: 0.005533713071296613\n",
      "-------epoch  64 -------\n",
      "train set Loss: 0.010938560959184543\n",
      "val set Loss: 0.0028739744351090244\n",
      "-------epoch  65 -------\n",
      "train set Loss: 0.012268365724303294\n",
      "val set Loss: 0.005379161467620482\n",
      "-------epoch  66 -------\n",
      "train set Loss: 0.011007000253302977\n",
      "val set Loss: 0.0029132474155630916\n",
      "-------epoch  67 -------\n",
      "train set Loss: 0.013062017918855418\n",
      "val set Loss: 0.006200361026761432\n",
      "-------epoch  68 -------\n",
      "train set Loss: 0.010934799711685627\n",
      "val set Loss: 0.0032594717534569404\n",
      "-------epoch  69 -------\n",
      "train set Loss: 0.011942117697035428\n",
      "val set Loss: 0.004768231223958234\n",
      "-------epoch  70 -------\n",
      "train set Loss: 0.010861806611064822\n",
      "val set Loss: 0.0029871476581320167\n",
      "-------epoch  71 -------\n",
      "train set Loss: 0.013435838467557915\n",
      "val set Loss: 0.005638237324698518\n",
      "-------epoch  72 -------\n",
      "train set Loss: 0.011188163098413497\n",
      "val set Loss: 0.0033162263377259174\n",
      "-------epoch  73 -------\n",
      "train set Loss: 0.013246475024498067\n",
      "val set Loss: 0.006463047311020394\n",
      "-------epoch  74 -------\n",
      "train set Loss: 0.010295798296574503\n",
      "val set Loss: 0.0036282465249920883\n",
      "-------epoch  75 -------\n",
      "train set Loss: 0.010602918322256301\n",
      "val set Loss: 0.0038804154707274088\n",
      "-------epoch  76 -------\n",
      "train set Loss: 0.01019875226484146\n",
      "val set Loss: 0.0029340670444071293\n",
      "-------epoch  77 -------\n",
      "train set Loss: 0.01137032012367854\n",
      "val set Loss: 0.004268240600746746\n",
      "-------epoch  78 -------\n",
      "train set Loss: 0.01009014910669066\n",
      "val set Loss: 0.0031639596951814988\n",
      "-------epoch  79 -------\n",
      "train set Loss: 0.010971556751755998\n",
      "val set Loss: 0.006090019422117621\n",
      "-------epoch  80 -------\n",
      "train set Loss: 0.010268435711041093\n",
      "val set Loss: 0.003260335768572986\n",
      "-------epoch  81 -------\n",
      "train set Loss: 0.011620112439850346\n",
      "val set Loss: 0.003930896384796749\n",
      "-------epoch  82 -------\n",
      "train set Loss: 0.009808722021989524\n",
      "val set Loss: 0.0029157178554063043\n",
      "-------epoch  83 -------\n",
      "train set Loss: 0.01030867285502609\n",
      "val set Loss: 0.004812615147481362\n",
      "-------epoch  84 -------\n",
      "train set Loss: 0.009878828212385997\n",
      "val set Loss: 0.0028842842099644863\n",
      "-------epoch  85 -------\n",
      "train set Loss: 0.01201012124074623\n",
      "val set Loss: 0.004273060243576765\n",
      "-------epoch  86 -------\n",
      "train set Loss: 0.010054976328974589\n",
      "val set Loss: 0.003049630468012765\n",
      "-------epoch  87 -------\n",
      "train set Loss: 0.010023068648879417\n",
      "val set Loss: 0.004001195979071781\n",
      "-------epoch  88 -------\n",
      "train set Loss: 0.008872691466240212\n",
      "val set Loss: 0.0029089851062356806\n",
      "-------epoch  89 -------\n",
      "train set Loss: 0.009492681489209644\n",
      "val set Loss: 0.003740807364617164\n",
      "-------epoch  90 -------\n",
      "train set Loss: 0.009477534245233983\n",
      "val set Loss: 0.0028368911249951148\n",
      "-------epoch  91 -------\n",
      "train set Loss: 0.011561008309945464\n",
      "val set Loss: 0.004464923064612473\n",
      "-------epoch  92 -------\n",
      "train set Loss: 0.009569017776520923\n",
      "val set Loss: 0.002929103618953377\n",
      "-------epoch  93 -------\n",
      "train set Loss: 0.00945818185529788\n",
      "val set Loss: 0.0035399331585116065\n",
      "-------epoch  94 -------\n",
      "train set Loss: 0.008895097357453778\n",
      "val set Loss: 0.002906436571114076\n",
      "-------epoch  95 -------\n",
      "train set Loss: 0.00946826713552582\n",
      "val set Loss: 0.003178243525326252\n",
      "-------epoch  96 -------\n",
      "train set Loss: 0.009310386168654077\n",
      "val set Loss: 0.0030527077566754692\n",
      "-------epoch  97 -------\n",
      "train set Loss: 0.01009882178506814\n",
      "val set Loss: 0.0030743857593430826\n",
      "-------epoch  98 -------\n",
      "train set Loss: 0.009139510901877656\n",
      "val set Loss: 0.0026431567845672057\n",
      "-------epoch  99 -------\n",
      "train set Loss: 0.008317191842215833\n",
      "val set Loss: 0.0038782358703125888\n",
      "-------epoch  100 -------\n",
      "train set Loss: 0.00795277876255568\n",
      "val set Loss: 0.0029982230820072195\n",
      "-------epoch  101 -------\n",
      "train set Loss: 0.007793637227732689\n",
      "val set Loss: 0.0042005228460766375\n",
      "-------epoch  102 -------\n",
      "train set Loss: 0.009279495326336474\n",
      "val set Loss: 0.005489458912052214\n",
      "-------epoch  103 -------\n",
      "train set Loss: 0.01318622319959104\n",
      "val set Loss: 0.0038851041657229266\n",
      "-------epoch  104 -------\n",
      "train set Loss: 0.02569900741800666\n",
      "val set Loss: 0.004184046760201454\n",
      "-------epoch  105 -------\n",
      "train set Loss: 0.008990409472608008\n",
      "val set Loss: 0.0029131327173672616\n",
      "-------epoch  106 -------\n",
      "train set Loss: 0.008085781937697902\n",
      "val set Loss: 0.002967298816656694\n",
      "-------epoch  107 -------\n",
      "train set Loss: 0.009256201992247953\n",
      "val set Loss: 0.0034043972264043987\n",
      "-------epoch  108 -------\n",
      "train set Loss: 0.015967570825014262\n",
      "val set Loss: 0.003325223340652883\n",
      "-------epoch  109 -------\n",
      "train set Loss: 0.024627212429768407\n",
      "val set Loss: 0.0041073301739137\n",
      "-------epoch  110 -------\n",
      "train set Loss: 0.009829656748333946\n",
      "val set Loss: 0.004891214077360928\n",
      "-------epoch  111 -------\n",
      "train set Loss: 0.013284152237465605\n",
      "val set Loss: 0.0029453794413711876\n",
      "-------epoch  112 -------\n",
      "train set Loss: 0.019474532494787127\n",
      "val set Loss: 0.007484786212444305\n",
      "-------epoch  113 -------\n",
      "train set Loss: 0.009821584088495\n",
      "val set Loss: 0.003540815164645513\n",
      "-------epoch  114 -------\n",
      "train set Loss: 0.00913362154387869\n",
      "val set Loss: 0.0031117889205537117\n",
      "-------epoch  115 -------\n",
      "train set Loss: 0.00951208234153455\n",
      "val set Loss: 0.0038646882555137077\n",
      "-------epoch  116 -------\n",
      "train set Loss: 0.009322332323645242\n",
      "val set Loss: 0.003111269499640912\n",
      "-------epoch  117 -------\n",
      "train set Loss: 0.009082724355102982\n",
      "val set Loss: 0.0038140035952286175\n",
      "-------epoch  118 -------\n",
      "train set Loss: 0.008800988121074625\n",
      "val set Loss: 0.0032818260175796845\n",
      "-------epoch  119 -------\n",
      "train set Loss: 0.008629673927789554\n",
      "val set Loss: 0.0037658688185426095\n",
      "-------epoch  120 -------\n",
      "train set Loss: 0.008602167557692155\n",
      "val set Loss: 0.003441105674331387\n",
      "-------epoch  121 -------\n",
      "train set Loss: 0.008384083043783902\n",
      "val set Loss: 0.003904821273560325\n",
      "-------epoch  122 -------\n",
      "train set Loss: 0.008561643832945266\n",
      "val set Loss: 0.004035913618281484\n",
      "-------epoch  123 -------\n",
      "train set Loss: 0.008514636029140092\n",
      "val set Loss: 0.004040018771775067\n",
      "-------epoch  124 -------\n",
      "train set Loss: 0.008907014319556766\n",
      "val set Loss: 0.005458061816170812\n",
      "-------epoch  125 -------\n",
      "train set Loss: 0.009378832778893412\n",
      "val set Loss: 0.004290947729411225\n",
      "-------epoch  126 -------\n",
      "train set Loss: 0.009389205951010808\n",
      "val set Loss: 0.006954090126479666\n",
      "-------epoch  127 -------\n",
      "train set Loss: 0.010134135494008661\n",
      "val set Loss: 0.004230443776274721\n",
      "-------epoch  128 -------\n",
      "train set Loss: 0.010082637142040766\n",
      "val set Loss: 0.009031054369794825\n",
      "-------epoch  129 -------\n",
      "train set Loss: 0.011924531180411577\n",
      "val set Loss: 0.004633845218146841\n",
      "-------epoch  130 -------\n",
      "train set Loss: 0.011361292832298205\n",
      "val set Loss: 0.007799262103314201\n",
      "-------epoch  131 -------\n",
      "train set Loss: 0.01168930972693488\n",
      "val set Loss: 0.004963761467176179\n",
      "-------epoch  132 -------\n",
      "train set Loss: 0.011727665378712117\n",
      "val set Loss: 0.008416588883846998\n",
      "-------epoch  133 -------\n",
      "train set Loss: 0.011643903891090303\n",
      "val set Loss: 0.005333374758871893\n",
      "-------epoch  134 -------\n",
      "train set Loss: 0.01176870587049052\n",
      "val set Loss: 0.012008025116908053\n",
      "-------epoch  135 -------\n",
      "train set Loss: 0.012388443313539029\n",
      "val set Loss: 0.007511277954714994\n",
      "-------epoch  136 -------\n",
      "train set Loss: 0.010759713841835036\n",
      "val set Loss: 0.01008416215578715\n",
      "-------epoch  137 -------\n",
      "train set Loss: 0.010834359291475266\n",
      "val set Loss: 0.004339038200366001\n",
      "-------epoch  138 -------\n",
      "train set Loss: 0.010346186708193272\n",
      "val set Loss: 0.009419766099502644\n",
      "-------epoch  139 -------\n",
      "train set Loss: 0.011494934288784862\n",
      "val set Loss: 0.004118801754278441\n",
      "-------epoch  140 -------\n",
      "train set Loss: 0.011317008018959313\n",
      "val set Loss: 0.009909532032907009\n",
      "-------epoch  141 -------\n",
      "train set Loss: 0.012487972099334001\n",
      "val set Loss: 0.005218809004873037\n",
      "-------epoch  142 -------\n",
      "train set Loss: 0.012236534925177693\n",
      "val set Loss: 0.01151527821396788\n",
      "-------epoch  143 -------\n",
      "train set Loss: 0.013649466212373227\n",
      "val set Loss: 0.005034770506123702\n",
      "-------epoch  144 -------\n",
      "train set Loss: 0.014615571796894074\n",
      "val set Loss: 0.013191645964980125\n",
      "-------epoch  145 -------\n",
      "train set Loss: 0.016125517855398355\n",
      "val set Loss: 0.005374512538158645\n",
      "-------epoch  146 -------\n",
      "train set Loss: 0.013759797705570237\n",
      "val set Loss: 0.013635719195008278\n",
      "-------epoch  147 -------\n",
      "train set Loss: 0.014608015711419285\n",
      "val set Loss: 0.00494124631707867\n",
      "-------epoch  148 -------\n",
      "train set Loss: 0.019553858251310886\n",
      "val set Loss: 0.024782327314217884\n",
      "-------epoch  149 -------\n",
      "train set Loss: 0.017350951393600555\n",
      "val set Loss: 0.0035315685478659966\n",
      "-------epoch  150 -------\n",
      "train set Loss: 0.014600985783035867\n",
      "val set Loss: 0.005866516226281722\n",
      "-------epoch  151 -------\n",
      "train set Loss: 0.011130614215508103\n",
      "val set Loss: 0.003966520307585597\n",
      "-------epoch  152 -------\n",
      "train set Loss: 0.011316347809042782\n",
      "val set Loss: 0.008088952551285425\n",
      "-------epoch  153 -------\n",
      "train set Loss: 0.010940004721051081\n",
      "val set Loss: 0.006524543898801009\n",
      "-------epoch  154 -------\n",
      "train set Loss: 0.009971334792207926\n",
      "val set Loss: 0.005311674516027172\n",
      "-------epoch  155 -------\n",
      "train set Loss: 0.00851600182009861\n",
      "val set Loss: 0.004568085365463048\n",
      "-------epoch  156 -------\n",
      "train set Loss: 0.00954232765128836\n",
      "val set Loss: 0.005017470122159769\n",
      "-------epoch  157 -------\n",
      "train set Loss: 0.009916436127386987\n",
      "val set Loss: 0.010224291744331518\n",
      "-------epoch  158 -------\n",
      "train set Loss: 0.009091185415163636\n",
      "val set Loss: 0.007106035676163931\n",
      "-------epoch  159 -------\n",
      "train set Loss: 0.010320095979841426\n",
      "val set Loss: 0.007022782869171351\n",
      "-------epoch  160 -------\n",
      "train set Loss: 0.007954010354587808\n",
      "val set Loss: 0.00433583677901576\n",
      "-------epoch  161 -------\n",
      "train set Loss: 0.008100547005888074\n",
      "val set Loss: 0.004049921194867541\n",
      "-------epoch  162 -------\n",
      "train set Loss: 0.007552412783261389\n",
      "val set Loss: 0.0030801552541864416\n",
      "-------epoch  163 -------\n",
      "train set Loss: 0.007494957060553134\n",
      "val set Loss: 0.0032618967622208097\n",
      "-------epoch  164 -------\n",
      "train set Loss: 0.007543536321027205\n",
      "val set Loss: 0.00326678273268044\n",
      "-------epoch  165 -------\n",
      "train set Loss: 0.007816757084801793\n",
      "val set Loss: 0.003755590800816814\n",
      "-------epoch  166 -------\n",
      "train set Loss: 0.007815475547104142\n",
      "val set Loss: 0.0034015161994223795\n",
      "-------epoch  167 -------\n",
      "train set Loss: 0.007992406594567\n",
      "val set Loss: 0.004090023547178134\n",
      "-------epoch  168 -------\n",
      "train set Loss: 0.00748269294097554\n",
      "val set Loss: 0.00372486311243847\n",
      "-------epoch  169 -------\n",
      "train set Loss: 0.007916299948119558\n",
      "val set Loss: 0.004051068855915219\n",
      "-------epoch  170 -------\n",
      "train set Loss: 0.007631567933713086\n",
      "val set Loss: 0.0031669315843222043\n",
      "-------epoch  171 -------\n",
      "train set Loss: 0.007643959129345603\n",
      "val set Loss: 0.0033978531525159874\n",
      "-------epoch  172 -------\n",
      "train set Loss: 0.007414580204058438\n",
      "val set Loss: 0.0032781268431184194\n",
      "-------epoch  173 -------\n",
      "train set Loss: 0.007487766837584786\n",
      "val set Loss: 0.003252711806756755\n",
      "-------epoch  174 -------\n",
      "train set Loss: 0.007471229906659573\n",
      "val set Loss: 0.0029416633963895342\n",
      "-------epoch  175 -------\n",
      "train set Loss: 0.0071732414880534634\n",
      "val set Loss: 0.003034037033406397\n",
      "-------epoch  176 -------\n",
      "train set Loss: 0.007110980054130777\n",
      "val set Loss: 0.0030484706124601266\n",
      "-------epoch  177 -------\n",
      "train set Loss: 0.007122221000026911\n",
      "val set Loss: 0.0030584937679426125\n",
      "-------epoch  178 -------\n",
      "train set Loss: 0.007303233440470649\n",
      "val set Loss: 0.003025756411564847\n",
      "-------epoch  179 -------\n",
      "train set Loss: 0.007352490314806346\n",
      "val set Loss: 0.002886597280545781\n",
      "-------epoch  180 -------\n",
      "train set Loss: 0.007741052633500658\n",
      "val set Loss: 0.0038746156302901604\n",
      "-------epoch  181 -------\n",
      "train set Loss: 0.010799917511758395\n",
      "val set Loss: 0.008100203548868498\n",
      "-------epoch  182 -------\n",
      "train set Loss: 0.013179524463484995\n",
      "val set Loss: 0.0032994699431583285\n",
      "-------epoch  183 -------\n",
      "train set Loss: 0.019456335367867724\n",
      "val set Loss: 0.017156286475559075\n",
      "-------epoch  184 -------\n",
      "train set Loss: 0.012641367336036637\n",
      "val set Loss: 0.006122784378627936\n",
      "-------epoch  185 -------\n",
      "train set Loss: 0.021462822109460832\n",
      "val set Loss: 0.004706083923034991\n",
      "-------epoch  186 -------\n",
      "train set Loss: 0.011720396869350225\n",
      "val set Loss: 0.0060687615380932885\n",
      "-------epoch  187 -------\n",
      "train set Loss: 0.014789187350543216\n",
      "val set Loss: 0.002853838261216879\n",
      "-------epoch  188 -------\n",
      "train set Loss: 0.0180314154305961\n",
      "val set Loss: 0.005876041483134031\n",
      "-------epoch  189 -------\n",
      "train set Loss: 0.00869278091849992\n",
      "val set Loss: 0.003982882325847943\n",
      "-------epoch  190 -------\n",
      "train set Loss: 0.007911506440141238\n",
      "val set Loss: 0.0028633368492592126\n",
      "-------epoch  191 -------\n",
      "train set Loss: 0.007729631718248129\n",
      "val set Loss: 0.003457469128382703\n",
      "-------epoch  192 -------\n",
      "train set Loss: 0.007586981257190928\n",
      "val set Loss: 0.0030065337972094617\n",
      "-------epoch  193 -------\n",
      "train set Loss: 0.007832617613021285\n",
      "val set Loss: 0.003467952172892789\n",
      "-------epoch  194 -------\n",
      "train set Loss: 0.0073023744818056\n",
      "val set Loss: 0.003194920990305642\n",
      "-------epoch  195 -------\n",
      "train set Loss: 0.0074621529970318075\n",
      "val set Loss: 0.0031839872632796564\n",
      "-------epoch  196 -------\n",
      "train set Loss: 0.006865937818074599\n",
      "val set Loss: 0.0031055630339930453\n",
      "-------epoch  197 -------\n",
      "train set Loss: 0.006800271286629141\n",
      "val set Loss: 0.0029029493064930043\n",
      "-------epoch  198 -------\n",
      "train set Loss: 0.0063983114948496225\n",
      "val set Loss: 0.002786221467734625\n",
      "-------epoch  199 -------\n",
      "train set Loss: 0.006567157947574742\n",
      "val set Loss: 0.002843143476638943\n",
      "-------epoch  200 -------\n",
      "train set Loss: 0.00627131869609002\n",
      "val set Loss: 0.003010528744198382\n",
      "-------epoch  201 -------\n",
      "train set Loss: 0.006397454400430433\n",
      "val set Loss: 0.004883575311396271\n",
      "-------epoch  202 -------\n",
      "train set Loss: 0.008675505277933553\n",
      "val set Loss: 0.005373049508004139\n",
      "-------epoch  203 -------\n",
      "train set Loss: 0.008561313508544117\n",
      "val set Loss: 0.008514131341750423\n",
      "-------epoch  204 -------\n",
      "train set Loss: 0.011201877008425072\n",
      "val set Loss: 0.014919922919943929\n",
      "-------epoch  205 -------\n",
      "train set Loss: 0.00751394321792759\n",
      "val set Loss: 0.005441523545111219\n",
      "-------epoch  206 -------\n",
      "train set Loss: 0.007289437445579096\n",
      "val set Loss: 0.0062282970660210895\n",
      "-------epoch  207 -------\n",
      "train set Loss: 0.006654000864364207\n",
      "val set Loss: 0.004725044263371577\n",
      "-------epoch  208 -------\n",
      "train set Loss: 0.006874634518753737\n",
      "val set Loss: 0.003279623187457522\n",
      "-------epoch  209 -------\n",
      "train set Loss: 0.0066306001541670415\n",
      "val set Loss: 0.002706355774231876\n",
      "-------epoch  210 -------\n",
      "train set Loss: 0.007331620522600133\n",
      "val set Loss: 0.008586888977636894\n",
      "-------epoch  211 -------\n",
      "train set Loss: 0.008891508476808667\n",
      "val set Loss: 0.0030505222675856203\n",
      "-------epoch  212 -------\n",
      "train set Loss: 0.008192621867638082\n",
      "val set Loss: 0.003364133163510511\n",
      "-------epoch  213 -------\n",
      "train set Loss: 0.007550061981892214\n",
      "val set Loss: 0.0031988774814332523\n",
      "-------epoch  214 -------\n",
      "train set Loss: 0.0064966513449326154\n",
      "val set Loss: 0.003417787879394988\n",
      "-------epoch  215 -------\n",
      "train set Loss: 0.006357899836148135\n",
      "val set Loss: 0.00338954208806778\n",
      "-------epoch  216 -------\n",
      "train set Loss: 0.006371367177926004\n",
      "val set Loss: 0.0039034873188938946\n",
      "-------epoch  217 -------\n",
      "train set Loss: 0.00727126459882129\n",
      "val set Loss: 0.0058064092687952025\n",
      "-------epoch  218 -------\n",
      "train set Loss: 0.006154344203823711\n",
      "val set Loss: 0.0036415614983222135\n",
      "-------epoch  219 -------\n",
      "train set Loss: 0.005497108012787066\n",
      "val set Loss: 0.002944173291325569\n",
      "-------epoch  220 -------\n",
      "train set Loss: 0.0060503800975857305\n",
      "val set Loss: 0.003157826683794459\n",
      "-------epoch  221 -------\n",
      "train set Loss: 0.006132092735497281\n",
      "val set Loss: 0.003119580496180182\n",
      "-------epoch  222 -------\n",
      "train set Loss: 0.006281472792616114\n",
      "val set Loss: 0.003103982201234127\n",
      "-------epoch  223 -------\n",
      "train set Loss: 0.006803078113007359\n",
      "val set Loss: 0.006972690452433501\n",
      "-------epoch  224 -------\n",
      "train set Loss: 0.007533284542732872\n",
      "val set Loss: 0.0031785484849630543\n",
      "-------epoch  225 -------\n",
      "train set Loss: 0.007647048762300983\n",
      "val set Loss: 0.005708833031045894\n",
      "-------epoch  226 -------\n",
      "train set Loss: 0.00752027686976362\n",
      "val set Loss: 0.005050843891998132\n",
      "-------epoch  227 -------\n",
      "train set Loss: 0.005614877251791768\n",
      "val set Loss: 0.0033517279856217406\n",
      "-------epoch  228 -------\n",
      "train set Loss: 0.00589294530916959\n",
      "val set Loss: 0.0038121821805058667\n",
      "-------epoch  229 -------\n",
      "train set Loss: 0.006185722468944732\n",
      "val set Loss: 0.0029155513717948147\n",
      "-------epoch  230 -------\n",
      "train set Loss: 0.005808319425123045\n",
      "val set Loss: 0.009659515179616088\n",
      "-------epoch  231 -------\n",
      "train set Loss: 0.0061334342646296135\n",
      "val set Loss: 0.007327744640254726\n",
      "-------epoch  232 -------\n",
      "train set Loss: 0.008068311057868413\n",
      "val set Loss: 0.003080895073556652\n",
      "-------epoch  233 -------\n",
      "train set Loss: 0.009000134282687214\n",
      "val set Loss: 0.0036109499245261154\n",
      "-------epoch  234 -------\n",
      "train set Loss: 0.00893264735408593\n",
      "val set Loss: 0.0027696034812834114\n",
      "-------epoch  235 -------\n",
      "train set Loss: 0.0064979247903102074\n",
      "val set Loss: 0.006184944494937857\n",
      "-------epoch  236 -------\n",
      "train set Loss: 0.005710357958450913\n",
      "val set Loss: 0.003191446390701458\n",
      "-------epoch  237 -------\n",
      "train set Loss: 0.006144239346613176\n",
      "val set Loss: 0.005525266887464871\n",
      "-------epoch  238 -------\n",
      "train set Loss: 0.0059151647984981535\n",
      "val set Loss: 0.005364573056188722\n",
      "-------epoch  239 -------\n",
      "train set Loss: 0.006295302514336072\n",
      "val set Loss: 0.003354593412950635\n",
      "-------epoch  240 -------\n",
      "train set Loss: 0.005758358018356375\n",
      "val set Loss: 0.005328299477696419\n",
      "-------epoch  241 -------\n",
      "train set Loss: 0.00565317285771016\n",
      "val set Loss: 0.0034396648309969655\n",
      "-------epoch  242 -------\n",
      "train set Loss: 0.00621881329570897\n",
      "val set Loss: 0.006253450255220135\n",
      "-------epoch  243 -------\n",
      "train set Loss: 0.006110147906001657\n",
      "val set Loss: 0.003931072598788887\n",
      "-------epoch  244 -------\n",
      "train set Loss: 0.007587724642944522\n",
      "val set Loss: 0.01083024979258577\n",
      "-------epoch  245 -------\n",
      "train set Loss: 0.00786968611762859\n",
      "val set Loss: 0.007377996652697523\n",
      "-------epoch  246 -------\n",
      "train set Loss: 0.01113087693869602\n",
      "val set Loss: 0.003033267091571664\n",
      "-------epoch  247 -------\n",
      "train set Loss: 0.00910480818769429\n",
      "val set Loss: 0.005022481083869934\n",
      "-------epoch  248 -------\n",
      "train set Loss: 0.006559485034667887\n",
      "val set Loss: 0.0049840320328560965\n",
      "-------epoch  249 -------\n",
      "train set Loss: 0.00622381828026846\n",
      "val set Loss: 0.01616031174004699\n",
      "-------epoch  250 -------\n",
      "train set Loss: 0.005774809860158711\n",
      "val set Loss: 0.00635294895619154\n",
      "-------epoch  251 -------\n",
      "train set Loss: 0.0068075568927451965\n",
      "val set Loss: 0.002694011927815154\n",
      "-------epoch  252 -------\n",
      "train set Loss: 0.006815578891837504\n",
      "val set Loss: 0.0037524620226273933\n",
      "-------epoch  253 -------\n",
      "train set Loss: 0.006875034421100281\n",
      "val set Loss: 0.00892138029060637\n",
      "-------epoch  254 -------\n",
      "train set Loss: 0.007212387542240322\n",
      "val set Loss: 0.0034116942163867256\n",
      "-------epoch  255 -------\n",
      "train set Loss: 0.008975383799988777\n",
      "val set Loss: 0.007702079601585865\n",
      "-------epoch  256 -------\n",
      "train set Loss: 0.008232865383615718\n",
      "val set Loss: 0.019061537672920775\n",
      "-------epoch  257 -------\n",
      "train set Loss: 0.006198638145579025\n",
      "val set Loss: 0.005933926159438367\n",
      "-------epoch  258 -------\n",
      "train set Loss: 0.006469411562429741\n",
      "val set Loss: 0.055828108995532\n",
      "-------epoch  259 -------\n",
      "train set Loss: 0.007281966197770089\n",
      "val set Loss: 0.010782698615609357\n",
      "-------epoch  260 -------\n",
      "train set Loss: 0.006585883098596241\n",
      "val set Loss: 0.003034164871981678\n",
      "-------epoch  261 -------\n",
      "train set Loss: 0.009118581592920236\n",
      "val set Loss: 0.007336570260425408\n",
      "-------epoch  262 -------\n",
      "train set Loss: 0.008494575805962086\n",
      "val set Loss: 0.014482643261241416\n",
      "-------epoch  263 -------\n",
      "train set Loss: 0.006611099498695694\n",
      "val set Loss: 0.02349966981758674\n",
      "-------epoch  264 -------\n",
      "train set Loss: 0.007341689043678343\n",
      "val set Loss: 0.08330889851398145\n",
      "-------epoch  265 -------\n",
      "train set Loss: 0.010003371168859304\n",
      "val set Loss: 0.005306935713936885\n",
      "-------epoch  266 -------\n",
      "train set Loss: 0.010133953359909355\n",
      "val set Loss: 0.0028704672780198357\n",
      "-------epoch  267 -------\n",
      "train set Loss: 0.008899151594669093\n",
      "val set Loss: 0.003240204881876707\n",
      "-------epoch  268 -------\n",
      "train set Loss: 0.007796343886293471\n",
      "val set Loss: 0.0029390122993694\n",
      "-------epoch  269 -------\n",
      "train set Loss: 0.00587180178030394\n",
      "val set Loss: 0.0033716754987835884\n",
      "-------epoch  270 -------\n",
      "train set Loss: 0.005906414475757629\n",
      "val set Loss: 0.0034541450052832565\n",
      "-------epoch  271 -------\n",
      "train set Loss: 0.005675778200384229\n",
      "val set Loss: 0.003492800324844817\n",
      "-------epoch  272 -------\n",
      "train set Loss: 0.005629251851351\n",
      "val set Loss: 0.0037020701759805283\n",
      "-------epoch  273 -------\n",
      "train set Loss: 0.005502224389347248\n",
      "val set Loss: 0.0035745883360505104\n",
      "-------epoch  274 -------\n",
      "train set Loss: 0.005697993279318326\n",
      "val set Loss: 0.004438684942821662\n",
      "-------epoch  275 -------\n",
      "train set Loss: 0.006191939525306225\n",
      "val set Loss: 0.0031582448088253536\n",
      "-------epoch  276 -------\n",
      "train set Loss: 0.0057985620632825885\n",
      "val set Loss: 0.004240423324517906\n",
      "-------epoch  277 -------\n",
      "train set Loss: 0.00781613391765859\n",
      "val set Loss: 0.00333142964518629\n",
      "-------epoch  278 -------\n",
      "train set Loss: 0.00915341274405364\n",
      "val set Loss: 0.005036582132258142\n",
      "-------epoch  279 -------\n",
      "train set Loss: 0.007070039854734205\n",
      "val set Loss: 0.008033126903076967\n",
      "-------epoch  280 -------\n",
      "train set Loss: 0.0066128131444565955\n",
      "val set Loss: 0.010020024298379818\n",
      "-------epoch  281 -------\n",
      "train set Loss: 0.006033441075123847\n",
      "val set Loss: 0.0045408471099411445\n",
      "-------epoch  282 -------\n",
      "train set Loss: 0.007142489635880338\n",
      "val set Loss: 0.04873159857622037\n",
      "-------epoch  283 -------\n",
      "train set Loss: 0.008279528054408729\n",
      "val set Loss: 0.011438357566172877\n",
      "-------epoch  284 -------\n",
      "train set Loss: 0.011318393459077924\n",
      "val set Loss: 0.003173162476741709\n",
      "-------epoch  285 -------\n",
      "train set Loss: 0.012754489430226385\n",
      "val set Loss: 0.0030154746200423688\n",
      "-------epoch  286 -------\n",
      "train set Loss: 0.010167485864367337\n",
      "val set Loss: 0.01315411909793814\n",
      "-------epoch  287 -------\n",
      "train set Loss: 0.007206037655705586\n",
      "val set Loss: 0.01252593860651056\n",
      "-------epoch  288 -------\n",
      "train set Loss: 0.00782570049574133\n",
      "val set Loss: 0.0194835155562032\n",
      "-------epoch  289 -------\n",
      "train set Loss: 0.00883256092580268\n",
      "val set Loss: 0.006325923061619203\n",
      "-------epoch  290 -------\n",
      "train set Loss: 0.015745255809742956\n",
      "val set Loss: 0.026144096317390602\n",
      "-------epoch  291 -------\n",
      "train set Loss: 0.007481051028007641\n",
      "val set Loss: 0.0039948379853740335\n",
      "-------epoch  292 -------\n",
      "train set Loss: 0.006117047721636482\n",
      "val set Loss: 0.00975409477056625\n",
      "-------epoch  293 -------\n",
      "train set Loss: 0.005921364272944629\n",
      "val set Loss: 0.0031550173832026\n",
      "-------epoch  294 -------\n",
      "train set Loss: 0.005468658616300672\n",
      "val set Loss: 0.012053684564307332\n",
      "-------epoch  295 -------\n",
      "train set Loss: 0.005997256123227998\n",
      "val set Loss: 0.0036933018709532917\n",
      "-------epoch  296 -------\n",
      "train set Loss: 0.005256995398667641\n",
      "val set Loss: 0.06616443193828066\n",
      "-------epoch  297 -------\n",
      "train set Loss: 0.006054925709031522\n",
      "val set Loss: 0.017836932946617406\n",
      "-------epoch  298 -------\n",
      "train set Loss: 0.005654711027164012\n",
      "val set Loss: 0.00345303436430792\n",
      "-------epoch  299 -------\n",
      "train set Loss: 0.005134716530446895\n",
      "val set Loss: 0.01502158430715402\n",
      "-------epoch  300 -------\n",
      "train set Loss: 0.00484570085798623\n",
      "val set Loss: 0.0066934841258140905\n",
      "-------epoch  301 -------\n",
      "train set Loss: 0.004571113434212748\n",
      "val set Loss: 0.003015936342611288\n",
      "-------epoch  302 -------\n",
      "train set Loss: 0.0051453035348095\n",
      "val set Loss: 0.005659131042193621\n",
      "-------epoch  303 -------\n",
      "train set Loss: 0.004849898103275336\n",
      "val set Loss: 0.003581474127713591\n",
      "-------epoch  304 -------\n",
      "train set Loss: 0.00597788082115585\n",
      "val set Loss: 0.006287232972681522\n",
      "-------epoch  305 -------\n",
      "train set Loss: 0.006232807246851735\n",
      "val set Loss: 0.006777203641831875\n",
      "-------epoch  306 -------\n",
      "train set Loss: 0.006376749718328938\n",
      "val set Loss: 0.006758211452203493\n",
      "-------epoch  307 -------\n",
      "train set Loss: 0.006881280429661274\n",
      "val set Loss: 0.004018236795673147\n",
      "-------epoch  308 -------\n",
      "train set Loss: 0.006428527855896391\n",
      "val set Loss: 0.004724879516288638\n",
      "-------epoch  309 -------\n",
      "train set Loss: 0.007284680156735703\n",
      "val set Loss: 0.005869898673457404\n",
      "-------epoch  310 -------\n",
      "train set Loss: 0.006696957834647037\n",
      "val set Loss: 0.003229211928555742\n",
      "-------epoch  311 -------\n",
      "train set Loss: 0.006799772534577642\n",
      "val set Loss: 0.01423831384939452\n",
      "-------epoch  312 -------\n",
      "train set Loss: 0.007364448296721093\n",
      "val set Loss: 0.003092192938008035\n",
      "-------epoch  313 -------\n",
      "train set Loss: 0.005986672242579516\n",
      "val set Loss: 0.05299780219017217\n",
      "-------epoch  314 -------\n",
      "train set Loss: 0.007344667208380997\n",
      "val set Loss: 0.004039501422084868\n",
      "-------epoch  315 -------\n",
      "train set Loss: 0.005878494215430692\n",
      "val set Loss: 0.03370417526457459\n",
      "-------epoch  316 -------\n",
      "train set Loss: 0.006226638430962339\n",
      "val set Loss: 0.0029248985035034516\n",
      "-------epoch  317 -------\n",
      "train set Loss: 0.005280362935154699\n",
      "val set Loss: 0.031251810384371005\n",
      "-------epoch  318 -------\n",
      "train set Loss: 0.005851190622197464\n",
      "val set Loss: 0.0034505098786515496\n",
      "-------epoch  319 -------\n",
      "train set Loss: 0.006437716183427256\n",
      "val set Loss: 0.004308335211438437\n",
      "-------epoch  320 -------\n",
      "train set Loss: 0.005930540920817293\n",
      "val set Loss: 0.005761949035028617\n",
      "-------epoch  321 -------\n",
      "train set Loss: 0.00581054623471573\n",
      "val set Loss: 0.004017104006682833\n",
      "-------epoch  322 -------\n",
      "train set Loss: 0.00510964507018798\n",
      "val set Loss: 0.003390471664412568\n",
      "-------epoch  323 -------\n",
      "train set Loss: 0.005327680794871412\n",
      "val set Loss: 0.003829082183074206\n",
      "-------epoch  324 -------\n",
      "train set Loss: 0.005848820433602669\n",
      "val set Loss: 0.0046428505835744245\n",
      "-------epoch  325 -------\n",
      "train set Loss: 0.006621169586433098\n",
      "val set Loss: 0.003905748851442089\n",
      "-------epoch  326 -------\n",
      "train set Loss: 0.007027152348891832\n",
      "val set Loss: 0.003239881402502457\n",
      "-------epoch  327 -------\n",
      "train set Loss: 0.006660018274851609\n",
      "val set Loss: 0.003725353667202095\n",
      "-------epoch  328 -------\n",
      "train set Loss: 0.0055853187359753064\n",
      "val set Loss: 0.00297086294934464\n",
      "-------epoch  329 -------\n",
      "train set Loss: 0.005180114273243817\n",
      "val set Loss: 0.003246378260276591\n",
      "-------epoch  330 -------\n",
      "train set Loss: 0.0049037374395993535\n",
      "val set Loss: 0.0029501631846263385\n",
      "-------epoch  331 -------\n",
      "train set Loss: 0.005282775398227386\n",
      "val set Loss: 0.003438669751631096\n",
      "-------epoch  332 -------\n",
      "train set Loss: 0.0050510612534708345\n",
      "val set Loss: 0.002948791351324568\n",
      "-------epoch  333 -------\n",
      "train set Loss: 0.0056656238081632185\n",
      "val set Loss: 0.004022714643118282\n",
      "-------epoch  334 -------\n",
      "train set Loss: 0.005326294957485516\n",
      "val set Loss: 0.003126175007006774\n",
      "-------epoch  335 -------\n",
      "train set Loss: 0.006319684134505224\n",
      "val set Loss: 0.0037642973378145448\n",
      "-------epoch  336 -------\n",
      "train set Loss: 0.005341321405139752\n",
      "val set Loss: 0.003776195323249946\n",
      "-------epoch  337 -------\n",
      "train set Loss: 0.0057448458706494425\n",
      "val set Loss: 0.005823108600452542\n",
      "-------epoch  338 -------\n",
      "train set Loss: 0.006036218949302566\n",
      "val set Loss: 0.003719611772491286\n",
      "-------epoch  339 -------\n",
      "train set Loss: 0.005193862732558046\n",
      "val set Loss: 0.0031361552925469973\n",
      "-------epoch  340 -------\n",
      "train set Loss: 0.004816753447812516\n",
      "val set Loss: 0.0037686977496681115\n",
      "-------epoch  341 -------\n",
      "train set Loss: 0.0047264567113597875\n",
      "val set Loss: 0.002967004678794183\n",
      "-------epoch  342 -------\n",
      "train set Loss: 0.004706694933120161\n",
      "val set Loss: 0.009107823823190605\n",
      "-------epoch  343 -------\n",
      "train set Loss: 0.00525679027341539\n",
      "val set Loss: 0.004660316713852808\n",
      "-------epoch  344 -------\n",
      "train set Loss: 0.00550293821725063\n",
      "val set Loss: 0.0038550630949127176\n",
      "-------epoch  345 -------\n",
      "train set Loss: 0.00600949319137726\n",
      "val set Loss: 0.00416304594061027\n",
      "-------epoch  346 -------\n",
      "train set Loss: 0.006186024511407595\n",
      "val set Loss: 0.0028559155374144516\n",
      "-------epoch  347 -------\n",
      "train set Loss: 0.0060130638195551\n",
      "val set Loss: 0.003095675929216668\n",
      "-------epoch  348 -------\n",
      "train set Loss: 0.004944453229545616\n",
      "val set Loss: 0.00776796427089721\n",
      "-------epoch  349 -------\n",
      "train set Loss: 0.005783285343786701\n",
      "val set Loss: 0.0031204628855145224\n",
      "-------epoch  350 -------\n",
      "train set Loss: 0.006295009689929429\n",
      "val set Loss: 0.005510002025403082\n",
      "-------epoch  351 -------\n",
      "train set Loss: 0.0058359133341582495\n",
      "val set Loss: 0.004795578638246904\n",
      "-------epoch  352 -------\n",
      "train set Loss: 0.004342738292180002\n",
      "val set Loss: 0.0032272651830377677\n",
      "-------epoch  353 -------\n",
      "train set Loss: 0.004170139423222281\n",
      "val set Loss: 0.0192439341917634\n",
      "-------epoch  354 -------\n",
      "train set Loss: 0.00489833606290631\n",
      "val set Loss: 0.0031428092916030437\n",
      "-------epoch  355 -------\n",
      "train set Loss: 0.005444011473446153\n",
      "val set Loss: 0.005751897716739525\n",
      "-------epoch  356 -------\n",
      "train set Loss: 0.005324215046130121\n",
      "val set Loss: 0.004360071926688154\n",
      "-------epoch  357 -------\n",
      "train set Loss: 0.007391364480718039\n",
      "val set Loss: 0.009687231775994102\n",
      "-------epoch  358 -------\n",
      "train set Loss: 0.005901561884675175\n",
      "val set Loss: 0.006225030675219993\n",
      "-------epoch  359 -------\n",
      "train set Loss: 0.008305345138651318\n",
      "val set Loss: 0.034576023501964905\n",
      "-------epoch  360 -------\n",
      "train set Loss: 0.005958118132548406\n",
      "val set Loss: 0.004351389633181195\n",
      "-------epoch  361 -------\n",
      "train set Loss: 0.006503342212527059\n",
      "val set Loss: 0.021717536204960197\n",
      "-------epoch  362 -------\n",
      "train set Loss: 0.005286077322089113\n",
      "val set Loss: 0.003230544384374904\n",
      "-------epoch  363 -------\n",
      "train set Loss: 0.005247046983567998\n",
      "val set Loss: 0.006525203779650231\n",
      "-------epoch  364 -------\n",
      "train set Loss: 0.005487358382088132\n",
      "val set Loss: 0.012617749137765108\n",
      "-------epoch  365 -------\n",
      "train set Loss: 0.004656715943710878\n",
      "val set Loss: 0.00419315571586291\n",
      "-------epoch  366 -------\n",
      "train set Loss: 0.0052616585150826725\n",
      "val set Loss: 0.002740850148256868\n",
      "-------epoch  367 -------\n",
      "train set Loss: 0.003928824778704439\n",
      "val set Loss: 0.0036719066362517574\n",
      "-------epoch  368 -------\n",
      "train set Loss: 0.0039199511165497825\n",
      "val set Loss: 0.002998857817146927\n",
      "-------epoch  369 -------\n",
      "train set Loss: 0.004427755622164114\n",
      "val set Loss: 0.004584006761433557\n",
      "-------epoch  370 -------\n",
      "train set Loss: 0.005428352838789579\n",
      "val set Loss: 0.004825873397445927\n",
      "-------epoch  371 -------\n",
      "train set Loss: 0.007491633978206664\n",
      "val set Loss: 0.01004392640121902\n",
      "-------epoch  372 -------\n",
      "train set Loss: 0.006144079849182162\n",
      "val set Loss: 0.005424686125479639\n",
      "-------epoch  373 -------\n",
      "train set Loss: 0.04843630153976847\n",
      "val set Loss: 0.005716886410179238\n",
      "-------epoch  374 -------\n",
      "train set Loss: 0.06085862160223769\n",
      "val set Loss: 0.010984846157953143\n",
      "-------epoch  375 -------\n",
      "train set Loss: 0.017767806224583182\n",
      "val set Loss: 0.012673505581915379\n",
      "-------epoch  376 -------\n",
      "train set Loss: 0.02726521075470373\n",
      "val set Loss: 0.005604514308894674\n",
      "-------epoch  377 -------\n",
      "train set Loss: 0.021300910491263494\n",
      "val set Loss: 0.02168412258227666\n",
      "-------epoch  378 -------\n",
      "train set Loss: 0.01735271680285223\n",
      "val set Loss: 0.01406916322108979\n",
      "-------epoch  379 -------\n",
      "train set Loss: 0.009681751360185445\n",
      "val set Loss: 0.008104837499558926\n",
      "-------epoch  380 -------\n",
      "train set Loss: 0.00793562752311118\n",
      "val set Loss: 0.005082049174234271\n",
      "-------epoch  381 -------\n",
      "train set Loss: 0.006573852596920915\n",
      "val set Loss: 0.004299218339535098\n",
      "-------epoch  382 -------\n",
      "train set Loss: 0.005428776285843924\n",
      "val set Loss: 0.0026042558796082935\n",
      "-------epoch  383 -------\n",
      "train set Loss: 0.007464907946850872\n",
      "val set Loss: 0.0031493840603313097\n",
      "-------epoch  384 -------\n",
      "train set Loss: 0.006924269226146862\n",
      "val set Loss: 0.012355804676190019\n",
      "-------epoch  385 -------\n",
      "train set Loss: 0.006357887511258014\n",
      "val set Loss: 0.0033473314251750708\n",
      "-------epoch  386 -------\n",
      "train set Loss: 0.005465174218261382\n",
      "val set Loss: 0.003153499341957892\n",
      "-------epoch  387 -------\n",
      "train set Loss: 0.004830136606178712\n",
      "val set Loss: 0.0026919205605130023\n",
      "-------epoch  388 -------\n",
      "train set Loss: 0.0043868369908886965\n",
      "val set Loss: 0.004421576615034913\n",
      "-------epoch  389 -------\n",
      "train set Loss: 0.004349707805376965\n",
      "val set Loss: 0.0028843004644537964\n",
      "-------epoch  390 -------\n",
      "train set Loss: 0.006149163455411326\n",
      "val set Loss: 0.005470780888572335\n",
      "-------epoch  391 -------\n",
      "train set Loss: 0.008062038657662925\n",
      "val set Loss: 0.0028110833518439904\n",
      "-------epoch  392 -------\n",
      "train set Loss: 0.005858168761769775\n",
      "val set Loss: 0.008813192621649554\n",
      "-------epoch  393 -------\n",
      "train set Loss: 0.006234977057320065\n",
      "val set Loss: 0.0035734670139693967\n",
      "-------epoch  394 -------\n",
      "train set Loss: 0.0065966341318562625\n",
      "val set Loss: 0.005129789390290777\n",
      "-------epoch  395 -------\n",
      "train set Loss: 0.005797815892728977\n",
      "val set Loss: 0.0031922210667592785\n",
      "-------epoch  396 -------\n",
      "train set Loss: 0.004982740812556586\n",
      "val set Loss: 0.0036683595293046287\n",
      "-------epoch  397 -------\n",
      "train set Loss: 0.004557937663048506\n",
      "val set Loss: 0.0027061639363334202\n",
      "-------epoch  398 -------\n",
      "train set Loss: 0.004179594026063569\n",
      "val set Loss: 0.002778336852012823\n",
      "-------epoch  399 -------\n",
      "train set Loss: 0.004128335046116263\n",
      "val set Loss: 0.00292711037521561\n",
      "-------epoch  400 -------\n",
      "train set Loss: 0.003982576287235133\n",
      "val set Loss: 0.002780979518623402\n",
      "-------epoch  401 -------\n",
      "train set Loss: 0.004052173470554408\n",
      "val set Loss: 0.0028516947447011867\n",
      "-------epoch  402 -------\n",
      "train set Loss: 0.004104350137567963\n",
      "val set Loss: 0.0027854681635896363\n",
      "-------epoch  403 -------\n",
      "train set Loss: 0.005099370611133054\n",
      "val set Loss: 0.0027968445792794228\n",
      "-------epoch  404 -------\n",
      "train set Loss: 0.005446756649253075\n",
      "val set Loss: 0.005414542625658214\n",
      "-------epoch  405 -------\n",
      "train set Loss: 0.005270052677369677\n",
      "val set Loss: 0.002719122596317902\n",
      "-------epoch  406 -------\n",
      "train set Loss: 0.0049789209346636195\n",
      "val set Loss: 0.004604077684537818\n",
      "-------epoch  407 -------\n",
      "train set Loss: 0.004195697765389923\n",
      "val set Loss: 0.002764889946168599\n",
      "-------epoch  408 -------\n",
      "train set Loss: 0.004003821164660621\n",
      "val set Loss: 0.0045444751061343895\n",
      "-------epoch  409 -------\n",
      "train set Loss: 0.0041891480970662085\n",
      "val set Loss: 0.003310760095094641\n",
      "-------epoch  410 -------\n",
      "train set Loss: 0.005083588078268804\n",
      "val set Loss: 0.0042837809305638075\n",
      "-------epoch  411 -------\n",
      "train set Loss: 0.004639658154337667\n",
      "val set Loss: 0.0028462680832793317\n",
      "-------epoch  412 -------\n",
      "train set Loss: 0.005017735322471708\n",
      "val set Loss: 0.005544715541570137\n",
      "-------epoch  413 -------\n",
      "train set Loss: 0.004061408772540745\n",
      "val set Loss: 0.003065246171900071\n",
      "-------epoch  414 -------\n",
      "train set Loss: 0.004443329364876263\n",
      "val set Loss: 0.004292931630819415\n",
      "-------epoch  415 -------\n",
      "train set Loss: 0.004200735599442851\n",
      "val set Loss: 0.0027648254666322223\n",
      "-------epoch  416 -------\n",
      "train set Loss: 0.004714181884337449\n",
      "val set Loss: 0.004537074904267986\n",
      "-------epoch  417 -------\n",
      "train set Loss: 0.004202317907474935\n",
      "val set Loss: 0.002860003281966783\n",
      "-------epoch  418 -------\n",
      "train set Loss: 0.004364840256166644\n",
      "val set Loss: 0.00557161927766477\n",
      "-------epoch  419 -------\n",
      "train set Loss: 0.004360305943409912\n",
      "val set Loss: 0.003238525406535094\n",
      "-------epoch  420 -------\n",
      "train set Loss: 0.005373743559030118\n",
      "val set Loss: 0.004986829512442152\n",
      "-------epoch  421 -------\n",
      "train set Loss: 0.004917130788380746\n",
      "val set Loss: 0.0028319645789451897\n",
      "-------epoch  422 -------\n",
      "train set Loss: 0.00473418873938499\n",
      "val set Loss: 0.00475005049762937\n",
      "-------epoch  423 -------\n",
      "train set Loss: 0.00407501033419976\n",
      "val set Loss: 0.0032077915287421397\n",
      "-------epoch  424 -------\n",
      "train set Loss: 0.003891608559933957\n",
      "val set Loss: 0.0035286815157936267\n",
      "-------epoch  425 -------\n",
      "train set Loss: 0.004121776931206114\n",
      "val set Loss: 0.003383128651573012\n",
      "-------epoch  426 -------\n",
      "train set Loss: 0.004316988080390729\n",
      "val set Loss: 0.004193445308677231\n",
      "-------epoch  427 -------\n",
      "train set Loss: 0.004804565800586715\n",
      "val set Loss: 0.0026974843349307775\n",
      "-------epoch  428 -------\n",
      "train set Loss: 0.005225371047854424\n",
      "val set Loss: 0.004559742674852411\n",
      "-------epoch  429 -------\n",
      "train set Loss: 0.004121032576658763\n",
      "val set Loss: 0.002888378124528875\n",
      "-------epoch  430 -------\n",
      "train set Loss: 0.0036917545562027954\n",
      "val set Loss: 0.004606112993011872\n",
      "-------epoch  431 -------\n",
      "train set Loss: 0.004249789327150211\n",
      "val set Loss: 0.0027613705557693415\n",
      "-------epoch  432 -------\n",
      "train set Loss: 0.0048004423626116476\n",
      "val set Loss: 0.0068571120500564575\n",
      "-------epoch  433 -------\n",
      "train set Loss: 0.00468236377928406\n",
      "val set Loss: 0.002906261390307918\n",
      "-------epoch  434 -------\n",
      "train set Loss: 0.005336623428447638\n",
      "val set Loss: 0.006178203388117254\n",
      "-------epoch  435 -------\n",
      "train set Loss: 0.004573580816795584\n",
      "val set Loss: 0.003095562142940859\n",
      "-------epoch  436 -------\n",
      "train set Loss: 0.004447571531054564\n",
      "val set Loss: 0.005639973950261871\n",
      "-------epoch  437 -------\n",
      "train set Loss: 0.0042721139689092524\n",
      "val set Loss: 0.003459926665527746\n",
      "-------epoch  438 -------\n",
      "train set Loss: 0.005064816442609299\n",
      "val set Loss: 0.0042057578296711045\n",
      "-------epoch  439 -------\n",
      "train set Loss: 0.004291258662124165\n",
      "val set Loss: 0.002788033149651407\n",
      "-------epoch  440 -------\n",
      "train set Loss: 0.00403642379125813\n",
      "val set Loss: 0.004051385360071436\n",
      "-------epoch  441 -------\n",
      "train set Loss: 0.003913767626218032\n",
      "val set Loss: 0.0032503549688650915\n",
      "-------epoch  442 -------\n",
      "train set Loss: 0.004972086362540722\n",
      "val set Loss: 0.005387864075601101\n",
      "-------epoch  443 -------\n",
      "train set Loss: 0.00422592035960406\n",
      "val set Loss: 0.00287456593165795\n",
      "-------epoch  444 -------\n",
      "train set Loss: 0.004934132828202565\n",
      "val set Loss: 0.008683457466152808\n",
      "-------epoch  445 -------\n",
      "train set Loss: 0.004623846084577963\n",
      "val set Loss: 0.0027740332055448866\n",
      "-------epoch  446 -------\n",
      "train set Loss: 0.005398534919368103\n",
      "val set Loss: 0.006376958219334483\n",
      "-------epoch  447 -------\n",
      "train set Loss: 0.005053157450747676\n",
      "val set Loss: 0.003269610354133571\n",
      "-------epoch  448 -------\n",
      "train set Loss: 0.0046497526086750444\n",
      "val set Loss: 0.0056126474373741075\n",
      "-------epoch  449 -------\n",
      "train set Loss: 0.004431241173879243\n",
      "val set Loss: 0.00288666980486596\n",
      "-------epoch  450 -------\n",
      "train set Loss: 0.00435721494795871\n",
      "val set Loss: 0.005699030322527203\n",
      "-------epoch  451 -------\n",
      "train set Loss: 0.004427339528338053\n",
      "val set Loss: 0.003246214871372407\n",
      "-------epoch  452 -------\n",
      "train set Loss: 0.0050125239844783205\n",
      "val set Loss: 0.004555004745877038\n",
      "-------epoch  453 -------\n",
      "train set Loss: 0.004101804581587203\n",
      "val set Loss: 0.0031269536848412827\n",
      "-------epoch  454 -------\n",
      "train set Loss: 0.003956867370870896\n",
      "val set Loss: 0.004458513139979914\n",
      "-------epoch  455 -------\n",
      "train set Loss: 0.0038268667500233277\n",
      "val set Loss: 0.0028667243605013937\n",
      "-------epoch  456 -------\n",
      "train set Loss: 0.004533132671058411\n",
      "val set Loss: 0.005008526903111488\n",
      "-------epoch  457 -------\n",
      "train set Loss: 0.004167260767426342\n",
      "val set Loss: 0.0026389376531975963\n",
      "-------epoch  458 -------\n",
      "train set Loss: 0.003960014752810821\n",
      "val set Loss: 0.004457248675559337\n",
      "-------epoch  459 -------\n",
      "train set Loss: 0.00347728188498877\n",
      "val set Loss: 0.0028157313354313374\n",
      "-------epoch  460 -------\n",
      "train set Loss: 0.0033713524820632302\n",
      "val set Loss: 0.007402902381727472\n",
      "-------epoch  461 -------\n",
      "train set Loss: 0.003555188950849697\n",
      "val set Loss: 0.0027707133073514947\n",
      "-------epoch  462 -------\n",
      "train set Loss: 0.004372899460577173\n",
      "val set Loss: 0.003439077700022608\n",
      "-------epoch  463 -------\n",
      "train set Loss: 0.004094948405690957\n",
      "val set Loss: 0.0030637751042377204\n",
      "-------epoch  464 -------\n",
      "train set Loss: 0.003914512317860499\n",
      "val set Loss: 0.003141532249477071\n",
      "-------epoch  465 -------\n",
      "train set Loss: 0.003979080503049772\n",
      "val set Loss: 0.003872477497983103\n",
      "-------epoch  466 -------\n",
      "train set Loss: 0.003893198195146397\n",
      "val set Loss: 0.004023243207484484\n",
      "-------epoch  467 -------\n",
      "train set Loss: 0.0028237591733341104\n",
      "val set Loss: 0.010516149709777286\n",
      "-------epoch  468 -------\n",
      "train set Loss: 0.004021304277703166\n",
      "val set Loss: 0.002936479305693259\n",
      "-------epoch  469 -------\n",
      "train set Loss: 0.004178384314873256\n",
      "val set Loss: 0.0030583203867233046\n",
      "-------epoch  470 -------\n",
      "train set Loss: 0.003650487936101854\n",
      "val set Loss: 0.002781890817762663\n",
      "-------epoch  471 -------\n",
      "train set Loss: 0.0044162520600366404\n",
      "val set Loss: 0.002895635067640493\n",
      "-------epoch  472 -------\n",
      "train set Loss: 0.00689929499902064\n",
      "val set Loss: 0.003014214181651672\n",
      "-------epoch  473 -------\n",
      "train set Loss: 0.006692701636929996\n",
      "val set Loss: 0.0033046478832451007\n",
      "-------epoch  474 -------\n",
      "train set Loss: 0.004198176831996534\n",
      "val set Loss: 0.00278788706054911\n",
      "-------epoch  475 -------\n",
      "train set Loss: 0.00421101841260679\n",
      "val set Loss: 0.003959310910431668\n",
      "-------epoch  476 -------\n",
      "train set Loss: 0.004982164055691101\n",
      "val set Loss: 0.003861463201853136\n",
      "-------epoch  477 -------\n",
      "train set Loss: 0.005629700543940999\n",
      "val set Loss: 0.007287347475842883\n",
      "-------epoch  478 -------\n",
      "train set Loss: 0.004750205663731322\n",
      "val set Loss: 0.004181394062470645\n",
      "-------epoch  479 -------\n",
      "train set Loss: 0.003993390637042467\n",
      "val set Loss: 0.008943114099868884\n",
      "-------epoch  480 -------\n",
      "train set Loss: 0.004859007829800248\n",
      "val set Loss: 0.004075643354250739\n",
      "-------epoch  481 -------\n",
      "train set Loss: 0.005241334178717807\n",
      "val set Loss: 0.0032580637489445508\n",
      "-------epoch  482 -------\n",
      "train set Loss: 0.0035295283852610736\n",
      "val set Loss: 0.003090405016943502\n",
      "-------epoch  483 -------\n",
      "train set Loss: 0.003756812000356149\n",
      "val set Loss: 0.007259688475945343\n",
      "-------epoch  484 -------\n",
      "train set Loss: 0.004224241724296007\n",
      "val set Loss: 0.0030739950210166476\n",
      "-------epoch  485 -------\n",
      "train set Loss: 0.00524303616664838\n",
      "val set Loss: 0.04224397203264137\n",
      "-------epoch  486 -------\n",
      "train set Loss: 0.005487545697833412\n",
      "val set Loss: 0.00332114136350962\n",
      "-------epoch  487 -------\n",
      "train set Loss: 0.005875837845087517\n",
      "val set Loss: 0.007950335818653306\n",
      "-------epoch  488 -------\n",
      "train set Loss: 0.004226222764409613\n",
      "val set Loss: 0.0032360601665762565\n",
      "-------epoch  489 -------\n",
      "train set Loss: 0.0040620318092987875\n",
      "val set Loss: 0.007299815789641191\n",
      "-------epoch  490 -------\n",
      "train set Loss: 0.003807584188180044\n",
      "val set Loss: 0.003330477047711611\n",
      "-------epoch  491 -------\n",
      "train set Loss: 0.004286490670056082\n",
      "val set Loss: 0.010218058518754939\n",
      "-------epoch  492 -------\n",
      "train set Loss: 0.004305128499981947\n",
      "val set Loss: 0.004053771709247182\n",
      "-------epoch  493 -------\n",
      "train set Loss: 0.00454932775173802\n",
      "val set Loss: 0.018874142920443166\n",
      "-------epoch  494 -------\n",
      "train set Loss: 0.004695916530909017\n",
      "val set Loss: 0.005200832825115261\n",
      "-------epoch  495 -------\n",
      "train set Loss: 0.0040231797724845815\n",
      "val set Loss: 0.010489300242625177\n",
      "-------epoch  496 -------\n",
      "train set Loss: 0.003616550176520832\n",
      "val set Loss: 0.005187359754927456\n",
      "-------epoch  497 -------\n",
      "train set Loss: 0.003429212071059737\n",
      "val set Loss: 0.016121780732646585\n",
      "-------epoch  498 -------\n",
      "train set Loss: 0.0034784612085786647\n",
      "val set Loss: 0.004606156377121806\n",
      "-------epoch  499 -------\n",
      "train set Loss: 0.00502966717001982\n",
      "val set Loss: 0.0029142291944784424\n",
      "-------epoch  500 -------\n",
      "train set Loss: 0.0038580102738342247\n",
      "val set Loss: 0.0027344474995819232\n",
      "-------epoch  501 -------\n",
      "train set Loss: 0.004260512636101339\n",
      "val set Loss: 0.0032886294454025724\n",
      "-------epoch  502 -------\n",
      "train set Loss: 0.003730388858093647\n",
      "val set Loss: 0.002842337805001686\n",
      "-------epoch  503 -------\n",
      "train set Loss: 0.003416573272988899\n",
      "val set Loss: 0.0033698465170649192\n",
      "-------epoch  504 -------\n",
      "train set Loss: 0.0035282970854314043\n",
      "val set Loss: 0.0032924083207035437\n",
      "-------epoch  505 -------\n",
      "train set Loss: 0.0034949963880353606\n",
      "val set Loss: 0.005859493374979745\n",
      "-------epoch  506 -------\n",
      "train set Loss: 0.0041385507385712115\n",
      "val set Loss: 0.006251207640161738\n",
      "-------epoch  507 -------\n",
      "train set Loss: 0.0034302372872480193\n",
      "val set Loss: 0.02541214699158445\n",
      "-------epoch  508 -------\n",
      "train set Loss: 0.003756306916475296\n",
      "val set Loss: 0.003017243337429439\n",
      "-------epoch  509 -------\n",
      "train set Loss: 0.00383558967965655\n",
      "val set Loss: 0.0030181654243885228\n",
      "-------epoch  510 -------\n",
      "train set Loss: 0.0035735713990288787\n",
      "val set Loss: 0.002639478218043223\n",
      "-------epoch  511 -------\n",
      "train set Loss: 0.0029845791377010756\n",
      "val set Loss: 0.002668645145604387\n",
      "-------epoch  512 -------\n",
      "train set Loss: 0.0031097984287771397\n",
      "val set Loss: 0.003926415811292827\n",
      "-------epoch  513 -------\n",
      "train set Loss: 0.0035618492317735216\n",
      "val set Loss: 0.003005697343420858\n",
      "-------epoch  514 -------\n",
      "train set Loss: 0.005068377933930605\n",
      "val set Loss: 0.011498112774764499\n",
      "-------epoch  515 -------\n",
      "train set Loss: 0.005219617296243087\n",
      "val set Loss: 0.00691112633406495\n",
      "-------epoch  516 -------\n",
      "train set Loss: 0.0034534594285651112\n",
      "val set Loss: 0.005197133568193142\n",
      "-------epoch  517 -------\n",
      "train set Loss: 0.0026025895157363267\n",
      "val set Loss: 0.006030545647566517\n",
      "-------epoch  518 -------\n",
      "train set Loss: 0.002655443896655925\n",
      "val set Loss: 0.004237287153955549\n",
      "-------epoch  519 -------\n",
      "train set Loss: 0.003620177885168232\n",
      "val set Loss: 0.0038276132642446705\n",
      "-------epoch  520 -------\n",
      "train set Loss: 0.002832599423127249\n",
      "val set Loss: 0.004479248173690091\n",
      "-------epoch  521 -------\n",
      "train set Loss: 0.003411109015432885\n",
      "val set Loss: 0.005178671582446744\n",
      "-------epoch  522 -------\n",
      "train set Loss: 0.002841191657644231\n",
      "val set Loss: 0.004927179814937214\n",
      "-------epoch  523 -------\n",
      "train set Loss: 0.003259802583488636\n",
      "val set Loss: 0.005128600843211946\n",
      "-------epoch  524 -------\n",
      "train set Loss: 0.0026635529634950216\n",
      "val set Loss: 0.00906420340955568\n",
      "-------epoch  525 -------\n",
      "train set Loss: 0.002877928210073151\n",
      "val set Loss: 0.0077329005871433765\n",
      "-------epoch  526 -------\n",
      "train set Loss: 0.003929521901300177\n",
      "val set Loss: 0.009302107384428382\n",
      "-------epoch  527 -------\n",
      "train set Loss: 0.0037318629046785646\n",
      "val set Loss: 0.010936839894081155\n",
      "-------epoch  528 -------\n",
      "train set Loss: 0.0047822195457411\n",
      "val set Loss: 0.012005665494749943\n",
      "-------epoch  529 -------\n",
      "train set Loss: 0.0030423150747083127\n",
      "val set Loss: 0.010953368619084358\n",
      "-------epoch  530 -------\n",
      "train set Loss: 0.0028413753371569327\n",
      "val set Loss: 0.005973796525116389\n",
      "-------epoch  531 -------\n",
      "train set Loss: 0.0024708105938043446\n",
      "val set Loss: 0.013787037780275568\n",
      "-------epoch  532 -------\n",
      "train set Loss: 0.003031657758401707\n",
      "val set Loss: 0.0049551178235560656\n",
      "-------epoch  533 -------\n",
      "train set Loss: 0.0040026627155020835\n",
      "val set Loss: 0.021423724091922242\n",
      "-------epoch  534 -------\n",
      "train set Loss: 0.0065085308405105026\n",
      "val set Loss: 0.006979766728666921\n",
      "-------epoch  535 -------\n",
      "train set Loss: 0.004742849604808725\n",
      "val set Loss: 0.004576585837639868\n",
      "-------epoch  536 -------\n",
      "train set Loss: 0.003821891536936164\n",
      "val set Loss: 0.016144971828907728\n",
      "-------epoch  537 -------\n",
      "train set Loss: 0.004285992643563077\n",
      "val set Loss: 0.0072446337435394526\n",
      "-------epoch  538 -------\n",
      "train set Loss: 0.005177859423565678\n",
      "val set Loss: 0.003808297410917779\n",
      "-------epoch  539 -------\n",
      "train set Loss: 0.0037025261466624216\n",
      "val set Loss: 0.0028550375233559557\n",
      "-------epoch  540 -------\n",
      "train set Loss: 0.0037309917763923297\n",
      "val set Loss: 0.00384150537623403\n",
      "-------epoch  541 -------\n",
      "train set Loss: 0.0037644374409865123\n",
      "val set Loss: 0.0031824144340741136\n",
      "-------epoch  542 -------\n",
      "train set Loss: 0.004929331860912498\n",
      "val set Loss: 0.004542583289245765\n",
      "-------epoch  543 -------\n",
      "train set Loss: 0.006284677151124924\n",
      "val set Loss: 0.006274163994627695\n",
      "-------epoch  544 -------\n",
      "train set Loss: 0.005364214784349315\n",
      "val set Loss: 0.009355971744904915\n",
      "-------epoch  545 -------\n",
      "train set Loss: 0.006492424085736275\n",
      "val set Loss: 0.01653108260749529\n",
      "-------epoch  546 -------\n",
      "train set Loss: 0.004118767741601914\n",
      "val set Loss: 0.0028585355709462115\n",
      "-------epoch  547 -------\n",
      "train set Loss: 0.0042868379660649224\n",
      "val set Loss: 0.003910116395369793\n",
      "-------epoch  548 -------\n",
      "train set Loss: 0.003695176373003051\n",
      "val set Loss: 0.008586850366555154\n",
      "-------epoch  549 -------\n",
      "train set Loss: 0.003698255292256363\n",
      "val set Loss: 0.003886368707753718\n",
      "-------epoch  550 -------\n",
      "train set Loss: 0.004121420618321281\n",
      "val set Loss: 0.02171090364572592\n",
      "-------epoch  551 -------\n",
      "train set Loss: 0.005053209637408145\n",
      "val set Loss: 0.005577803938649595\n",
      "-------epoch  552 -------\n",
      "train set Loss: 0.005787477848352865\n",
      "val set Loss: 0.0032268986687995493\n",
      "-------epoch  553 -------\n",
      "train set Loss: 0.004737209746381268\n",
      "val set Loss: 0.004925551785466571\n",
      "-------epoch  554 -------\n",
      "train set Loss: 0.00483519232366234\n",
      "val set Loss: 0.003028895085056623\n",
      "-------epoch  555 -------\n",
      "train set Loss: 0.003823505643522367\n",
      "val set Loss: 0.003422062892544394\n",
      "-------epoch  556 -------\n",
      "train set Loss: 0.003915590382239316\n",
      "val set Loss: 0.0031436612577332803\n",
      "-------epoch  557 -------\n",
      "train set Loss: 0.0035754502727650106\n",
      "val set Loss: 0.003336470059972877\n",
      "-------epoch  558 -------\n",
      "train set Loss: 0.0032365159585606307\n",
      "val set Loss: 0.004515495054268588\n",
      "-------epoch  559 -------\n",
      "train set Loss: 0.003526812344789505\n",
      "val set Loss: 0.0056498724249346806\n",
      "-------epoch  560 -------\n",
      "train set Loss: 0.0039633281825808804\n",
      "val set Loss: 0.016895717883016914\n",
      "-------epoch  561 -------\n",
      "train set Loss: 0.005492515421356075\n",
      "val set Loss: 0.00332337872532662\n",
      "-------epoch  562 -------\n",
      "train set Loss: 0.00474711288290564\n",
      "val set Loss: 0.003157193869507561\n",
      "-------epoch  563 -------\n",
      "train set Loss: 0.0034993752470472827\n",
      "val set Loss: 0.002978776271144549\n",
      "-------epoch  564 -------\n",
      "train set Loss: 0.0033678869897266848\n",
      "val set Loss: 0.0030912623818342886\n",
      "-------epoch  565 -------\n",
      "train set Loss: 0.0032711875176755713\n",
      "val set Loss: 0.005093395089109738\n",
      "-------epoch  566 -------\n",
      "train set Loss: 0.0032067262893542645\n",
      "val set Loss: 0.0035114939285752675\n",
      "-------epoch  567 -------\n",
      "train set Loss: 0.002873022862477228\n",
      "val set Loss: 0.00521335673208038\n",
      "-------epoch  568 -------\n",
      "train set Loss: 0.0036034890240989625\n",
      "val set Loss: 0.003511177080023723\n",
      "-------epoch  569 -------\n",
      "train set Loss: 0.0039093800846603695\n",
      "val set Loss: 0.005345395106511812\n",
      "-------epoch  570 -------\n",
      "train set Loss: 0.00409786831587553\n",
      "val set Loss: 0.00456917214129741\n",
      "-------epoch  571 -------\n",
      "train set Loss: 0.0043805046333000065\n",
      "val set Loss: 0.013510525071372589\n",
      "-------epoch  572 -------\n",
      "train set Loss: 0.003030918872682378\n",
      "val set Loss: 0.006710724934237078\n",
      "-------epoch  573 -------\n",
      "train set Loss: 0.002636841351049952\n",
      "val set Loss: 0.006442121433792636\n",
      "-------epoch  574 -------\n",
      "train set Loss: 0.0027571223146514966\n",
      "val set Loss: 0.004597018259422232\n",
      "-------epoch  575 -------\n",
      "train set Loss: 0.0025932634303171653\n",
      "val set Loss: 0.004759114158029358\n",
      "-------epoch  576 -------\n",
      "train set Loss: 0.002681634781183675\n",
      "val set Loss: 0.00379799732278722\n",
      "-------epoch  577 -------\n",
      "train set Loss: 0.002088184321910376\n",
      "val set Loss: 0.0036868011423697076\n",
      "-------epoch  578 -------\n",
      "train set Loss: 0.002174774120794609\n",
      "val set Loss: 0.0038071448992316923\n",
      "-------epoch  579 -------\n",
      "train set Loss: 0.002389215157018043\n",
      "val set Loss: 0.005031495665510495\n",
      "-------epoch  580 -------\n",
      "train set Loss: 0.0024229574808850886\n",
      "val set Loss: 0.00507742502183343\n",
      "-------epoch  581 -------\n",
      "train set Loss: 0.0035242714489868376\n",
      "val set Loss: 0.006956215812048565\n",
      "-------epoch  582 -------\n",
      "train set Loss: 0.003355578586924821\n",
      "val set Loss: 0.005405967453649889\n",
      "-------epoch  583 -------\n",
      "train set Loss: 0.0035573323725839145\n",
      "val set Loss: 0.007572674085774149\n",
      "-------epoch  584 -------\n",
      "train set Loss: 0.002900170182110742\n",
      "val set Loss: 0.004637783213790196\n",
      "-------epoch  585 -------\n",
      "train set Loss: 0.0027795781382883434\n",
      "val set Loss: 0.005058331027006109\n",
      "-------epoch  586 -------\n",
      "train set Loss: 0.0030664278761832974\n",
      "val set Loss: 0.0038916228756230944\n",
      "-------epoch  587 -------\n",
      "train set Loss: 0.0024154004859155975\n",
      "val set Loss: 0.004292596073355526\n",
      "-------epoch  588 -------\n",
      "train set Loss: 0.00247808382337098\n",
      "val set Loss: 0.003554844554552498\n",
      "-------epoch  589 -------\n",
      "train set Loss: 0.002082487004227005\n",
      "val set Loss: 0.003818657035784175\n",
      "-------epoch  590 -------\n",
      "train set Loss: 0.002185534488526173\n",
      "val set Loss: 0.004375422693556175\n",
      "-------epoch  591 -------\n",
      "train set Loss: 0.002797861485159956\n",
      "val set Loss: 0.006348296476062387\n",
      "-------epoch  592 -------\n",
      "train set Loss: 0.0026497231831308452\n",
      "val set Loss: 0.005019037547754124\n",
      "-------epoch  593 -------\n",
      "train set Loss: 0.003992275134078227\n",
      "val set Loss: 0.007930132880574092\n",
      "-------epoch  594 -------\n",
      "train set Loss: 0.0037849839398404585\n",
      "val set Loss: 0.004850839652741949\n",
      "-------epoch  595 -------\n",
      "train set Loss: 0.002890072506852448\n",
      "val set Loss: 0.006069404732746382\n",
      "-------epoch  596 -------\n",
      "train set Loss: 0.0026791536761447787\n",
      "val set Loss: 0.003973290654054533\n",
      "-------epoch  597 -------\n",
      "train set Loss: 0.002366160467208829\n",
      "val set Loss: 0.004263807670213282\n",
      "-------epoch  598 -------\n",
      "train set Loss: 0.002335524579684716\n",
      "val set Loss: 0.0037479125312529504\n",
      "-------epoch  599 -------\n",
      "train set Loss: 0.0019995025626849384\n",
      "val set Loss: 0.0037621153169311583\n",
      "-------epoch  600 -------\n",
      "train set Loss: 0.002069563737750286\n",
      "val set Loss: 0.003693590969002495\n",
      "-------epoch  601 -------\n",
      "train set Loss: 0.0022330675645207522\n",
      "val set Loss: 0.004407416679896414\n",
      "-------epoch  602 -------\n",
      "train set Loss: 0.002623748976911884\n",
      "val set Loss: 0.0051040791246729595\n",
      "-------epoch  603 -------\n",
      "train set Loss: 0.004786818335705902\n",
      "val set Loss: 0.010640332902160784\n",
      "-------epoch  604 -------\n",
      "train set Loss: 0.003912030452338513\n",
      "val set Loss: 0.005561824752173076\n",
      "-------epoch  605 -------\n",
      "train set Loss: 0.0034678956991410813\n",
      "val set Loss: 0.008416168537223712\n",
      "-------epoch  606 -------\n",
      "train set Loss: 0.002840073888655752\n",
      "val set Loss: 0.004199336050078273\n",
      "-------epoch  607 -------\n",
      "train set Loss: 0.0027331571679678744\n",
      "val set Loss: 0.004628188131997983\n",
      "-------epoch  608 -------\n",
      "train set Loss: 0.002720579453743994\n",
      "val set Loss: 0.003917982539860532\n",
      "-------epoch  609 -------\n",
      "train set Loss: 0.0024239163829770406\n",
      "val set Loss: 0.005134669714607298\n",
      "-------epoch  610 -------\n",
      "train set Loss: 0.002312859168741852\n",
      "val set Loss: 0.004684140963945538\n",
      "-------epoch  611 -------\n",
      "train set Loss: 0.00225610231194878\n",
      "val set Loss: 0.0035862883378285915\n",
      "-------epoch  612 -------\n",
      "train set Loss: 0.004545788227987941\n",
      "val set Loss: 0.025125639978796244\n",
      "-------epoch  613 -------\n",
      "train set Loss: 0.009096390794729814\n",
      "val set Loss: 0.006070806101585428\n",
      "-------epoch  614 -------\n",
      "train set Loss: 0.0092111994093284\n",
      "val set Loss: 0.003578988544177264\n",
      "-------epoch  615 -------\n",
      "train set Loss: 0.0193970306229312\n",
      "val set Loss: 0.007463418577875321\n",
      "-------epoch  616 -------\n",
      "train set Loss: 0.02800043165916577\n",
      "val set Loss: 0.016772379788259666\n",
      "-------epoch  617 -------\n",
      "train set Loss: 0.019247081734938547\n",
      "val set Loss: 0.020376008314390976\n",
      "-------epoch  618 -------\n",
      "train set Loss: 0.028889813320129177\n",
      "val set Loss: 0.010898448216418425\n",
      "-------epoch  619 -------\n",
      "train set Loss: 0.022233707038685678\n",
      "val set Loss: 0.020449672515193622\n",
      "-------epoch  620 -------\n",
      "train set Loss: 0.017413571126526223\n",
      "val set Loss: 0.008893947505081693\n",
      "-------epoch  621 -------\n",
      "train set Loss: 0.008949582987697794\n",
      "val set Loss: 0.0070243167380491895\n",
      "-------epoch  622 -------\n",
      "train set Loss: 0.00847313404432498\n",
      "val set Loss: 0.006854775051275889\n",
      "-------epoch  623 -------\n",
      "train set Loss: 0.007343477816903032\n",
      "val set Loss: 0.006691287892560164\n",
      "-------epoch  624 -------\n",
      "train set Loss: 0.005907593630836345\n",
      "val set Loss: 0.002855481997054691\n",
      "-------epoch  625 -------\n",
      "train set Loss: 0.005190088349045254\n",
      "val set Loss: 0.0026965970949580273\n",
      "-------epoch  626 -------\n",
      "train set Loss: 0.0056566293915966525\n",
      "val set Loss: 0.005293840193189681\n",
      "-------epoch  627 -------\n",
      "train set Loss: 0.00498518310196232\n",
      "val set Loss: 0.00333346767971913\n",
      "-------epoch  628 -------\n",
      "train set Loss: 0.004200520531157963\n",
      "val set Loss: 0.0038436908119668565\n",
      "-------epoch  629 -------\n",
      "train set Loss: 0.004017102784710005\n",
      "val set Loss: 0.003265953380226468\n",
      "-------epoch  630 -------\n",
      "train set Loss: 0.003917066635913216\n",
      "val set Loss: 0.0035325086403948567\n",
      "-------epoch  631 -------\n",
      "train set Loss: 0.0038143582749762574\n",
      "val set Loss: 0.0031688677311952538\n",
      "-------epoch  632 -------\n",
      "train set Loss: 0.003975790461699944\n",
      "val set Loss: 0.027302666538162157\n",
      "-------epoch  633 -------\n",
      "train set Loss: 0.004526586576830595\n",
      "val set Loss: 0.0033179570794648803\n",
      "-------epoch  634 -------\n",
      "train set Loss: 0.005294781071715988\n",
      "val set Loss: 0.003982591559179127\n",
      "-------epoch  635 -------\n",
      "train set Loss: 0.004292273938335711\n",
      "val set Loss: 0.002684435516130179\n",
      "-------epoch  636 -------\n",
      "train set Loss: 0.003724751044937875\n",
      "val set Loss: 0.003108574135694653\n",
      "-------epoch  637 -------\n",
      "train set Loss: 0.003444298134127166\n",
      "val set Loss: 0.00326150253143472\n",
      "-------epoch  638 -------\n",
      "train set Loss: 0.003319469264242798\n",
      "val set Loss: 0.0039040334910775223\n",
      "-------epoch  639 -------\n",
      "train set Loss: 0.0030611855391180142\n",
      "val set Loss: 0.007206513235966365\n",
      "-------epoch  640 -------\n",
      "train set Loss: 0.002625213779101614\n",
      "val set Loss: 0.010263504043299084\n",
      "-------epoch  641 -------\n",
      "train set Loss: 0.0026746140909381213\n",
      "val set Loss: 0.008635224949102849\n",
      "-------epoch  642 -------\n",
      "train set Loss: 0.002775046659517102\n",
      "val set Loss: 0.015095360092042634\n",
      "-------epoch  643 -------\n",
      "train set Loss: 0.0036559237744950225\n",
      "val set Loss: 0.0037509796869320176\n",
      "-------epoch  644 -------\n",
      "train set Loss: 0.005736532433074899\n",
      "val set Loss: 0.007011575003465016\n",
      "-------epoch  645 -------\n",
      "train set Loss: 0.004424993803695543\n",
      "val set Loss: 0.01046571867967335\n",
      "-------epoch  646 -------\n",
      "train set Loss: 0.0029440609290031718\n",
      "val set Loss: 0.011163935133178407\n",
      "-------epoch  647 -------\n",
      "train set Loss: 0.0025138316687662154\n",
      "val set Loss: 0.007501567616903533\n",
      "-------epoch  648 -------\n",
      "train set Loss: 0.0025221069852705115\n",
      "val set Loss: 0.006086511634445439\n",
      "-------epoch  649 -------\n",
      "train set Loss: 0.0022748607324319893\n",
      "val set Loss: 0.009034196031279862\n",
      "-------epoch  650 -------\n",
      "train set Loss: 0.002124011483392678\n",
      "val set Loss: 0.0100051676951504\n",
      "-------epoch  651 -------\n",
      "train set Loss: 0.0023041917914815714\n",
      "val set Loss: 0.01421732515639936\n",
      "-------epoch  652 -------\n",
      "train set Loss: 0.002600781408691546\n",
      "val set Loss: 0.009662569471402094\n",
      "-------epoch  653 -------\n",
      "train set Loss: 0.003818156282795826\n",
      "val set Loss: 0.028275947785004973\n",
      "-------epoch  654 -------\n",
      "train set Loss: 0.004525990669208113\n",
      "val set Loss: 0.004712634642298023\n",
      "-------epoch  655 -------\n",
      "train set Loss: 0.005291979087051004\n",
      "val set Loss: 0.004573806771077216\n",
      "-------epoch  656 -------\n",
      "train set Loss: 0.003551807532203384\n",
      "val set Loss: 0.002882601179104919\n",
      "-------epoch  657 -------\n",
      "train set Loss: 0.003089629902970046\n",
      "val set Loss: 0.003248842117803482\n",
      "-------epoch  658 -------\n",
      "train set Loss: 0.002778533129603602\n",
      "val set Loss: 0.0032868254638742656\n",
      "-------epoch  659 -------\n",
      "train set Loss: 0.002730409352807328\n",
      "val set Loss: 0.00324361568588453\n",
      "-------epoch  660 -------\n",
      "train set Loss: 0.0026954438383108934\n",
      "val set Loss: 0.0035719250057203076\n",
      "-------epoch  661 -------\n",
      "train set Loss: 0.002559910537238466\n",
      "val set Loss: 0.003513026691507548\n",
      "-------epoch  662 -------\n",
      "train set Loss: 0.00262940666245413\n",
      "val set Loss: 0.0035765466066853455\n",
      "-------epoch  663 -------\n",
      "train set Loss: 0.002762256737187272\n",
      "val set Loss: 0.0051014906881997986\n",
      "-------epoch  664 -------\n",
      "train set Loss: 0.0031533105894050095\n",
      "val set Loss: 0.006882370721238355\n",
      "-------epoch  665 -------\n",
      "train set Loss: 0.0032823069697769823\n",
      "val set Loss: 0.007121493710049738\n",
      "-------epoch  666 -------\n",
      "train set Loss: 0.0028794105544511697\n",
      "val set Loss: 0.004512570289080031\n",
      "-------epoch  667 -------\n",
      "train set Loss: 0.002316082723191357\n",
      "val set Loss: 0.007477346516679972\n",
      "-------epoch  668 -------\n",
      "train set Loss: 0.0021112250098303774\n",
      "val set Loss: 0.005097372724170175\n",
      "-------epoch  669 -------\n",
      "train set Loss: 0.002049093725727289\n",
      "val set Loss: 0.008350514525470013\n",
      "-------epoch  670 -------\n",
      "train set Loss: 0.002168484473077115\n",
      "val set Loss: 0.006052859510721949\n",
      "-------epoch  671 -------\n",
      "train set Loss: 0.0023103880920098165\n",
      "val set Loss: 0.01227308406184117\n",
      "-------epoch  672 -------\n",
      "train set Loss: 0.0027088005357654766\n",
      "val set Loss: 0.007278964112629183\n",
      "-------epoch  673 -------\n",
      "train set Loss: 0.003011621910700342\n",
      "val set Loss: 0.01149005702851961\n",
      "-------epoch  674 -------\n",
      "train set Loss: 0.0028489565008203497\n",
      "val set Loss: 0.01169900145517507\n",
      "-------epoch  675 -------\n",
      "train set Loss: 0.0025349470882065363\n",
      "val set Loss: 0.010203632283567762\n",
      "-------epoch  676 -------\n",
      "train set Loss: 0.002254762797165313\n",
      "val set Loss: 0.008678230122313835\n",
      "-------epoch  677 -------\n",
      "train set Loss: 0.0021504888579511315\n",
      "val set Loss: 0.0091540491169629\n",
      "-------epoch  678 -------\n",
      "train set Loss: 0.002180373405863065\n",
      "val set Loss: 0.007502841215076235\n",
      "-------epoch  679 -------\n",
      "train set Loss: 0.002202159487060271\n",
      "val set Loss: 0.008199607575079426\n",
      "-------epoch  680 -------\n",
      "train set Loss: 0.0024099501135060562\n",
      "val set Loss: 0.0060918436259574564\n",
      "-------epoch  681 -------\n",
      "train set Loss: 0.0024581521927029824\n",
      "val set Loss: 0.0077959607588127255\n",
      "-------epoch  682 -------\n",
      "train set Loss: 0.002511393646709621\n",
      "val set Loss: 0.006043998238358957\n",
      "-------epoch  683 -------\n",
      "train set Loss: 0.0024318247093469835\n",
      "val set Loss: 0.008323770239561176\n",
      "-------epoch  684 -------\n",
      "train set Loss: 0.002278662959433859\n",
      "val set Loss: 0.007269296940648928\n",
      "-------epoch  685 -------\n",
      "train set Loss: 0.0022634388256119564\n",
      "val set Loss: 0.009116340981563553\n",
      "-------epoch  686 -------\n",
      "train set Loss: 0.002209021487215068\n",
      "val set Loss: 0.00758346470441514\n",
      "-------epoch  687 -------\n",
      "train set Loss: 0.0023081934537913184\n",
      "val set Loss: 0.009284070091477284\n",
      "-------epoch  688 -------\n",
      "train set Loss: 0.0023784697654627963\n",
      "val set Loss: 0.006869342643767595\n",
      "-------epoch  689 -------\n",
      "train set Loss: 0.0024077289219712836\n",
      "val set Loss: 0.008680638168395186\n",
      "-------epoch  690 -------\n",
      "train set Loss: 0.0023978978177910905\n",
      "val set Loss: 0.006400814338121563\n",
      "-------epoch  691 -------\n",
      "train set Loss: 0.0022470179192896466\n",
      "val set Loss: 0.007854429597500712\n",
      "-------epoch  692 -------\n",
      "train set Loss: 0.002234138169878861\n",
      "val set Loss: 0.005915277613288102\n",
      "-------epoch  693 -------\n",
      "train set Loss: 0.0020979697802249574\n",
      "val set Loss: 0.007282844802830368\n",
      "-------epoch  694 -------\n",
      "train set Loss: 0.0021527987057925204\n",
      "val set Loss: 0.0059996711982724564\n",
      "-------epoch  695 -------\n",
      "train set Loss: 0.00210604119252821\n",
      "val set Loss: 0.00755380280315876\n",
      "-------epoch  696 -------\n",
      "train set Loss: 0.0022852665740356313\n",
      "val set Loss: 0.005861485968731965\n",
      "-------epoch  697 -------\n",
      "train set Loss: 0.0023150518417241984\n",
      "val set Loss: 0.00758046288198481\n",
      "-------epoch  698 -------\n",
      "train set Loss: 0.002336052599493996\n",
      "val set Loss: 0.007140964745000626\n",
      "-------epoch  699 -------\n",
      "train set Loss: 0.0023208931295084765\n",
      "val set Loss: 0.009746143410059934\n",
      "-------epoch  700 -------\n",
      "train set Loss: 0.002176454139626003\n",
      "val set Loss: 0.009120313712628558\n",
      "-------epoch  701 -------\n",
      "train set Loss: 0.0022197914990829304\n",
      "val set Loss: 0.010062947529756153\n",
      "-------epoch  702 -------\n",
      "train set Loss: 0.0022007338146431722\n",
      "val set Loss: 0.007843960086271787\n",
      "-------epoch  703 -------\n",
      "train set Loss: 0.0023051260015927253\n",
      "val set Loss: 0.00818190232773001\n",
      "-------epoch  704 -------\n",
      "train set Loss: 0.0024323834447568513\n",
      "val set Loss: 0.004938222099250804\n",
      "-------epoch  705 -------\n",
      "train set Loss: 0.002267367209715303\n",
      "val set Loss: 0.006921440168904762\n",
      "-------epoch  706 -------\n",
      "train set Loss: 0.0023528550150513183\n",
      "val set Loss: 0.005579107770851503\n",
      "-------epoch  707 -------\n",
      "train set Loss: 0.002058331682201242\n",
      "val set Loss: 0.007168425615721692\n",
      "-------epoch  708 -------\n",
      "train set Loss: 0.0022593617471284235\n",
      "val set Loss: 0.004575079767770755\n",
      "-------epoch  709 -------\n",
      "train set Loss: 0.0022440806691884064\n",
      "val set Loss: 0.004938585596391931\n",
      "-------epoch  710 -------\n",
      "train set Loss: 0.002718825330666732\n",
      "val set Loss: 0.004428137404223283\n",
      "-------epoch  711 -------\n",
      "train set Loss: 0.0023039736593636916\n",
      "val set Loss: 0.006438198479978989\n",
      "-------epoch  712 -------\n",
      "train set Loss: 0.00240460015978897\n",
      "val set Loss: 0.005342763722486173\n",
      "-------epoch  713 -------\n",
      "train set Loss: 0.002691007483517751\n",
      "val set Loss: 0.0071705599160244065\n",
      "-------epoch  714 -------\n",
      "train set Loss: 0.0028718108426255638\n",
      "val set Loss: 0.006722956342855468\n",
      "-------epoch  715 -------\n",
      "train set Loss: 0.0032569837516348344\n",
      "val set Loss: 0.012502667959779501\n",
      "-------epoch  716 -------\n",
      "train set Loss: 0.0027650125617947195\n",
      "val set Loss: 0.012853470572736114\n",
      "-------epoch  717 -------\n",
      "train set Loss: 0.0029009705016505905\n",
      "val set Loss: 0.015950231696479023\n",
      "-------epoch  718 -------\n",
      "train set Loss: 0.0022530379990348594\n",
      "val set Loss: 0.008478716277750209\n",
      "-------epoch  719 -------\n",
      "train set Loss: 0.002640293898730306\n",
      "val set Loss: 0.00796535147431617\n",
      "-------epoch  720 -------\n",
      "train set Loss: 0.002568009213428013\n",
      "val set Loss: 0.006369923648890108\n",
      "-------epoch  721 -------\n",
      "train set Loss: 0.002754383229184896\n",
      "val set Loss: 0.008805749355815351\n",
      "-------epoch  722 -------\n",
      "train set Loss: 0.003499192817835137\n",
      "val set Loss: 0.005457278205237041\n",
      "-------epoch  723 -------\n",
      "train set Loss: 0.0034622515365481375\n",
      "val set Loss: 0.008512657407360772\n",
      "-------epoch  724 -------\n",
      "train set Loss: 0.0037460800987901164\n",
      "val set Loss: 0.005737223929221121\n",
      "-------epoch  725 -------\n",
      "train set Loss: 0.0024527623044559733\n",
      "val set Loss: 0.0068708051985595375\n",
      "-------epoch  726 -------\n",
      "train set Loss: 0.0023185951766208747\n",
      "val set Loss: 0.004849974560784176\n",
      "-------epoch  727 -------\n",
      "train set Loss: 0.0022934333760349546\n",
      "val set Loss: 0.007133760159679999\n",
      "-------epoch  728 -------\n",
      "train set Loss: 0.0022861131934769218\n",
      "val set Loss: 0.008774890447966754\n",
      "-------epoch  729 -------\n",
      "train set Loss: 0.002996263940585777\n",
      "val set Loss: 0.013529859541449696\n",
      "-------epoch  730 -------\n",
      "train set Loss: 0.0028717825160128998\n",
      "val set Loss: 0.007552802135857443\n",
      "-------epoch  731 -------\n",
      "train set Loss: 0.003230183954583481\n",
      "val set Loss: 0.011327854978541533\n",
      "-------epoch  732 -------\n",
      "train set Loss: 0.00267939624725841\n",
      "val set Loss: 0.006578813733843465\n",
      "-------epoch  733 -------\n",
      "train set Loss: 0.0022904036630643533\n",
      "val set Loss: 0.007201446753848965\n",
      "-------epoch  734 -------\n",
      "train set Loss: 0.0023965476076409685\n",
      "val set Loss: 0.005029971701636289\n",
      "-------epoch  735 -------\n",
      "train set Loss: 0.0020424366273800844\n",
      "val set Loss: 0.005370760957400004\n",
      "-------epoch  736 -------\n",
      "train set Loss: 0.002298705329594668\n",
      "val set Loss: 0.004132530545272554\n",
      "-------epoch  737 -------\n",
      "train set Loss: 0.0020908524266269523\n",
      "val set Loss: 0.005191862748082106\n",
      "-------epoch  738 -------\n",
      "train set Loss: 0.0025850479750079104\n",
      "val set Loss: 0.0051373928048027056\n",
      "-------epoch  739 -------\n",
      "train set Loss: 0.002778713841980789\n",
      "val set Loss: 0.01227769635928174\n",
      "-------epoch  740 -------\n",
      "train set Loss: 0.0023636652647110166\n",
      "val set Loss: 0.00911081800586544\n",
      "-------epoch  741 -------\n",
      "train set Loss: 0.002638129476981703\n",
      "val set Loss: 0.006627148803090677\n",
      "-------epoch  742 -------\n",
      "train set Loss: 0.00262202540106955\n",
      "val set Loss: 0.005965103356478115\n",
      "-------epoch  743 -------\n",
      "train set Loss: 0.0025560719463101123\n",
      "val set Loss: 0.008552873575051004\n",
      "-------epoch  744 -------\n",
      "train set Loss: 0.003423531205917243\n",
      "val set Loss: 0.01019972202872547\n",
      "-------epoch  745 -------\n",
      "train set Loss: 0.0031695543295063543\n",
      "val set Loss: 0.012566156394314021\n",
      "-------epoch  746 -------\n",
      "train set Loss: 0.004030661300785141\n",
      "val set Loss: 0.007421170468054091\n",
      "-------epoch  747 -------\n",
      "train set Loss: 0.0027016928655211815\n",
      "val set Loss: 0.008452090667560697\n",
      "-------epoch  748 -------\n",
      "train set Loss: 0.0028709501308912875\n",
      "val set Loss: 0.004137153984629549\n",
      "-------epoch  749 -------\n",
      "train set Loss: 0.002429444176814286\n",
      "val set Loss: 0.006621633326479544\n",
      "-------epoch  750 -------\n",
      "train set Loss: 0.0029214263462927193\n",
      "val set Loss: 0.004484117787797004\n",
      "-------epoch  751 -------\n",
      "train set Loss: 0.0033807844320108416\n",
      "val set Loss: 0.012512635323219001\n",
      "-------epoch  752 -------\n",
      "train set Loss: 0.0031631632469361647\n",
      "val set Loss: 0.008871527728236591\n",
      "-------epoch  753 -------\n",
      "train set Loss: 0.003441990242645261\n",
      "val set Loss: 0.014647792520311972\n",
      "-------epoch  754 -------\n",
      "train set Loss: 0.002580120461789193\n",
      "val set Loss: 0.009613750056208422\n",
      "-------epoch  755 -------\n",
      "train set Loss: 0.0024900333376717755\n",
      "val set Loss: 0.010318714009675508\n",
      "-------epoch  756 -------\n",
      "train set Loss: 0.0030534076946787535\n",
      "val set Loss: 0.005224224005360156\n",
      "-------epoch  757 -------\n",
      "train set Loss: 0.00307205269113183\n",
      "val set Loss: 0.009274224110413343\n",
      "-------epoch  758 -------\n",
      "train set Loss: 0.003505087574594654\n",
      "val set Loss: 0.004412429649770881\n",
      "-------epoch  759 -------\n",
      "train set Loss: 0.002658118746621767\n",
      "val set Loss: 0.006480910233221948\n",
      "-------epoch  760 -------\n",
      "train set Loss: 0.002760618190513924\n",
      "val set Loss: 0.004520193120697513\n",
      "-------epoch  761 -------\n",
      "train set Loss: 0.0025466302034328693\n",
      "val set Loss: 0.009936637128703296\n",
      "-------epoch  762 -------\n",
      "train set Loss: 0.002439065473008668\n",
      "val set Loss: 0.008998292119940743\n",
      "-------epoch  763 -------\n",
      "train set Loss: 0.003059598274412565\n",
      "val set Loss: 0.014619148588584116\n",
      "-------epoch  764 -------\n",
      "train set Loss: 0.0026787997141946105\n",
      "val set Loss: 0.007484756608998093\n",
      "-------epoch  765 -------\n",
      "train set Loss: 0.0021366313254111446\n",
      "val set Loss: 0.007910004816949368\n",
      "-------epoch  766 -------\n",
      "train set Loss: 0.0021141590968181845\n",
      "val set Loss: 0.004172169904146965\n",
      "-------epoch  767 -------\n",
      "train set Loss: 0.0022031525897909885\n",
      "val set Loss: 0.006477010882614802\n",
      "-------epoch  768 -------\n",
      "train set Loss: 0.0030006833829247627\n",
      "val set Loss: 0.0033037259127013385\n",
      "-------epoch  769 -------\n",
      "train set Loss: 0.0030026757228188215\n",
      "val set Loss: 0.00791028888973718\n",
      "-------epoch  770 -------\n",
      "train set Loss: 0.0027272135970997625\n",
      "val set Loss: 0.008222944733764356\n",
      "-------epoch  771 -------\n",
      "train set Loss: 0.002396215155167738\n",
      "val set Loss: 0.011496728257043287\n",
      "-------epoch  772 -------\n",
      "train set Loss: 0.002084096400940325\n",
      "val set Loss: 0.007518014288507402\n",
      "-------epoch  773 -------\n",
      "train set Loss: 0.00218229916295968\n",
      "val set Loss: 0.010359948151744902\n",
      "-------epoch  774 -------\n",
      "train set Loss: 0.00256992178488872\n",
      "val set Loss: 0.0037418158462969586\n",
      "-------epoch  775 -------\n",
      "train set Loss: 0.002236930429935455\n",
      "val set Loss: 0.004464197515820463\n",
      "-------epoch  776 -------\n",
      "train set Loss: 0.0021565382566768676\n",
      "val set Loss: 0.0051872878830181435\n",
      "-------epoch  777 -------\n",
      "train set Loss: 0.001660142567125149\n",
      "val set Loss: 0.004830689596322675\n",
      "-------epoch  778 -------\n",
      "train set Loss: 0.0017083042417652904\n",
      "val set Loss: 0.0049503143527545035\n",
      "-------epoch  779 -------\n",
      "train set Loss: 0.00208958622883074\n",
      "val set Loss: 0.009462041528119395\n",
      "-------epoch  780 -------\n",
      "train set Loss: 0.0023578423344224574\n",
      "val set Loss: 0.007008774962741882\n",
      "-------epoch  781 -------\n",
      "train set Loss: 0.0032402574767183977\n",
      "val set Loss: 0.016272344742901623\n",
      "-------epoch  782 -------\n",
      "train set Loss: 0.0027960547152906657\n",
      "val set Loss: 0.007775671159227689\n",
      "-------epoch  783 -------\n",
      "train set Loss: 0.003147893542482052\n",
      "val set Loss: 0.010440550647520771\n",
      "-------epoch  784 -------\n",
      "train set Loss: 0.0028071094618644567\n",
      "val set Loss: 0.008790194493485615\n",
      "-------epoch  785 -------\n",
      "train set Loss: 0.003148375486198347\n",
      "val set Loss: 0.009205745261472961\n",
      "-------epoch  786 -------\n",
      "train set Loss: 0.002903138827823568\n",
      "val set Loss: 0.0049199834174942225\n",
      "-------epoch  787 -------\n",
      "train set Loss: 0.002454153690923704\n",
      "val set Loss: 0.006266106705879793\n",
      "-------epoch  788 -------\n",
      "train set Loss: 0.0028583983662974787\n",
      "val set Loss: 0.0043075990009432035\n",
      "-------epoch  789 -------\n",
      "train set Loss: 0.002730102748610079\n",
      "val set Loss: 0.009433753633250793\n",
      "-------epoch  790 -------\n",
      "train set Loss: 0.0026846256779390386\n",
      "val set Loss: 0.010571818216703832\n",
      "-------epoch  791 -------\n",
      "train set Loss: 0.0033976202650228514\n",
      "val set Loss: 0.017041678598616272\n",
      "-------epoch  792 -------\n",
      "train set Loss: 0.003823568637599237\n",
      "val set Loss: 0.009336084554282328\n",
      "-------epoch  793 -------\n",
      "train set Loss: 0.004533403726527468\n",
      "val set Loss: 0.006730338286918898\n",
      "-------epoch  794 -------\n",
      "train set Loss: 0.004261200627079234\n",
      "val set Loss: 0.013148512933791304\n",
      "-------epoch  795 -------\n",
      "train set Loss: 0.003419776496011764\n",
      "val set Loss: 0.00555267926150312\n",
      "-------epoch  796 -------\n",
      "train set Loss: 0.004609871567809023\n",
      "val set Loss: 0.003952521811394642\n",
      "-------epoch  797 -------\n",
      "train set Loss: 0.0035481752661871723\n",
      "val set Loss: 0.009858743433142081\n",
      "-------epoch  798 -------\n",
      "train set Loss: 0.0027197154288296586\n",
      "val set Loss: 0.006084674717082332\n",
      "-------epoch  799 -------\n",
      "train set Loss: 0.002827309115091339\n",
      "val set Loss: 0.006674255108616005\n",
      "-------epoch  800 -------\n",
      "train set Loss: 0.003587327569257468\n",
      "val set Loss: 0.009237691391414652\n",
      "-------epoch  801 -------\n",
      "train set Loss: 0.003640094108704943\n",
      "val set Loss: 0.006214594449071835\n",
      "-------epoch  802 -------\n",
      "train set Loss: 0.003156271300977096\n",
      "val set Loss: 0.017241938699347276\n",
      "-------epoch  803 -------\n",
      "train set Loss: 0.002262759225559421\n",
      "val set Loss: 0.012694491306319833\n",
      "-------epoch  804 -------\n",
      "train set Loss: 0.001954216815283871\n",
      "val set Loss: 0.014037571536997953\n",
      "-------epoch  805 -------\n",
      "train set Loss: 0.0018131704008555972\n",
      "val set Loss: 0.009926343152377134\n",
      "-------epoch  806 -------\n",
      "train set Loss: 0.0019223170015902724\n",
      "val set Loss: 0.010933421057416126\n",
      "-------epoch  807 -------\n",
      "train set Loss: 0.0022619592968840152\n",
      "val set Loss: 0.006701957613889438\n",
      "-------epoch  808 -------\n",
      "train set Loss: 0.0024519264508853665\n",
      "val set Loss: 0.00983068886368225\n",
      "-------epoch  809 -------\n",
      "train set Loss: 0.002944168209651252\n",
      "val set Loss: 0.0059279918593044085\n",
      "-------epoch  810 -------\n",
      "train set Loss: 0.0024387333444610706\n",
      "val set Loss: 0.010543864084562907\n",
      "-------epoch  811 -------\n",
      "train set Loss: 0.002029454123112373\n",
      "val set Loss: 0.0082602023758227\n",
      "-------epoch  812 -------\n",
      "train set Loss: 0.0019462306950299535\n",
      "val set Loss: 0.011841692175948992\n",
      "-------epoch  813 -------\n",
      "train set Loss: 0.0016800094571954105\n",
      "val set Loss: 0.00912530294347865\n",
      "-------epoch  814 -------\n",
      "train set Loss: 0.0017181628828984686\n",
      "val set Loss: 0.009534322452964261\n",
      "-------epoch  815 -------\n",
      "train set Loss: 0.001798454550007591\n",
      "val set Loss: 0.004822905922386174\n",
      "-------epoch  816 -------\n",
      "train set Loss: 0.001979024678003043\n",
      "val set Loss: 0.005613921404195328\n",
      "-------epoch  817 -------\n",
      "train set Loss: 0.0021492713774205184\n",
      "val set Loss: 0.004046559838267664\n",
      "-------epoch  818 -------\n",
      "train set Loss: 0.001957295851680101\n",
      "val set Loss: 0.005846364035581549\n",
      "-------epoch  819 -------\n",
      "train set Loss: 0.0023380454136349726\n",
      "val set Loss: 0.0049720598860100535\n",
      "-------epoch  820 -------\n",
      "train set Loss: 0.0022557590540964157\n",
      "val set Loss: 0.010679974123680344\n",
      "-------epoch  821 -------\n",
      "train set Loss: 0.002147003514546668\n",
      "val set Loss: 0.003919202892575413\n",
      "-------epoch  822 -------\n",
      "train set Loss: 0.0022996961994795127\n",
      "val set Loss: 0.01666220958577469\n",
      "-------epoch  823 -------\n",
      "train set Loss: 0.0019820455013541505\n",
      "val set Loss: 0.010397317935712636\n",
      "-------epoch  824 -------\n",
      "train set Loss: 0.002233416626113467\n",
      "val set Loss: 0.011144586159692457\n",
      "-------epoch  825 -------\n",
      "train set Loss: 0.0026981836077175103\n",
      "val set Loss: 0.010156750019329289\n",
      "-------epoch  826 -------\n",
      "train set Loss: 0.002983406631683465\n",
      "val set Loss: 0.00698741195568194\n",
      "-------epoch  827 -------\n",
      "train set Loss: 0.003232519881421467\n",
      "val set Loss: 0.004121869850981359\n",
      "-------epoch  828 -------\n",
      "train set Loss: 0.0034066194244951474\n",
      "val set Loss: 0.00475205098822092\n",
      "-------epoch  829 -------\n",
      "train set Loss: 0.003367843300511595\n",
      "val set Loss: 0.003877990636586522\n",
      "-------epoch  830 -------\n",
      "train set Loss: 0.0032941150109400043\n",
      "val set Loss: 0.007266824773978442\n",
      "-------epoch  831 -------\n",
      "train set Loss: 0.003469778267754009\n",
      "val set Loss: 0.007196742400992662\n",
      "-------epoch  832 -------\n",
      "train set Loss: 0.003599076143000275\n",
      "val set Loss: 0.013819959402705232\n",
      "-------epoch  833 -------\n",
      "train set Loss: 0.0029187126489705405\n",
      "val set Loss: 0.007843059526445964\n",
      "-------epoch  834 -------\n",
      "train set Loss: 0.0033865159496781418\n",
      "val set Loss: 0.010799717798363417\n",
      "-------epoch  835 -------\n",
      "train set Loss: 0.0028944476711330936\n",
      "val set Loss: 0.005942700974022348\n",
      "-------epoch  836 -------\n",
      "train set Loss: 0.002281278796144761\n",
      "val set Loss: 0.00608024427977701\n",
      "-------epoch  837 -------\n",
      "train set Loss: 0.002153818769438658\n",
      "val set Loss: 0.005081960970225434\n",
      "-------epoch  838 -------\n",
      "train set Loss: 0.002006881548441015\n",
      "val set Loss: 0.004582738125463948\n",
      "-------epoch  839 -------\n",
      "train set Loss: 0.0018221606279257684\n",
      "val set Loss: 0.005272342241369188\n",
      "-------epoch  840 -------\n",
      "train set Loss: 0.002479067488166038\n",
      "val set Loss: 0.005250449011024709\n",
      "-------epoch  841 -------\n",
      "train set Loss: 0.003824054985670955\n",
      "val set Loss: 0.014798612178613743\n",
      "-------epoch  842 -------\n",
      "train set Loss: 0.002695467949670274\n",
      "val set Loss: 0.009304504725150764\n",
      "-------epoch  843 -------\n",
      "train set Loss: 0.0025886934145819395\n",
      "val set Loss: 0.010420741164125502\n",
      "-------epoch  844 -------\n",
      "train set Loss: 0.002907153413107153\n",
      "val set Loss: 0.0048390414255360765\n",
      "-------epoch  845 -------\n",
      "train set Loss: 0.002542078932165168\n",
      "val set Loss: 0.005776521943820019\n",
      "-------epoch  846 -------\n",
      "train set Loss: 0.0027206336402741727\n",
      "val set Loss: 0.005482269324905549\n",
      "-------epoch  847 -------\n",
      "train set Loss: 0.005179067846038379\n",
      "val set Loss: 0.003421411539117495\n",
      "-------epoch  848 -------\n",
      "train set Loss: 0.007090251759509556\n",
      "val set Loss: 0.041831920544306435\n",
      "-------epoch  849 -------\n",
      "train set Loss: 0.009143841781187802\n",
      "val set Loss: 0.022248886603241164\n",
      "-------epoch  850 -------\n",
      "train set Loss: 0.010835411799489521\n",
      "val set Loss: 0.012833427307972064\n",
      "-------epoch  851 -------\n",
      "train set Loss: 0.005259931833716109\n",
      "val set Loss: 0.005813263434295853\n",
      "-------epoch  852 -------\n",
      "train set Loss: 0.006385803616140038\n",
      "val set Loss: 0.004502887468940268\n",
      "-------epoch  853 -------\n",
      "train set Loss: 0.006303450501873158\n",
      "val set Loss: 0.008116690092720091\n",
      "-------epoch  854 -------\n",
      "train set Loss: 0.0046737273473991085\n",
      "val set Loss: 0.0063987793400883675\n",
      "-------epoch  855 -------\n",
      "train set Loss: 0.004803002992994152\n",
      "val set Loss: 0.004643685184419155\n",
      "-------epoch  856 -------\n",
      "train set Loss: 0.0036517786787590013\n",
      "val set Loss: 0.004116494014548759\n",
      "-------epoch  857 -------\n",
      "train set Loss: 0.0034609561698744074\n",
      "val set Loss: 0.0038581175807242594\n",
      "-------epoch  858 -------\n",
      "train set Loss: 0.002772549260989763\n",
      "val set Loss: 0.003093714884016663\n",
      "-------epoch  859 -------\n",
      "train set Loss: 0.0028563488594954833\n",
      "val set Loss: 0.00415480545295092\n",
      "-------epoch  860 -------\n",
      "train set Loss: 0.00415552576771006\n",
      "val set Loss: 0.01260474145722886\n",
      "-------epoch  861 -------\n",
      "train set Loss: 0.0032112263642193285\n",
      "val set Loss: 0.015987232327461243\n",
      "-------epoch  862 -------\n",
      "train set Loss: 0.0024413095013005657\n",
      "val set Loss: 0.010872738329150403\n",
      "-------epoch  863 -------\n",
      "train set Loss: 0.0023497694252000655\n",
      "val set Loss: 0.013309694574369738\n",
      "-------epoch  864 -------\n",
      "train set Loss: 0.002098388380545657\n",
      "val set Loss: 0.012893216082981477\n",
      "-------epoch  865 -------\n",
      "train set Loss: 0.0020076560563757084\n",
      "val set Loss: 0.014224724407540634\n",
      "-------epoch  866 -------\n",
      "train set Loss: 0.002093678560486296\n",
      "val set Loss: 0.01229932852826702\n",
      "-------epoch  867 -------\n",
      "train set Loss: 0.0023247065593750447\n",
      "val set Loss: 0.013472311838995665\n",
      "-------epoch  868 -------\n",
      "train set Loss: 0.00303453687869478\n",
      "val set Loss: 0.009789055358851328\n",
      "-------epoch  869 -------\n",
      "train set Loss: 0.0025507666358316784\n",
      "val set Loss: 0.014157220624232044\n",
      "-------epoch  870 -------\n",
      "train set Loss: 0.0020792227864149027\n",
      "val set Loss: 0.011757204066573953\n",
      "-------epoch  871 -------\n",
      "train set Loss: 0.0018602453237690497\n",
      "val set Loss: 0.012789472695052003\n",
      "-------epoch  872 -------\n",
      "train set Loss: 0.0018961725053668489\n",
      "val set Loss: 0.009102459783510616\n",
      "-------epoch  873 -------\n",
      "train set Loss: 0.0018711857646121644\n",
      "val set Loss: 0.009746579269024854\n",
      "-------epoch  874 -------\n",
      "train set Loss: 0.0020492764344089663\n",
      "val set Loss: 0.009287652501370758\n",
      "-------epoch  875 -------\n",
      "train set Loss: 0.002396007831193856\n",
      "val set Loss: 0.012263911446401229\n",
      "-------epoch  876 -------\n",
      "train set Loss: 0.0025396707440086177\n",
      "val set Loss: 0.008406419617434343\n",
      "-------epoch  877 -------\n",
      "train set Loss: 0.002445493490231456\n",
      "val set Loss: 0.011255846882704645\n",
      "-------epoch  878 -------\n",
      "train set Loss: 0.0020722623274923536\n",
      "val set Loss: 0.009212831947176406\n",
      "-------epoch  879 -------\n",
      "train set Loss: 0.00183229538044543\n",
      "val set Loss: 0.010129172335534046\n",
      "-------epoch  880 -------\n",
      "train set Loss: 0.0020312835363438353\n",
      "val set Loss: 0.0072680587181821465\n",
      "-------epoch  881 -------\n",
      "train set Loss: 0.0019315052005549659\n",
      "val set Loss: 0.010618867498124018\n",
      "-------epoch  882 -------\n",
      "train set Loss: 0.0018785300653689774\n",
      "val set Loss: 0.007239073786574106\n",
      "-------epoch  883 -------\n",
      "train set Loss: 0.0021677327475481435\n",
      "val set Loss: 0.009719256030318016\n",
      "-------epoch  884 -------\n",
      "train set Loss: 0.002180959883480682\n",
      "val set Loss: 0.009138289742016545\n",
      "-------epoch  885 -------\n",
      "train set Loss: 0.002030348786356626\n",
      "val set Loss: 0.010549227454854796\n",
      "-------epoch  886 -------\n",
      "train set Loss: 0.001997126744390698\n",
      "val set Loss: 0.007702731808725123\n",
      "-------epoch  887 -------\n",
      "train set Loss: 0.001930896725243656\n",
      "val set Loss: 0.009337647245653594\n",
      "-------epoch  888 -------\n",
      "train set Loss: 0.002023772129105055\n",
      "val set Loss: 0.006696281838230789\n",
      "-------epoch  889 -------\n",
      "train set Loss: 0.002210104538826272\n",
      "val set Loss: 0.009432333453635996\n",
      "-------epoch  890 -------\n",
      "train set Loss: 0.0021533184301370054\n",
      "val set Loss: 0.007347845462694143\n",
      "-------epoch  891 -------\n",
      "train set Loss: 0.0017879477482347283\n",
      "val set Loss: 0.012297621025936678\n",
      "-------epoch  892 -------\n",
      "train set Loss: 0.0018698857064009644\n",
      "val set Loss: 0.010453482042066753\n",
      "-------epoch  893 -------\n",
      "train set Loss: 0.002009685335215181\n",
      "val set Loss: 0.01105410308809951\n",
      "-------epoch  894 -------\n",
      "train set Loss: 0.0020196498026780318\n",
      "val set Loss: 0.006426701739352818\n",
      "-------epoch  895 -------\n",
      "train set Loss: 0.0020248476530832704\n",
      "val set Loss: 0.007975916630433252\n",
      "-------epoch  896 -------\n",
      "train set Loss: 0.0018829504125460516\n",
      "val set Loss: 0.007208559991947065\n",
      "-------epoch  897 -------\n",
      "train set Loss: 0.00164990176250285\n",
      "val set Loss: 0.009715967540008327\n",
      "-------epoch  898 -------\n",
      "train set Loss: 0.0016300713810778688\n",
      "val set Loss: 0.007457942158604662\n",
      "-------epoch  899 -------\n",
      "train set Loss: 0.0017481220826448408\n",
      "val set Loss: 0.009238820765555525\n",
      "-------epoch  900 -------\n",
      "train set Loss: 0.0016720436746254564\n",
      "val set Loss: 0.004125063559816529\n",
      "-------epoch  901 -------\n",
      "train set Loss: 0.0019523702732112723\n",
      "val set Loss: 0.005336354661267251\n",
      "-------epoch  902 -------\n",
      "train set Loss: 0.0018762835318921133\n",
      "val set Loss: 0.004499328735012871\n",
      "-------epoch  903 -------\n",
      "train set Loss: 0.002003876817107084\n",
      "val set Loss: 0.009408530216508856\n",
      "-------epoch  904 -------\n",
      "train set Loss: 0.0016903088209801354\n",
      "val set Loss: 0.007595553247180457\n",
      "-------epoch  905 -------\n",
      "train set Loss: 0.0014072358841076492\n",
      "val set Loss: 0.008740390767343342\n",
      "-------epoch  906 -------\n",
      "train set Loss: 0.0012971254844887882\n",
      "val set Loss: 0.0067896663676947355\n",
      "-------epoch  907 -------\n",
      "train set Loss: 0.0013186375853547361\n",
      "val set Loss: 0.006802673606822888\n",
      "-------epoch  908 -------\n",
      "train set Loss: 0.0012212279790401225\n",
      "val set Loss: 0.004475320616620593\n",
      "-------epoch  909 -------\n",
      "train set Loss: 0.0012577948217949598\n",
      "val set Loss: 0.00419092060959277\n",
      "-------epoch  910 -------\n",
      "train set Loss: 0.0019654626872215885\n",
      "val set Loss: 0.005743970046751201\n",
      "-------epoch  911 -------\n",
      "train set Loss: 0.0026852372029679827\n",
      "val set Loss: 0.003505386489753922\n",
      "-------epoch  912 -------\n",
      "train set Loss: 0.003171251946769189\n",
      "val set Loss: 0.011953860327290991\n",
      "-------epoch  913 -------\n",
      "train set Loss: 0.004235649115289561\n",
      "val set Loss: 0.005800334387458861\n",
      "-------epoch  914 -------\n",
      "train set Loss: 0.0065416667645331475\n",
      "val set Loss: 0.023109251478066046\n",
      "-------epoch  915 -------\n",
      "train set Loss: 0.005393769644433633\n",
      "val set Loss: 0.00964187072046722\n",
      "-------epoch  916 -------\n",
      "train set Loss: 0.004100357891293243\n",
      "val set Loss: 0.010347157794361314\n",
      "-------epoch  917 -------\n",
      "train set Loss: 0.00435818915721029\n",
      "val set Loss: 0.005363891366869211\n",
      "-------epoch  918 -------\n",
      "train set Loss: 0.003764203975442797\n",
      "val set Loss: 0.007823838949358711\n",
      "-------epoch  919 -------\n",
      "train set Loss: 0.003098687805904774\n",
      "val set Loss: 0.007744081871351227\n",
      "-------epoch  920 -------\n",
      "train set Loss: 0.0033761224996123928\n",
      "val set Loss: 0.01242359079575787\n",
      "-------epoch  921 -------\n",
      "train set Loss: 0.0032053264108253643\n",
      "val set Loss: 0.004792987087663884\n",
      "-------epoch  922 -------\n",
      "train set Loss: 0.005617814885918051\n",
      "val set Loss: 0.020809762179851532\n",
      "-------epoch  923 -------\n",
      "train set Loss: 0.004845528233563528\n",
      "val set Loss: 0.018179061812891934\n",
      "-------epoch  924 -------\n",
      "train set Loss: 0.0034776554355630653\n",
      "val set Loss: 0.015780276618897915\n",
      "-------epoch  925 -------\n",
      "train set Loss: 0.0036131286271847782\n",
      "val set Loss: 0.01487288709419469\n",
      "-------epoch  926 -------\n",
      "train set Loss: 0.002999841485871002\n",
      "val set Loss: 0.014068311332569769\n",
      "-------epoch  927 -------\n",
      "train set Loss: 0.0027915716605639317\n",
      "val set Loss: 0.012163393286755309\n",
      "-------epoch  928 -------\n",
      "train set Loss: 0.002493659800529713\n",
      "val set Loss: 0.015437915455549955\n",
      "-------epoch  929 -------\n",
      "train set Loss: 0.0025597147579537703\n",
      "val set Loss: 0.013776098242184768\n",
      "-------epoch  930 -------\n",
      "train set Loss: 0.0030505588625965173\n",
      "val set Loss: 0.01791598814694832\n",
      "-------epoch  931 -------\n",
      "train set Loss: 0.00254830584366573\n",
      "val set Loss: 0.014883227791870013\n",
      "-------epoch  932 -------\n",
      "train set Loss: 0.0024482021293079016\n",
      "val set Loss: 0.017030739681407187\n",
      "-------epoch  933 -------\n",
      "train set Loss: 0.0025320363504579293\n",
      "val set Loss: 0.015082094410900027\n",
      "-------epoch  934 -------\n",
      "train set Loss: 0.0023954441877140197\n",
      "val set Loss: 0.017612522448568296\n",
      "-------epoch  935 -------\n",
      "train set Loss: 0.002258386859903112\n",
      "val set Loss: 0.016134200006490573\n",
      "-------epoch  936 -------\n",
      "train set Loss: 0.0024535026508237935\n",
      "val set Loss: 0.020763832008621346\n",
      "-------epoch  937 -------\n",
      "train set Loss: 0.0023983863879402634\n",
      "val set Loss: 0.016429999329072114\n",
      "-------epoch  938 -------\n",
      "train set Loss: 0.0028379960390157066\n",
      "val set Loss: 0.021248566646439333\n",
      "-------epoch  939 -------\n",
      "train set Loss: 0.002594783335662214\n",
      "val set Loss: 0.01722394272413415\n",
      "-------epoch  940 -------\n",
      "train set Loss: 0.0024122918021748773\n",
      "val set Loss: 0.020969968793603282\n",
      "-------epoch  941 -------\n",
      "train set Loss: 0.0022696165749221107\n",
      "val set Loss: 0.015681733280265082\n",
      "-------epoch  942 -------\n",
      "train set Loss: 0.0022031783577403986\n",
      "val set Loss: 0.017718609209017206\n",
      "-------epoch  943 -------\n",
      "train set Loss: 0.0019596457039006056\n",
      "val set Loss: 0.016370814458544675\n",
      "-------epoch  944 -------\n",
      "train set Loss: 0.0019133970551047242\n",
      "val set Loss: 0.018381603692735855\n",
      "-------epoch  945 -------\n",
      "train set Loss: 0.0019841037889273138\n",
      "val set Loss: 0.014465582265984267\n",
      "-------epoch  946 -------\n",
      "train set Loss: 0.0019222980078484398\n",
      "val set Loss: 0.01716499980345058\n",
      "-------epoch  947 -------\n",
      "train set Loss: 0.001826269901066553\n",
      "val set Loss: 0.013517188849315668\n",
      "-------epoch  948 -------\n",
      "train set Loss: 0.001890483939059777\n",
      "val set Loss: 0.015630929886053007\n",
      "-------epoch  949 -------\n",
      "train set Loss: 0.002410126119357301\n",
      "val set Loss: 0.012076580062663803\n",
      "-------epoch  950 -------\n",
      "train set Loss: 0.002590716092599905\n",
      "val set Loss: 0.01762655513205876\n",
      "-------epoch  951 -------\n",
      "train set Loss: 0.0019974791040294803\n",
      "val set Loss: 0.011900630711655443\n",
      "-------epoch  952 -------\n",
      "train set Loss: 0.0015956682685646228\n",
      "val set Loss: 0.015759733214508742\n",
      "-------epoch  953 -------\n",
      "train set Loss: 0.0016552620951551945\n",
      "val set Loss: 0.010967817070195451\n",
      "-------epoch  954 -------\n",
      "train set Loss: 0.0015028304739098531\n",
      "val set Loss: 0.01257296180119738\n",
      "-------epoch  955 -------\n",
      "train set Loss: 0.0013135527855047257\n",
      "val set Loss: 0.011027155657454083\n",
      "-------epoch  956 -------\n",
      "train set Loss: 0.001279718777514063\n",
      "val set Loss: 0.013097403629217297\n",
      "-------epoch  957 -------\n",
      "train set Loss: 0.0012467227164597715\n",
      "val set Loss: 0.010310554003808647\n",
      "-------epoch  958 -------\n",
      "train set Loss: 0.0013331175963685383\n",
      "val set Loss: 0.010295804890726382\n",
      "-------epoch  959 -------\n",
      "train set Loss: 0.0013882722033304162\n",
      "val set Loss: 0.009052151891713342\n",
      "-------epoch  960 -------\n",
      "train set Loss: 0.001329863434220897\n",
      "val set Loss: 0.00898922091194739\n",
      "-------epoch  961 -------\n",
      "train set Loss: 0.001418185859802179\n",
      "val set Loss: 0.008149818323242167\n",
      "-------epoch  962 -------\n",
      "train set Loss: 0.0012664574721566169\n",
      "val set Loss: 0.008904148184228688\n",
      "-------epoch  963 -------\n",
      "train set Loss: 0.001514298043839517\n",
      "val set Loss: 0.006942377066782986\n",
      "-------epoch  964 -------\n",
      "train set Loss: 0.0016684150305809452\n",
      "val set Loss: 0.008891760313417763\n",
      "-------epoch  965 -------\n",
      "train set Loss: 0.0022251972112280784\n",
      "val set Loss: 0.010430884974387785\n",
      "-------epoch  966 -------\n",
      "train set Loss: 0.0034140083473175762\n",
      "val set Loss: 0.012617140600923449\n",
      "-------epoch  967 -------\n",
      "train set Loss: 0.0022563842733507047\n",
      "val set Loss: 0.012680003914283589\n",
      "-------epoch  968 -------\n",
      "train set Loss: 0.0020624980883440004\n",
      "val set Loss: 0.011450147780124098\n",
      "-------epoch  969 -------\n",
      "train set Loss: 0.002203384505119175\n",
      "val set Loss: 0.011165015283040702\n",
      "-------epoch  970 -------\n",
      "train set Loss: 0.0024937661454896443\n",
      "val set Loss: 0.00537752154438446\n",
      "-------epoch  971 -------\n",
      "train set Loss: 0.0028314132287050597\n",
      "val set Loss: 0.004930706743228559\n",
      "-------epoch  972 -------\n",
      "train set Loss: 0.0026014288428996223\n",
      "val set Loss: 0.006088937749154866\n",
      "-------epoch  973 -------\n",
      "train set Loss: 0.0035920136942877434\n",
      "val set Loss: 0.011754032651272913\n",
      "-------epoch  974 -------\n",
      "train set Loss: 0.00487340767052956\n",
      "val set Loss: 0.020760963612701744\n",
      "-------epoch  975 -------\n",
      "train set Loss: 0.00268744903645711\n",
      "val set Loss: 0.009894900363481915\n",
      "-------epoch  976 -------\n",
      "train set Loss: 0.0019180550251621754\n",
      "val set Loss: 0.009450546989683062\n",
      "-------epoch  977 -------\n",
      "train set Loss: 0.0018952343738055787\n",
      "val set Loss: 0.007975248804238314\n",
      "-------epoch  978 -------\n",
      "train set Loss: 0.001506515738728922\n",
      "val set Loss: 0.012570977676659822\n",
      "-------epoch  979 -------\n",
      "train set Loss: 0.0040257397133973425\n",
      "val set Loss: 0.009435676697952053\n",
      "-------epoch  980 -------\n",
      "train set Loss: 0.005552851875545457\n",
      "val set Loss: 0.017065348763329286\n",
      "-------epoch  981 -------\n",
      "train set Loss: 0.0037693149538245052\n",
      "val set Loss: 0.008475503622321412\n",
      "-------epoch  982 -------\n",
      "train set Loss: 0.0029397468923707494\n",
      "val set Loss: 0.010702009400120005\n",
      "-------epoch  983 -------\n",
      "train set Loss: 0.002364072804048192\n",
      "val set Loss: 0.008293375644522408\n",
      "-------epoch  984 -------\n",
      "train set Loss: 0.002307513291016221\n",
      "val set Loss: 0.00853857498926421\n",
      "-------epoch  985 -------\n",
      "train set Loss: 0.0022704080591211097\n",
      "val set Loss: 0.006457506213337183\n",
      "-------epoch  986 -------\n",
      "train set Loss: 0.00209397909042309\n",
      "val set Loss: 0.008448743765863279\n",
      "-------epoch  987 -------\n",
      "train set Loss: 0.0018687418522313236\n",
      "val set Loss: 0.006582620573074867\n",
      "-------epoch  988 -------\n",
      "train set Loss: 0.0018374478897021619\n",
      "val set Loss: 0.00906403906022509\n",
      "-------epoch  989 -------\n",
      "train set Loss: 0.001764915216481313\n",
      "val set Loss: 0.0066592976412114995\n",
      "-------epoch  990 -------\n",
      "train set Loss: 0.0019104816194158048\n",
      "val set Loss: 0.009259259454362715\n",
      "-------epoch  991 -------\n",
      "train set Loss: 0.0018492926089675166\n",
      "val set Loss: 0.007025772812388216\n",
      "-------epoch  992 -------\n",
      "train set Loss: 0.0018912643611838575\n",
      "val set Loss: 0.009212934024011096\n",
      "-------epoch  993 -------\n",
      "train set Loss: 0.0018365912559966092\n",
      "val set Loss: 0.006789566551257546\n",
      "-------epoch  994 -------\n",
      "train set Loss: 0.001798227746185148\n",
      "val set Loss: 0.009559484819571177\n",
      "-------epoch  995 -------\n",
      "train set Loss: 0.0016430812886392232\n",
      "val set Loss: 0.007236145640490577\n",
      "-------epoch  996 -------\n",
      "train set Loss: 0.0016607074381317943\n",
      "val set Loss: 0.009533587493933737\n",
      "-------epoch  997 -------\n",
      "train set Loss: 0.0016444070860598004\n",
      "val set Loss: 0.007213337473028029\n",
      "-------epoch  998 -------\n",
      "train set Loss: 0.001768930260295747\n",
      "val set Loss: 0.009606213890947402\n",
      "-------epoch  999 -------\n",
      "train set Loss: 0.001823178675113013\n",
      "val set Loss: 0.007218491286039352\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "# checking if GPU is available\n",
    "device = torch.device(\"cpu\")\n",
    "if (torch.cuda.is_available()):\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print('Training on GPU.')\n",
    "else:\n",
    "    print('No GPU available, training on CPU.')\n",
    "\n",
    "# 构建模型\n",
    "model = LSTMModel(input_size=input_size,\n",
    "                  hidden_size=hidden_size,\n",
    "                  output_size=output_size,\n",
    "                  num_layers = num_layers)\n",
    "model = model.to(device) # lstm doesnt work on gpu?\n",
    "# train\n",
    "train_dataset = LoadDataset(train_directory, seq_len=seq_len, features=features)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "# validation\n",
    "val_dataset = LoadDataset(val_directory, seq_len=seq_len, features=features)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 储存路径\n",
    "work_dir = './LSTM'\n",
    "# 添加tensorboard\n",
    "writer = SummaryWriter(\"{}/logs\".format(work_dir))\n",
    "\n",
    "# model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "# checkponits = epoch // 5\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(epoch):\n",
    "    print(\"-------epoch  {} -------\".format(epoch))\n",
    "    # 训练步骤\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for train_data, train_data_real in train_dataloader:\n",
    "        train_data = torch.squeeze(train_data).to(device)\n",
    "        train_data_real = torch.squeeze(train_data_real).to(device)\n",
    "\n",
    "        output = model(train_data)\n",
    "        output = torch.squeeze(output)\n",
    "        optimizer.zero_grad()\n",
    "        train_loss = criterion(output, train_data_real)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += train_loss.item()\n",
    "    avg_train_loss = total_train_loss/len(train_dataloader)\n",
    "    print(\"train set Loss: {}\".format(avg_train_loss)) # 出现nan可能是seq_len太长了,有些数据集比seq_len短\n",
    "\n",
    "    # 测试步骤\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():#用于在推断或验证阶段，当不需要计算梯度时，以提高效率和减少内存占用\n",
    "        for val_data, val_data_real in val_dataloader:\n",
    "            val_data = torch.squeeze(val_data).to(device)\n",
    "            val_data_real = torch.squeeze(val_data_real).to(device)\n",
    "\n",
    "            val_output = model(val_data)\n",
    "            val_output = torch.squeeze(val_output)\n",
    "            val_loss = criterion(val_output, val_data_real)\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss/len(val_dataloader)\n",
    "    print(\"val set Loss: {}\".format(avg_val_loss))\n",
    "\n",
    "    # save checkpoint\n",
    "    # if epochs % checkponits == 0:\n",
    "    if avg_train_loss < 0.0001  and avg_val_loss.item()< 0.0001 :\n",
    "        torch.save(model.state_dict(), str('EX_')+save_path[:-4]+str(epoch)+'.pth')\n",
    "        print(\"save model:epoch {}\".format(epoch))\n",
    "    if avg_train_loss < 0.0005  and avg_val_loss.item()< 0.0005 :\n",
    "        torch.save(model.state_dict(), str('A_')+save_path[:-4]+str(epoch)+'.pth')\n",
    "        print(\"save model:epoch {}\".format(epoch))\n",
    "    if avg_train_loss < 0.001  and avg_val_loss.item()< 0.001 :\n",
    "        torch.save(model.state_dict(), str('B_')+save_path[:-4]+str(epoch)+'.pth')\n",
    "        print(\"save model:epoch {}\".format(epoch))\n",
    "# save last1\n",
    "torch.save(model.state_dict(), save_path[:-4]+'last.pth')"
   ],
   "id": "a0ea029b5d94e7ad"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 3.eval and plot comparation"
   ],
   "id": "c048ac89b009992b"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T09:28:46.523686Z",
     "start_time": "2024-03-25T09:28:45.935980Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'seq20_last.pth'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 9\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# load\u001B[39;00m\n\u001B[1;32m      8\u001B[0m lstm \u001B[38;5;241m=\u001B[39m LSTMModel(input_size\u001B[38;5;241m=\u001B[39minput_size, hidden_size\u001B[38;5;241m=\u001B[39mhidden_size, output_size\u001B[38;5;241m=\u001B[39moutput_size, num_layers\u001B[38;5;241m=\u001B[39mnum_layers)\n\u001B[0;32m----> 9\u001B[0m lstm\u001B[38;5;241m.\u001B[39mload_state_dict(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43msave_path\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     10\u001B[0m lstm\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m     11\u001B[0m output \u001B[38;5;241m=\u001B[39m lstm(test_data)\n",
      "File \u001B[0;32m~/anaconda3/envs/quanti/lib/python3.8/site-packages/torch/serialization.py:791\u001B[0m, in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001B[0m\n\u001B[1;32m    788\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m pickle_load_args\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m    789\u001B[0m     pickle_load_args[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m--> 791\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_file_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_file:\n\u001B[1;32m    792\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_zipfile(opened_file):\n\u001B[1;32m    793\u001B[0m         \u001B[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001B[39;00m\n\u001B[1;32m    794\u001B[0m         \u001B[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001B[39;00m\n\u001B[1;32m    795\u001B[0m         \u001B[38;5;66;03m# reset back to the original position.\u001B[39;00m\n\u001B[1;32m    796\u001B[0m         orig_position \u001B[38;5;241m=\u001B[39m opened_file\u001B[38;5;241m.\u001B[39mtell()\n",
      "File \u001B[0;32m~/anaconda3/envs/quanti/lib/python3.8/site-packages/torch/serialization.py:271\u001B[0m, in \u001B[0;36m_open_file_like\u001B[0;34m(name_or_buffer, mode)\u001B[0m\n\u001B[1;32m    269\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_open_file_like\u001B[39m(name_or_buffer, mode):\n\u001B[1;32m    270\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_path(name_or_buffer):\n\u001B[0;32m--> 271\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_open_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    272\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    273\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n",
      "File \u001B[0;32m~/anaconda3/envs/quanti/lib/python3.8/site-packages/torch/serialization.py:252\u001B[0m, in \u001B[0;36m_open_file.__init__\u001B[0;34m(self, name, mode)\u001B[0m\n\u001B[1;32m    251\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, mode):\n\u001B[0;32m--> 252\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'seq20_last.pth'"
     ]
    }
   ],
   "source": [
    "test_battery_id = 'B0018'\n",
    "# save_path = save_path\n",
    "save_path = 'seq20_last.pth'\n",
    "\n",
    "test_battery_path = test_directory+ test_battery_id + '.mat'\n",
    "test_data,test_data_real = data_loader(test_battery_path,seq_len,features)\n",
    "# load\n",
    "lstm = LSTMModel(input_size=input_size, hidden_size=hidden_size, output_size=output_size, num_layers=num_layers)\n",
    "lstm.load_state_dict(torch.load(save_path))\n",
    "lstm.eval()\n",
    "output = lstm(test_data)\n",
    "predicted_data = output.detach().numpy().reshape(-1)\n",
    "print(predicted_data.shape)\n",
    "\n",
    "# draw\n",
    "origin_data = norm_data(test_battery_path) # dictionary\n",
    "sns.set_style(\"white\")\n",
    "plt.figure(figsize=(8, 5))\n",
    "#Draw\n",
    "plt.plot([i for i in range(len(origin_data['SOH']))], origin_data['SOH'], label='SOH')\n",
    "# predicted_data = np.concatenate((origin_data['SOH'][0:seq_len],predicted_data), axis = 0)\n",
    "plt.plot([i for i in range(seq_len,len(origin_data['SOH']))], predicted_data, label='Predicted SOH')\n",
    "plt.plot([0.,len(origin_data['SOH'])], [0.70, 0.70], label='Threshold')\n",
    "\n",
    "# make x-axis ticks legible\n",
    "adf = plt.gca().get_xaxis().get_major_formatter()\n",
    "plt.xlabel('cycle')\n",
    "plt.ylabel('SOH')\n",
    "plt.title('Discharge {}'.format(test_battery_id))\n",
    "\n",
    "\n",
    "MAE =  np.mean(np.abs(predicted_data - origin_data['SOH'][seq_len:]))\n",
    "MAPE = np.mean(np.abs((origin_data['SOH'][seq_len:] - predicted_data) / origin_data['SOH'][seq_len:]))\n",
    "MSE = np.mean((predicted_data - origin_data['SOH'][seq_len:]) ** 2)\n",
    "RMSE = np.sqrt(MSE)\n",
    "print('MAE:{}'.format(MAE))\n",
    "print('MAPE:{}'.format(MAPE))\n",
    "print('MSE:{}'.format(MSE))\n",
    "print('RMSE:{}'.format(RMSE))"
   ],
   "id": "7b6efadd8c3db5c8"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [],
   "id": "ab1d5c7bb3d33233"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
