{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-28T06:36:54.399242Z",
     "start_time": "2024-03-28T06:36:52.433807Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1.hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T06:37:01.255832Z",
     "start_time": "2024-03-28T06:37:01.252492Z"
    }
   },
   "outputs": [],
   "source": [
    "# hyper\n",
    "features = ['SOH','voltage_measured', 'current_measured',\n",
    "            'temperature_measured', 'time']\n",
    "batch_size = 1  # 1*len(every_file)\n",
    "input_size = len(features)\n",
    "hidden_size = 128\n",
    "num_layers = 1\n",
    "output_size = 1\n",
    "seq_len = 20   # 预测序列长度\n",
    "epoch = 500   # 1*len(train_directory)\n",
    "learning_rate = 0.001  # upgrade to adaptive lr?\n",
    "\n",
    "save_path = 'seq{}_.pth'.format(str(seq_len))  # model path\n",
    "train_directory = '../datasets/train/'\n",
    "val_directory = '../datasets/val/'\n",
    "test_directory = '../datasets/alldataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T07:46:25.467798Z",
     "start_time": "2024-03-28T06:37:02.221326Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU.\n",
      "-------epoch  0 -------\n",
      "train set Loss: 0.3081004764139652\n",
      "val set Loss: 0.21314329405625662\n",
      "-------epoch  1 -------\n",
      "train set Loss: 0.24179610927589237\n",
      "val set Loss: 0.05799399440487226\n",
      "-------epoch  2 -------\n",
      "train set Loss: 0.17695694818161428\n",
      "val set Loss: 0.014206769255300363\n",
      "-------epoch  3 -------\n",
      "train set Loss: 0.1385323558934033\n",
      "val set Loss: 0.041642249251405396\n",
      "-------epoch  4 -------\n",
      "train set Loss: 0.13191318767145277\n",
      "val set Loss: 0.06665029749274254\n",
      "-------epoch  5 -------\n",
      "train set Loss: 0.11686185862869024\n",
      "val set Loss: 0.05226448364555836\n",
      "-------epoch  6 -------\n",
      "train set Loss: 0.0709448061697185\n",
      "val set Loss: 0.02043652596573035\n",
      "-------epoch  7 -------\n",
      "train set Loss: 0.05856394522532355\n",
      "val set Loss: 0.03357184290265044\n",
      "-------epoch  8 -------\n",
      "train set Loss: 0.033917240211740134\n",
      "val set Loss: 0.008113949676044285\n",
      "-------epoch  9 -------\n",
      "train set Loss: 0.027575690841767937\n",
      "val set Loss: 0.005939080651539068\n",
      "-------epoch  10 -------\n",
      "train set Loss: 0.021501920777373017\n",
      "val set Loss: 0.0033452060694495835\n",
      "-------epoch  11 -------\n",
      "train set Loss: 0.021985750325693516\n",
      "val set Loss: 0.004741311655379832\n",
      "-------epoch  12 -------\n",
      "train set Loss: 0.044627715340757275\n",
      "val set Loss: 0.011174143912891546\n",
      "-------epoch  13 -------\n",
      "train set Loss: 0.062276170942350294\n",
      "val set Loss: 0.02750690033038457\n",
      "-------epoch  14 -------\n",
      "train set Loss: 0.049577833609073425\n",
      "val set Loss: 0.026492643790940445\n",
      "-------epoch  15 -------\n",
      "train set Loss: 0.03718853118596598\n",
      "val set Loss: 0.027761109173297882\n",
      "-------epoch  16 -------\n",
      "train set Loss: 0.0776624595472822\n",
      "val set Loss: 0.05849828633169333\n",
      "-------epoch  17 -------\n",
      "train set Loss: 0.033863104213960465\n",
      "val set Loss: 0.006969727886219819\n",
      "-------epoch  18 -------\n",
      "train set Loss: 0.02053230093384627\n",
      "val set Loss: 0.0042451680831921594\n",
      "-------epoch  19 -------\n",
      "train set Loss: 0.01801239095570054\n",
      "val set Loss: 0.005572347280879815\n",
      "-------epoch  20 -------\n",
      "train set Loss: 0.0176441747797071\n",
      "val set Loss: 0.0036198890690381327\n",
      "-------epoch  21 -------\n",
      "train set Loss: 0.017212105246144346\n",
      "val set Loss: 0.003128544563272347\n",
      "-------epoch  22 -------\n",
      "train set Loss: 0.01700352386891609\n",
      "val set Loss: 0.0027424105937825516\n",
      "-------epoch  23 -------\n",
      "train set Loss: 0.0167551908607129\n",
      "val set Loss: 0.0026026257352593043\n",
      "-------epoch  24 -------\n",
      "train set Loss: 0.016613916036731097\n",
      "val set Loss: 0.0027619497365473458\n",
      "-------epoch  25 -------\n",
      "train set Loss: 0.016547159762703812\n",
      "val set Loss: 0.0034727152863827846\n",
      "-------epoch  26 -------\n",
      "train set Loss: 0.0168486919690622\n",
      "val set Loss: 0.005138376960530877\n",
      "-------epoch  27 -------\n",
      "train set Loss: 0.01756903622765094\n",
      "val set Loss: 0.00822941151758035\n",
      "-------epoch  28 -------\n",
      "train set Loss: 0.019191058450378478\n",
      "val set Loss: 0.012687971039364735\n",
      "-------epoch  29 -------\n",
      "train set Loss: 0.020480948232288937\n",
      "val set Loss: 0.017967484270532925\n",
      "-------epoch  30 -------\n",
      "train set Loss: 0.03927155964018311\n",
      "val set Loss: 0.03865614471336206\n",
      "-------epoch  31 -------\n",
      "train set Loss: 0.04534963039215654\n",
      "val set Loss: 0.026206431289513905\n",
      "-------epoch  32 -------\n",
      "train set Loss: 0.041123816833132876\n",
      "val set Loss: 0.021093984600156546\n",
      "-------epoch  33 -------\n",
      "train set Loss: 0.026576875038444997\n",
      "val set Loss: 0.011202217700580755\n",
      "-------epoch  34 -------\n",
      "train set Loss: 0.03204865017556585\n",
      "val set Loss: 0.016904824879020452\n",
      "-------epoch  35 -------\n",
      "train set Loss: 0.019853978051105513\n",
      "val set Loss: 0.0036095615165929\n",
      "-------epoch  36 -------\n",
      "train set Loss: 0.0198377254587831\n",
      "val set Loss: 0.007562021162205686\n",
      "-------epoch  37 -------\n",
      "train set Loss: 0.015958171868114733\n",
      "val set Loss: 0.003477405523881316\n",
      "-------epoch  38 -------\n",
      "train set Loss: 0.01688203992205672\n",
      "val set Loss: 0.00679226500991111\n",
      "-------epoch  39 -------\n",
      "train set Loss: 0.014626379561086651\n",
      "val set Loss: 0.0033947683793182173\n",
      "-------epoch  40 -------\n",
      "train set Loss: 0.018074602431443054\n",
      "val set Loss: 0.006820495618740097\n",
      "-------epoch  41 -------\n",
      "train set Loss: 0.015933626596815884\n",
      "val set Loss: 0.0033623781734301397\n",
      "-------epoch  42 -------\n",
      "train set Loss: 0.016026477235136553\n",
      "val set Loss: 0.005650511438337465\n",
      "-------epoch  43 -------\n",
      "train set Loss: 0.01330821826675674\n",
      "val set Loss: 0.0030045474607807896\n",
      "-------epoch  44 -------\n",
      "train set Loss: 0.013485933408082929\n",
      "val set Loss: 0.005154201372837027\n",
      "-------epoch  45 -------\n",
      "train set Loss: 0.012405697077338119\n",
      "val set Loss: 0.0038645304545449712\n",
      "-------epoch  46 -------\n",
      "train set Loss: 0.014726421274535823\n",
      "val set Loss: 0.006824343407060951\n",
      "-------epoch  47 -------\n",
      "train set Loss: 0.013784465484204702\n",
      "val set Loss: 0.004354883567430079\n",
      "-------epoch  48 -------\n",
      "train set Loss: 0.019314676197827795\n",
      "val set Loss: 0.010932124375055233\n",
      "-------epoch  49 -------\n",
      "train set Loss: 0.0157645765657071\n",
      "val set Loss: 0.003939773382929464\n",
      "-------epoch  50 -------\n",
      "train set Loss: 0.018975183281581848\n",
      "val set Loss: 0.011952268658205867\n",
      "-------epoch  51 -------\n",
      "train set Loss: 0.013829224561341107\n",
      "val set Loss: 0.003499810448071609\n",
      "-------epoch  52 -------\n",
      "train set Loss: 0.013819238294963725\n",
      "val set Loss: 0.007819936028681695\n",
      "-------epoch  53 -------\n",
      "train set Loss: 0.012443682362500113\n",
      "val set Loss: 0.004661542790321012\n",
      "-------epoch  54 -------\n",
      "train set Loss: 0.014374233421403915\n",
      "val set Loss: 0.008322684676386416\n",
      "-------epoch  55 -------\n",
      "train set Loss: 0.013290454587258865\n",
      "val set Loss: 0.004033562572052081\n",
      "-------epoch  56 -------\n",
      "train set Loss: 0.016479760077781975\n",
      "val set Loss: 0.008443948851587871\n",
      "-------epoch  57 -------\n",
      "train set Loss: 0.013533514613518491\n",
      "val set Loss: 0.003406321629881859\n",
      "-------epoch  58 -------\n",
      "train set Loss: 0.014737909627729095\n",
      "val set Loss: 0.007033676471716414\n",
      "-------epoch  59 -------\n",
      "train set Loss: 0.012044506169622764\n",
      "val set Loss: 0.00328303239075467\n",
      "-------epoch  60 -------\n",
      "train set Loss: 0.012350361375138164\n",
      "val set Loss: 0.005658407074709733\n",
      "-------epoch  61 -------\n",
      "train set Loss: 0.011257539953221566\n",
      "val set Loss: 0.003359708139517655\n",
      "-------epoch  62 -------\n",
      "train set Loss: 0.012045783732319251\n",
      "val set Loss: 0.005164575598125036\n",
      "-------epoch  63 -------\n",
      "train set Loss: 0.011313006010313984\n",
      "val set Loss: 0.0032669628077807524\n",
      "-------epoch  64 -------\n",
      "train set Loss: 0.012373013824690133\n",
      "val set Loss: 0.00513304127768303\n",
      "-------epoch  65 -------\n",
      "train set Loss: 0.01135327737487387\n",
      "val set Loss: 0.003242221583301822\n",
      "-------epoch  66 -------\n",
      "train set Loss: 0.012284482744289562\n",
      "val set Loss: 0.004682734822078298\n",
      "-------epoch  67 -------\n",
      "train set Loss: 0.011187464552931488\n",
      "val set Loss: 0.00317813020471173\n",
      "-------epoch  68 -------\n",
      "train set Loss: 0.012213723818713334\n",
      "val set Loss: 0.005044273702272524\n",
      "-------epoch  69 -------\n",
      "train set Loss: 0.01130176976090297\n",
      "val set Loss: 0.0032835665915627033\n",
      "-------epoch  70 -------\n",
      "train set Loss: 0.011423044963157736\n",
      "val set Loss: 0.004098825399220611\n",
      "-------epoch  71 -------\n",
      "train set Loss: 0.010304315849207341\n",
      "val set Loss: 0.003168059503271555\n",
      "-------epoch  72 -------\n",
      "train set Loss: 0.010385710299597123\n",
      "val set Loss: 0.004235579011340936\n",
      "-------epoch  73 -------\n",
      "train set Loss: 0.010053325269836932\n",
      "val set Loss: 0.0031923273345455527\n",
      "-------epoch  74 -------\n",
      "train set Loss: 0.010460269128670915\n",
      "val set Loss: 0.003811141252905751\n",
      "-------epoch  75 -------\n",
      "train set Loss: 0.010186299514607526\n",
      "val set Loss: 0.0031839962175581604\n",
      "-------epoch  76 -------\n",
      "train set Loss: 0.010644409974338487\n",
      "val set Loss: 0.00438804523825335\n",
      "-------epoch  77 -------\n",
      "train set Loss: 0.010505589690292255\n",
      "val set Loss: 0.0033142865480234227\n",
      "-------epoch  78 -------\n",
      "train set Loss: 0.010913406141917222\n",
      "val set Loss: 0.003552420161819706\n",
      "-------epoch  79 -------\n",
      "train set Loss: 0.009576983921579085\n",
      "val set Loss: 0.0030686346775231263\n",
      "-------epoch  80 -------\n",
      "train set Loss: 0.01016914403589908\n",
      "val set Loss: 0.004573737484558175\n",
      "-------epoch  81 -------\n",
      "train set Loss: 0.010512557098409162\n",
      "val set Loss: 0.0030737961060367525\n",
      "-------epoch  82 -------\n",
      "train set Loss: 0.011677078418433667\n",
      "val set Loss: 0.003667539257245759\n",
      "-------epoch  83 -------\n",
      "train set Loss: 0.010167382673826069\n",
      "val set Loss: 0.003132342176589494\n",
      "-------epoch  84 -------\n",
      "train set Loss: 0.011522927857004105\n",
      "val set Loss: 0.003400246539968066\n",
      "-------epoch  85 -------\n",
      "train set Loss: 0.009916804818785749\n",
      "val set Loss: 0.0028028003871440887\n",
      "-------epoch  86 -------\n",
      "train set Loss: 0.009718627129623202\n",
      "val set Loss: 0.003313985711429268\n",
      "-------epoch  87 -------\n",
      "train set Loss: 0.008759135664440691\n",
      "val set Loss: 0.002792617970650705\n",
      "-------epoch  88 -------\n",
      "train set Loss: 0.009107595345412847\n",
      "val set Loss: 0.0031815090672656274\n",
      "-------epoch  89 -------\n",
      "train set Loss: 0.008770594195229933\n",
      "val set Loss: 0.0027722670881000036\n",
      "-------epoch  90 -------\n",
      "train set Loss: 0.009400801765732467\n",
      "val set Loss: 0.0032493342296220362\n",
      "-------epoch  91 -------\n",
      "train set Loss: 0.009115137007902376\n",
      "val set Loss: 0.00281067731945465\n",
      "-------epoch  92 -------\n",
      "train set Loss: 0.010154182878613938\n",
      "val set Loss: 0.0034466216602595523\n",
      "-------epoch  93 -------\n",
      "train set Loss: 0.009386950596235693\n",
      "val set Loss: 0.002952499819609026\n",
      "-------epoch  94 -------\n",
      "train set Loss: 0.009813583354407455\n",
      "val set Loss: 0.0031585919932695106\n",
      "-------epoch  95 -------\n",
      "train set Loss: 0.009717140935827047\n",
      "val set Loss: 0.003177820200410982\n",
      "-------epoch  96 -------\n",
      "train set Loss: 0.01186956035962794\n",
      "val set Loss: 0.0033984597345503667\n",
      "-------epoch  97 -------\n",
      "train set Loss: 0.009630110421567225\n",
      "val set Loss: 0.003226351235449935\n",
      "-------epoch  98 -------\n",
      "train set Loss: 0.008748271153890527\n",
      "val set Loss: 0.003498870355542749\n",
      "-------epoch  99 -------\n",
      "train set Loss: 0.008502684354316442\n",
      "val set Loss: 0.0028156415743675702\n",
      "-------epoch  100 -------\n",
      "train set Loss: 0.008535737808560952\n",
      "val set Loss: 0.0033957604221844426\n",
      "-------epoch  101 -------\n",
      "train set Loss: 0.00868016675231047\n",
      "val set Loss: 0.002979026826020951\n",
      "-------epoch  102 -------\n",
      "train set Loss: 0.008727830924617591\n",
      "val set Loss: 0.0037174514145590365\n",
      "-------epoch  103 -------\n",
      "train set Loss: 0.008977830063086003\n",
      "val set Loss: 0.003065794051508419\n",
      "-------epoch  104 -------\n",
      "train set Loss: 0.009274553269788157\n",
      "val set Loss: 0.004490000234606366\n",
      "-------epoch  105 -------\n",
      "train set Loss: 0.00967773874872364\n",
      "val set Loss: 0.0030067316498995447\n",
      "-------epoch  106 -------\n",
      "train set Loss: 0.010241977995610796\n",
      "val set Loss: 0.004699753830209374\n",
      "-------epoch  107 -------\n",
      "train set Loss: 0.009918903918005526\n",
      "val set Loss: 0.0034479455741044753\n",
      "-------epoch  108 -------\n",
      "train set Loss: 0.010172027091612109\n",
      "val set Loss: 0.005530668810630838\n",
      "-------epoch  109 -------\n",
      "train set Loss: 0.010103404775727541\n",
      "val set Loss: 0.0030359006098782024\n",
      "-------epoch  110 -------\n",
      "train set Loss: 0.010433085489203221\n",
      "val set Loss: 0.005964222053686778\n",
      "-------epoch  111 -------\n",
      "train set Loss: 0.010208107756916433\n",
      "val set Loss: 0.0029907921901515997\n",
      "-------epoch  112 -------\n",
      "train set Loss: 0.01063564326672349\n",
      "val set Loss: 0.008241440208318332\n",
      "-------epoch  113 -------\n",
      "train set Loss: 0.010226589041994884\n",
      "val set Loss: 0.003552738615932564\n",
      "-------epoch  114 -------\n",
      "train set Loss: 0.012326973048329819\n",
      "val set Loss: 0.0027023277361877263\n",
      "-------epoch  115 -------\n",
      "train set Loss: 0.01000464306678623\n",
      "val set Loss: 0.0027685325064036683\n",
      "-------epoch  116 -------\n",
      "train set Loss: 0.011382353936787694\n",
      "val set Loss: 0.0041729067064200836\n",
      "-------epoch  117 -------\n",
      "train set Loss: 0.012442523167701438\n",
      "val set Loss: 0.002713269136923676\n",
      "-------epoch  118 -------\n",
      "train set Loss: 0.015368655871716328\n",
      "val set Loss: 0.0042378601695721345\n",
      "-------epoch  119 -------\n",
      "train set Loss: 0.009137246694881468\n",
      "val set Loss: 0.003754002672697728\n",
      "-------epoch  120 -------\n",
      "train set Loss: 0.008411285182228312\n",
      "val set Loss: 0.0034499865335722766\n",
      "-------epoch  121 -------\n",
      "train set Loss: 0.008587513492675497\n",
      "val set Loss: 0.0036698539818947515\n",
      "-------epoch  122 -------\n",
      "train set Loss: 0.00820590481394902\n",
      "val set Loss: 0.003204890943986053\n",
      "-------epoch  123 -------\n",
      "train set Loss: 0.008130199289298616\n",
      "val set Loss: 0.0039139519988869624\n",
      "-------epoch  124 -------\n",
      "train set Loss: 0.008379695350304245\n",
      "val set Loss: 0.0032422085447857776\n",
      "-------epoch  125 -------\n",
      "train set Loss: 0.008785596292000264\n",
      "val set Loss: 0.005046756976904969\n",
      "-------epoch  126 -------\n",
      "train set Loss: 0.009219885973725467\n",
      "val set Loss: 0.003130310540048716\n",
      "-------epoch  127 -------\n",
      "train set Loss: 0.010349318493390457\n",
      "val set Loss: 0.00910099440564712\n",
      "-------epoch  128 -------\n",
      "train set Loss: 0.010776567441644147\n",
      "val set Loss: 0.002751341894812261\n",
      "-------epoch  129 -------\n",
      "train set Loss: 0.011812638752162456\n",
      "val set Loss: 0.006714848103001714\n",
      "-------epoch  130 -------\n",
      "train set Loss: 0.010763450034428388\n",
      "val set Loss: 0.004433829608994226\n",
      "-------epoch  131 -------\n",
      "train set Loss: 0.00939860633923672\n",
      "val set Loss: 0.005729499758065988\n",
      "-------epoch  132 -------\n",
      "train set Loss: 0.00981203931150958\n",
      "val set Loss: 0.00429538800381124\n",
      "-------epoch  133 -------\n",
      "train set Loss: 0.010422138557187282\n",
      "val set Loss: 0.00966387395358955\n",
      "-------epoch  134 -------\n",
      "train set Loss: 0.011215486434521154\n",
      "val set Loss: 0.004954730335157365\n",
      "-------epoch  135 -------\n",
      "train set Loss: 0.009614847244811243\n",
      "val set Loss: 0.006293699533368151\n",
      "-------epoch  136 -------\n",
      "train set Loss: 0.009638868444599212\n",
      "val set Loss: 0.005872886627912521\n",
      "-------epoch  137 -------\n",
      "train set Loss: 0.010388896358199418\n",
      "val set Loss: 0.008060000759238998\n",
      "-------epoch  138 -------\n",
      "train set Loss: 0.010452856925548986\n",
      "val set Loss: 0.0069250564168517785\n",
      "-------epoch  139 -------\n",
      "train set Loss: 0.011203210009261966\n",
      "val set Loss: 0.009978944552130997\n",
      "-------epoch  140 -------\n",
      "train set Loss: 0.012220587662886829\n",
      "val set Loss: 0.009593632111015419\n",
      "-------epoch  141 -------\n",
      "train set Loss: 0.011010519530973397\n",
      "val set Loss: 0.008977862540632486\n",
      "-------epoch  142 -------\n",
      "train set Loss: 0.010051040982361883\n",
      "val set Loss: 0.003992683758648734\n",
      "-------epoch  143 -------\n",
      "train set Loss: 0.012295784574234858\n",
      "val set Loss: 0.01202173282702764\n",
      "-------epoch  144 -------\n",
      "train set Loss: 0.013644517452921718\n",
      "val set Loss: 0.0047530565255632\n",
      "-------epoch  145 -------\n",
      "train set Loss: 0.015080381458392366\n",
      "val set Loss: 0.011980059711883465\n",
      "-------epoch  146 -------\n",
      "train set Loss: 0.016052003018558025\n",
      "val set Loss: 0.004020415071863681\n",
      "-------epoch  147 -------\n",
      "train set Loss: 0.020021766026038678\n",
      "val set Loss: 0.01881360588595271\n",
      "-------epoch  148 -------\n",
      "train set Loss: 0.014625205458141863\n",
      "val set Loss: 0.005101016179348032\n",
      "-------epoch  149 -------\n",
      "train set Loss: 0.013910398832522333\n",
      "val set Loss: 0.013916241470724344\n",
      "-------epoch  150 -------\n",
      "train set Loss: 0.014991488801315426\n",
      "val set Loss: 0.0037724344486681125\n",
      "-------epoch  151 -------\n",
      "train set Loss: 0.012506626641843467\n",
      "val set Loss: 0.008657910705854496\n",
      "-------epoch  152 -------\n",
      "train set Loss: 0.012207245160825551\n",
      "val set Loss: 0.006038621999323368\n",
      "-------epoch  153 -------\n",
      "train set Loss: 0.011051820311695337\n",
      "val set Loss: 0.008174107720454534\n",
      "-------epoch  154 -------\n",
      "train set Loss: 0.012288800312671811\n",
      "val set Loss: 0.009615271197011074\n",
      "-------epoch  155 -------\n",
      "train set Loss: 0.013466070110443979\n",
      "val set Loss: 0.01086248146990935\n",
      "-------epoch  156 -------\n",
      "train set Loss: 0.014466289766132831\n",
      "val set Loss: 0.013707795025159916\n",
      "-------epoch  157 -------\n",
      "train set Loss: 0.014741875920444727\n",
      "val set Loss: 0.009307510529955229\n",
      "-------epoch  158 -------\n",
      "train set Loss: 0.01760079026222229\n",
      "val set Loss: 0.002717123308684677\n",
      "-------epoch  159 -------\n",
      "train set Loss: 0.00915655410150066\n",
      "val set Loss: 0.0029724678897764534\n",
      "-------epoch  160 -------\n",
      "train set Loss: 0.013673598166787997\n",
      "val set Loss: 0.004800335892165701\n",
      "-------epoch  161 -------\n",
      "train set Loss: 0.01936791280983016\n",
      "val set Loss: 0.0030814718920737505\n",
      "-------epoch  162 -------\n",
      "train set Loss: 0.018606776107335462\n",
      "val set Loss: 0.005296326906924757\n",
      "-------epoch  163 -------\n",
      "train set Loss: 0.009580474243848584\n",
      "val set Loss: 0.004286916538452108\n",
      "-------epoch  164 -------\n",
      "train set Loss: 0.00917225353914546\n",
      "val set Loss: 0.004329522838816047\n",
      "-------epoch  165 -------\n",
      "train set Loss: 0.00920487514056731\n",
      "val set Loss: 0.005479264849176009\n",
      "-------epoch  166 -------\n",
      "train set Loss: 0.009689911749446764\n",
      "val set Loss: 0.005733203453322251\n",
      "-------epoch  167 -------\n",
      "train set Loss: 0.010263036964461207\n",
      "val set Loss: 0.0071846589756508665\n",
      "-------epoch  168 -------\n",
      "train set Loss: 0.011217136710183696\n",
      "val set Loss: 0.008683258512367805\n",
      "-------epoch  169 -------\n",
      "train set Loss: 0.011916463798843323\n",
      "val set Loss: 0.009461810967574516\n",
      "-------epoch  170 -------\n",
      "train set Loss: 0.013275404302403331\n",
      "val set Loss: 0.012116807512938976\n",
      "-------epoch  171 -------\n",
      "train set Loss: 0.013716301121748984\n",
      "val set Loss: 0.00820333044975996\n",
      "-------epoch  172 -------\n",
      "train set Loss: 0.010836919655557721\n",
      "val set Loss: 0.006718726751084129\n",
      "-------epoch  173 -------\n",
      "train set Loss: 0.011163353774463758\n",
      "val set Loss: 0.0030438544927164912\n",
      "-------epoch  174 -------\n",
      "train set Loss: 0.010355938514112494\n",
      "val set Loss: 0.003790546858605618\n",
      "-------epoch  175 -------\n",
      "train set Loss: 0.00868856804445386\n",
      "val set Loss: 0.006170241433816652\n",
      "-------epoch  176 -------\n",
      "train set Loss: 0.009209859667462296\n",
      "val set Loss: 0.007010329165495932\n",
      "-------epoch  177 -------\n",
      "train set Loss: 0.008601097249484156\n",
      "val set Loss: 0.0040829196126045035\n",
      "-------epoch  178 -------\n",
      "train set Loss: 0.007375918826437555\n",
      "val set Loss: 0.003294237055039654\n",
      "-------epoch  179 -------\n",
      "train set Loss: 0.007122984259040095\n",
      "val set Loss: 0.0029395096110723293\n",
      "-------epoch  180 -------\n",
      "train set Loss: 0.00704713549464941\n",
      "val set Loss: 0.002857934848483031\n",
      "-------epoch  181 -------\n",
      "train set Loss: 0.007069557970389724\n",
      "val set Loss: 0.0028520675259642303\n",
      "-------epoch  182 -------\n",
      "train set Loss: 0.006870564098935574\n",
      "val set Loss: 0.0029421428916975856\n",
      "-------epoch  183 -------\n",
      "train set Loss: 0.00686698543082457\n",
      "val set Loss: 0.0030561120268733553\n",
      "-------epoch  184 -------\n",
      "train set Loss: 0.006937680168775841\n",
      "val set Loss: 0.0034541188021345683\n",
      "-------epoch  185 -------\n",
      "train set Loss: 0.008038761159114075\n",
      "val set Loss: 0.003230655895701299\n",
      "-------epoch  186 -------\n",
      "train set Loss: 0.009028718506451696\n",
      "val set Loss: 0.003675186599139124\n",
      "-------epoch  187 -------\n",
      "train set Loss: 0.009868916586274281\n",
      "val set Loss: 0.004746592079754919\n",
      "-------epoch  188 -------\n",
      "train set Loss: 0.008222638563020156\n",
      "val set Loss: 0.003275359767333915\n",
      "-------epoch  189 -------\n",
      "train set Loss: 0.007491308258031495\n",
      "val set Loss: 0.00395237280948398\n",
      "-------epoch  190 -------\n",
      "train set Loss: 0.007099349158233963\n",
      "val set Loss: 0.003152346568337331\n",
      "-------epoch  191 -------\n",
      "train set Loss: 0.006911828614829574\n",
      "val set Loss: 0.0031140359545437\n",
      "-------epoch  192 -------\n",
      "train set Loss: 0.006886462324473541\n",
      "val set Loss: 0.0029324253749412796\n",
      "-------epoch  193 -------\n",
      "train set Loss: 0.00687043655780144\n",
      "val set Loss: 0.002936125121777877\n",
      "-------epoch  194 -------\n",
      "train set Loss: 0.00657027410750743\n",
      "val set Loss: 0.0028679705089113363\n",
      "-------epoch  195 -------\n",
      "train set Loss: 0.006429687092313543\n",
      "val set Loss: 0.0028873624445016808\n",
      "-------epoch  196 -------\n",
      "train set Loss: 0.006474126576504205\n",
      "val set Loss: 0.00297460681758821\n",
      "-------epoch  197 -------\n",
      "train set Loss: 0.006501702310342808\n",
      "val set Loss: 0.0028585128796597323\n",
      "-------epoch  198 -------\n",
      "train set Loss: 0.006659072335896781\n",
      "val set Loss: 0.0030836753042725227\n",
      "-------epoch  199 -------\n",
      "train set Loss: 0.007305954964831472\n",
      "val set Loss: 0.0032438047928735614\n",
      "-------epoch  200 -------\n",
      "train set Loss: 0.008991966690809932\n",
      "val set Loss: 0.004306356509914622\n",
      "-------epoch  201 -------\n",
      "train set Loss: 0.017085913693299516\n",
      "val set Loss: 0.009625140965605775\n",
      "-------epoch  202 -------\n",
      "train set Loss: 0.010499894034001044\n",
      "val set Loss: 0.00322509496860827\n",
      "-------epoch  203 -------\n",
      "train set Loss: 0.008294089315459132\n",
      "val set Loss: 0.0037417817511595786\n",
      "-------epoch  204 -------\n",
      "train set Loss: 0.008256495343230199\n",
      "val set Loss: 0.003969927784055471\n",
      "-------epoch  205 -------\n",
      "train set Loss: 0.011678161674644798\n",
      "val set Loss: 0.017373813316226006\n",
      "-------epoch  206 -------\n",
      "train set Loss: 0.01621339111123234\n",
      "val set Loss: 0.0030740713506626585\n",
      "-------epoch  207 -------\n",
      "train set Loss: 0.013027477395953611\n",
      "val set Loss: 0.015265142545104027\n",
      "-------epoch  208 -------\n",
      "train set Loss: 0.011553305515553803\n",
      "val set Loss: 0.005790976574644446\n",
      "-------epoch  209 -------\n",
      "train set Loss: 0.012621254701516591\n",
      "val set Loss: 0.015954288343588512\n",
      "-------epoch  210 -------\n",
      "train set Loss: 0.011419505546509754\n",
      "val set Loss: 0.008204457893346747\n",
      "-------epoch  211 -------\n",
      "train set Loss: 0.009349088016315364\n",
      "val set Loss: 0.006949545660366614\n",
      "-------epoch  212 -------\n",
      "train set Loss: 0.007545884900027886\n",
      "val set Loss: 0.00357351738299864\n",
      "-------epoch  213 -------\n",
      "train set Loss: 0.007408314062049612\n",
      "val set Loss: 0.0037012839068969092\n",
      "-------epoch  214 -------\n",
      "train set Loss: 0.007625297849881463\n",
      "val set Loss: 0.0037305544052893915\n",
      "-------epoch  215 -------\n",
      "train set Loss: 0.007846894360118312\n",
      "val set Loss: 0.004057255030299227\n",
      "-------epoch  216 -------\n",
      "train set Loss: 0.007982726015034131\n",
      "val set Loss: 0.003945499037702878\n",
      "-------epoch  217 -------\n",
      "train set Loss: 0.008103493786184118\n",
      "val set Loss: 0.004555152263492346\n",
      "-------epoch  218 -------\n",
      "train set Loss: 0.008077304447069764\n",
      "val set Loss: 0.004051066314180692\n",
      "-------epoch  219 -------\n",
      "train set Loss: 0.008230649188626558\n",
      "val set Loss: 0.0059379466498891515\n",
      "-------epoch  220 -------\n",
      "train set Loss: 0.007788784753065556\n",
      "val set Loss: 0.0035036925692111254\n",
      "-------epoch  221 -------\n",
      "train set Loss: 0.008701818363042547\n",
      "val set Loss: 0.0038900411066909633\n",
      "-------epoch  222 -------\n",
      "train set Loss: 0.013566653061716352\n",
      "val set Loss: 0.009048726875334978\n",
      "-------epoch  223 -------\n",
      "train set Loss: 0.015152993680385408\n",
      "val set Loss: 0.004139045408616464\n",
      "-------epoch  224 -------\n",
      "train set Loss: 0.012774023534730077\n",
      "val set Loss: 0.004819728841539472\n",
      "-------epoch  225 -------\n",
      "train set Loss: 0.011784532840829342\n",
      "val set Loss: 0.0034460813427964845\n",
      "-------epoch  226 -------\n",
      "train set Loss: 0.012419516467489303\n",
      "val set Loss: 0.0051939809539665776\n",
      "-------epoch  227 -------\n",
      "train set Loss: 0.008809644164284692\n",
      "val set Loss: 0.0036780631247286997\n",
      "-------epoch  228 -------\n",
      "train set Loss: 0.007710288324160501\n",
      "val set Loss: 0.0027771880365132042\n",
      "-------epoch  229 -------\n",
      "train set Loss: 0.007422440794180148\n",
      "val set Loss: 0.0030988347328578434\n",
      "-------epoch  230 -------\n",
      "train set Loss: 0.007253399579203687\n",
      "val set Loss: 0.0027869393913230547\n",
      "-------epoch  231 -------\n",
      "train set Loss: 0.007200502500636503\n",
      "val set Loss: 0.0029827262624166906\n",
      "-------epoch  232 -------\n",
      "train set Loss: 0.007087773170205765\n",
      "val set Loss: 0.0029000170373668275\n",
      "-------epoch  233 -------\n",
      "train set Loss: 0.007073549997294322\n",
      "val set Loss: 0.002949739592925956\n",
      "-------epoch  234 -------\n",
      "train set Loss: 0.006987086387816817\n",
      "val set Loss: 0.0029805697461900613\n",
      "-------epoch  235 -------\n",
      "train set Loss: 0.006980969926225953\n",
      "val set Loss: 0.002912139539451649\n",
      "-------epoch  236 -------\n",
      "train set Loss: 0.006858188563492149\n",
      "val set Loss: 0.003007131958535562\n",
      "-------epoch  237 -------\n",
      "train set Loss: 0.006792444775928743\n",
      "val set Loss: 0.002872069599106908\n",
      "-------epoch  238 -------\n",
      "train set Loss: 0.006612189565203153\n",
      "val set Loss: 0.002943446646289279\n",
      "-------epoch  239 -------\n",
      "train set Loss: 0.006494879586389288\n",
      "val set Loss: 0.002802957266491527\n",
      "-------epoch  240 -------\n",
      "train set Loss: 0.0063307826645905155\n",
      "val set Loss: 0.0028115414218821875\n",
      "-------epoch  241 -------\n",
      "train set Loss: 0.006226424029155169\n",
      "val set Loss: 0.002811943006236106\n",
      "-------epoch  242 -------\n",
      "train set Loss: 0.006220329035131727\n",
      "val set Loss: 0.003027031673506523\n",
      "-------epoch  243 -------\n",
      "train set Loss: 0.006456967461854219\n",
      "val set Loss: 0.003927069231091688\n",
      "-------epoch  244 -------\n",
      "train set Loss: 0.007002242335875053\n",
      "val set Loss: 0.005936748037735621\n",
      "-------epoch  245 -------\n",
      "train set Loss: 0.010555709403706714\n",
      "val set Loss: 0.00654355021348844\n",
      "-------epoch  246 -------\n",
      "train set Loss: 0.010722898481180892\n",
      "val set Loss: 0.007932867233951887\n",
      "-------epoch  247 -------\n",
      "train set Loss: 0.016923211854882537\n",
      "val set Loss: 0.017470196665575106\n",
      "-------epoch  248 -------\n",
      "train set Loss: 0.009656231646658853\n",
      "val set Loss: 0.00731570723777016\n",
      "-------epoch  249 -------\n",
      "train set Loss: 0.010795520604297053\n",
      "val set Loss: 0.009906085052837929\n",
      "-------epoch  250 -------\n",
      "train set Loss: 0.008181358748115599\n",
      "val set Loss: 0.0034838985496511063\n",
      "-------epoch  251 -------\n",
      "train set Loss: 0.007928035021468532\n",
      "val set Loss: 0.00490039138821885\n",
      "-------epoch  252 -------\n",
      "train set Loss: 0.007103668713825755\n",
      "val set Loss: 0.003328700258862227\n",
      "-------epoch  253 -------\n",
      "train set Loss: 0.007084295607346576\n",
      "val set Loss: 0.0036551904825804136\n",
      "-------epoch  254 -------\n",
      "train set Loss: 0.006920901067205705\n",
      "val set Loss: 0.003452666220255196\n",
      "-------epoch  255 -------\n",
      "train set Loss: 0.00697526702482719\n",
      "val set Loss: 0.0035464302636682987\n",
      "-------epoch  256 -------\n",
      "train set Loss: 0.006825757588376291\n",
      "val set Loss: 0.0037618999291832247\n",
      "-------epoch  257 -------\n",
      "train set Loss: 0.006897380311274901\n",
      "val set Loss: 0.0030192198852698007\n",
      "-------epoch  258 -------\n",
      "train set Loss: 0.007282307508867234\n",
      "val set Loss: 0.0028064149664714932\n",
      "-------epoch  259 -------\n",
      "train set Loss: 0.0072447882909909824\n",
      "val set Loss: 0.003264312671187023\n",
      "-------epoch  260 -------\n",
      "train set Loss: 0.008079504960332997\n",
      "val set Loss: 0.004461111462054153\n",
      "-------epoch  261 -------\n",
      "train set Loss: 0.007343662644270808\n",
      "val set Loss: 0.0036922754710152126\n",
      "-------epoch  262 -------\n",
      "train set Loss: 0.0074209168908419085\n",
      "val set Loss: 0.007818994034702579\n",
      "-------epoch  263 -------\n",
      "train set Loss: 0.008251010403037072\n",
      "val set Loss: 0.007116958770590524\n",
      "-------epoch  264 -------\n",
      "train set Loss: 0.0070074332502554175\n",
      "val set Loss: 0.006726385288250943\n",
      "-------epoch  265 -------\n",
      "train set Loss: 0.006698264587321319\n",
      "val set Loss: 0.00419691593075792\n",
      "-------epoch  266 -------\n",
      "train set Loss: 0.0060805469250772145\n",
      "val set Loss: 0.003002759525164341\n",
      "-------epoch  267 -------\n",
      "train set Loss: 0.006956292684189975\n",
      "val set Loss: 0.003795863672470053\n",
      "-------epoch  268 -------\n",
      "train set Loss: 0.006995263203280046\n",
      "val set Loss: 0.0028860465196582177\n",
      "-------epoch  269 -------\n",
      "train set Loss: 0.0074573624605545775\n",
      "val set Loss: 0.005137881031259894\n",
      "-------epoch  270 -------\n",
      "train set Loss: 0.008566648857668042\n",
      "val set Loss: 0.005084209590374182\n",
      "-------epoch  271 -------\n",
      "train set Loss: 0.009324012930737808\n",
      "val set Loss: 0.0032988697009083503\n",
      "-------epoch  272 -------\n",
      "train set Loss: 0.008483512727107154\n",
      "val set Loss: 0.0053105439292266965\n",
      "-------epoch  273 -------\n",
      "train set Loss: 0.009719335000263528\n",
      "val set Loss: 0.006653205258771777\n",
      "-------epoch  274 -------\n",
      "train set Loss: 0.007428464976255782\n",
      "val set Loss: 0.0076650391177584725\n",
      "-------epoch  275 -------\n",
      "train set Loss: 0.008080124034313485\n",
      "val set Loss: 0.006614516372792423\n",
      "-------epoch  276 -------\n",
      "train set Loss: 0.007408075488056057\n",
      "val set Loss: 0.00645990341824169\n",
      "-------epoch  277 -------\n",
      "train set Loss: 0.006990888905129396\n",
      "val set Loss: 0.005145487006908904\n",
      "-------epoch  278 -------\n",
      "train set Loss: 0.0065827330853790045\n",
      "val set Loss: 0.0037237385598321757\n",
      "-------epoch  279 -------\n",
      "train set Loss: 0.005813538962975144\n",
      "val set Loss: 0.0028809240514722965\n",
      "-------epoch  280 -------\n",
      "train set Loss: 0.007305514195468277\n",
      "val set Loss: 0.00615804778256764\n",
      "-------epoch  281 -------\n",
      "train set Loss: 0.009770211093127727\n",
      "val set Loss: 0.0034540623310022056\n",
      "-------epoch  282 -------\n",
      "train set Loss: 0.0075196838483680035\n",
      "val set Loss: 0.0028322206247442714\n",
      "-------epoch  283 -------\n",
      "train set Loss: 0.006663216453744098\n",
      "val set Loss: 0.004984443366993219\n",
      "-------epoch  284 -------\n",
      "train set Loss: 0.005870028251665644\n",
      "val set Loss: 0.003449032665230334\n",
      "-------epoch  285 -------\n",
      "train set Loss: 0.005708887293585576\n",
      "val set Loss: 0.0031146002584137022\n",
      "-------epoch  286 -------\n",
      "train set Loss: 0.005503726582974195\n",
      "val set Loss: 0.0036364003705481687\n",
      "-------epoch  287 -------\n",
      "train set Loss: 0.005356077674368862\n",
      "val set Loss: 0.002923150769978141\n",
      "-------epoch  288 -------\n",
      "train set Loss: 0.005176229202770628\n",
      "val set Loss: 0.0033608806552365422\n",
      "-------epoch  289 -------\n",
      "train set Loss: 0.0051621525469818155\n",
      "val set Loss: 0.0033568317885510623\n",
      "-------epoch  290 -------\n",
      "train set Loss: 0.005477042178972625\n",
      "val set Loss: 0.0033963351355244717\n",
      "-------epoch  291 -------\n",
      "train set Loss: 0.005944073711289093\n",
      "val set Loss: 0.005786345883583029\n",
      "-------epoch  292 -------\n",
      "train set Loss: 0.008025843577925115\n",
      "val set Loss: 0.005615343320338677\n",
      "-------epoch  293 -------\n",
      "train set Loss: 0.00855106517788954\n",
      "val set Loss: 0.009985857177525759\n",
      "-------epoch  294 -------\n",
      "train set Loss: 0.014555982068413869\n",
      "val set Loss: 0.004087877003864075\n",
      "-------epoch  295 -------\n",
      "train set Loss: 0.010717251468449832\n",
      "val set Loss: 0.0047578332014381886\n",
      "-------epoch  296 -------\n",
      "train set Loss: 0.025597045390168206\n",
      "val set Loss: 0.006468357882113196\n",
      "-------epoch  297 -------\n",
      "train set Loss: 0.0805333195195999\n",
      "val set Loss: 0.023081193988521893\n",
      "-------epoch  298 -------\n",
      "train set Loss: 0.04567624413874\n",
      "val set Loss: 0.009115604683756828\n",
      "-------epoch  299 -------\n",
      "train set Loss: 0.021113208506139926\n",
      "val set Loss: 0.018287820431093376\n",
      "-------epoch  300 -------\n",
      "train set Loss: 0.034180319854058325\n",
      "val set Loss: 0.0382134560495615\n",
      "-------epoch  301 -------\n",
      "train set Loss: 0.02634076710412046\n",
      "val set Loss: 0.022643960701922577\n",
      "-------epoch  302 -------\n",
      "train set Loss: 0.015100135242100805\n",
      "val set Loss: 0.00857827055733651\n",
      "-------epoch  303 -------\n",
      "train set Loss: 0.010371650140732526\n",
      "val set Loss: 0.009320336782063047\n",
      "-------epoch  304 -------\n",
      "train set Loss: 0.009435212584212422\n",
      "val set Loss: 0.006995629829665025\n",
      "-------epoch  305 -------\n",
      "train set Loss: 0.00844824115454685\n",
      "val set Loss: 0.0037220174369091787\n",
      "-------epoch  306 -------\n",
      "train set Loss: 0.007592902256874368\n",
      "val set Loss: 0.003366093607231354\n",
      "-------epoch  307 -------\n",
      "train set Loss: 0.006961185114341788\n",
      "val set Loss: 0.003469459848323216\n",
      "-------epoch  308 -------\n",
      "train set Loss: 0.006772802714840509\n",
      "val set Loss: 0.003243690385716036\n",
      "-------epoch  309 -------\n",
      "train set Loss: 0.00659287702961592\n",
      "val set Loss: 0.003412914724322036\n",
      "-------epoch  310 -------\n",
      "train set Loss: 0.0065271344664506615\n",
      "val set Loss: 0.0032076961263859025\n",
      "-------epoch  311 -------\n",
      "train set Loss: 0.006436098812846467\n",
      "val set Loss: 0.0033734422468114644\n",
      "-------epoch  312 -------\n",
      "train set Loss: 0.006450878693722188\n",
      "val set Loss: 0.0030870497964012125\n",
      "-------epoch  313 -------\n",
      "train set Loss: 0.006461487978813238\n",
      "val set Loss: 0.003528504273466145\n",
      "-------epoch  314 -------\n",
      "train set Loss: 0.0066348218015627935\n",
      "val set Loss: 0.0030218580019815513\n",
      "-------epoch  315 -------\n",
      "train set Loss: 0.006756136039621196\n",
      "val set Loss: 0.003986411165290822\n",
      "-------epoch  316 -------\n",
      "train set Loss: 0.0068824130593566225\n",
      "val set Loss: 0.003025669459020719\n",
      "-------epoch  317 -------\n",
      "train set Loss: 0.006777600850327871\n",
      "val set Loss: 0.004350275800485785\n",
      "-------epoch  318 -------\n",
      "train set Loss: 0.006511984689277597\n",
      "val set Loss: 0.0030182445916580036\n",
      "-------epoch  319 -------\n",
      "train set Loss: 0.006242864184896462\n",
      "val set Loss: 0.004365864665790771\n",
      "-------epoch  320 -------\n",
      "train set Loss: 0.00604912190057803\n",
      "val set Loss: 0.0030566717662926144\n",
      "-------epoch  321 -------\n",
      "train set Loss: 0.006050303140946198\n",
      "val set Loss: 0.004546049371128902\n",
      "-------epoch  322 -------\n",
      "train set Loss: 0.005738908686907962\n",
      "val set Loss: 0.003048597364492404\n",
      "-------epoch  323 -------\n",
      "train set Loss: 0.005835139619011898\n",
      "val set Loss: 0.004714318977979322\n",
      "-------epoch  324 -------\n",
      "train set Loss: 0.00579913109948393\n",
      "val set Loss: 0.0030252607684815302\n",
      "-------epoch  325 -------\n",
      "train set Loss: 0.006392336669960059\n",
      "val set Loss: 0.005424796089452381\n",
      "-------epoch  326 -------\n",
      "train set Loss: 0.006044577952125109\n",
      "val set Loss: 0.0029585937154479325\n",
      "-------epoch  327 -------\n",
      "train set Loss: 0.006676317556994036\n",
      "val set Loss: 0.006111432303441688\n",
      "-------epoch  328 -------\n",
      "train set Loss: 0.006607287923106924\n",
      "val set Loss: 0.002935554861323908\n",
      "-------epoch  329 -------\n",
      "train set Loss: 0.006952406259078998\n",
      "val set Loss: 0.005543887654008965\n",
      "-------epoch  330 -------\n",
      "train set Loss: 0.006349726025364362\n",
      "val set Loss: 0.0030365988835304356\n",
      "-------epoch  331 -------\n",
      "train set Loss: 0.006609224294661545\n",
      "val set Loss: 0.005710697034373879\n",
      "-------epoch  332 -------\n",
      "train set Loss: 0.006032511331140995\n",
      "val set Loss: 0.0030454588413704187\n",
      "-------epoch  333 -------\n",
      "train set Loss: 0.005814471209596377\n",
      "val set Loss: 0.004640715740000208\n",
      "-------epoch  334 -------\n",
      "train set Loss: 0.00553576884442009\n",
      "val set Loss: 0.0031082900046991804\n",
      "-------epoch  335 -------\n",
      "train set Loss: 0.005648399919446092\n",
      "val set Loss: 0.004650239803595468\n",
      "-------epoch  336 -------\n",
      "train set Loss: 0.005654695467092097\n",
      "val set Loss: 0.002941342148308953\n",
      "-------epoch  337 -------\n",
      "train set Loss: 0.006229595692420844\n",
      "val set Loss: 0.005360461878202234\n",
      "-------epoch  338 -------\n",
      "train set Loss: 0.005799559747101739\n",
      "val set Loss: 0.0029045094076233604\n",
      "-------epoch  339 -------\n",
      "train set Loss: 0.006209998533304315\n",
      "val set Loss: 0.006179949617944658\n",
      "-------epoch  340 -------\n",
      "train set Loss: 0.00606026012566872\n",
      "val set Loss: 0.0029728617422127477\n",
      "-------epoch  341 -------\n",
      "train set Loss: 0.006531008533784188\n",
      "val set Loss: 0.006788286826728533\n",
      "-------epoch  342 -------\n",
      "train set Loss: 0.006033259484684095\n",
      "val set Loss: 0.0030180691683199257\n",
      "-------epoch  343 -------\n",
      "train set Loss: 0.006144754603446927\n",
      "val set Loss: 0.007298290496692061\n",
      "-------epoch  344 -------\n",
      "train set Loss: 0.0057167315011611205\n",
      "val set Loss: 0.0029242581222206354\n",
      "-------epoch  345 -------\n",
      "train set Loss: 0.0062830886439769525\n",
      "val set Loss: 0.0058173988945782185\n",
      "-------epoch  346 -------\n",
      "train set Loss: 0.005849040475441143\n",
      "val set Loss: 0.0031113315102023384\n",
      "-------epoch  347 -------\n",
      "train set Loss: 0.005931953432154842\n",
      "val set Loss: 0.00940180653318142\n",
      "-------epoch  348 -------\n",
      "train set Loss: 0.006045915126160253\n",
      "val set Loss: 0.0028625850827666\n",
      "-------epoch  349 -------\n",
      "train set Loss: 0.006658535374153871\n",
      "val set Loss: 0.0044091959910777705\n",
      "-------epoch  350 -------\n",
      "train set Loss: 0.0057894731842679905\n",
      "val set Loss: 0.003054870860069059\n",
      "-------epoch  351 -------\n",
      "train set Loss: 0.005735234939493239\n",
      "val set Loss: 0.0048869647628938155\n",
      "-------epoch  352 -------\n",
      "train set Loss: 0.005665663457184564\n",
      "val set Loss: 0.003222142743955677\n",
      "-------epoch  353 -------\n",
      "train set Loss: 0.006052543061086908\n",
      "val set Loss: 0.005953052343102172\n",
      "-------epoch  354 -------\n",
      "train set Loss: 0.005414994087768719\n",
      "val set Loss: 0.002948078234718802\n",
      "-------epoch  355 -------\n",
      "train set Loss: 0.005582279879017733\n",
      "val set Loss: 0.006168181687826291\n",
      "-------epoch  356 -------\n",
      "train set Loss: 0.0053187550161965195\n",
      "val set Loss: 0.0028458524805804095\n",
      "-------epoch  357 -------\n",
      "train set Loss: 0.005846332271466963\n",
      "val set Loss: 0.006344088003970683\n",
      "-------epoch  358 -------\n",
      "train set Loss: 0.005574658241821453\n",
      "val set Loss: 0.0028786066298683486\n",
      "-------epoch  359 -------\n",
      "train set Loss: 0.006200379295914899\n",
      "val set Loss: 0.006670118387167652\n",
      "-------epoch  360 -------\n",
      "train set Loss: 0.005582013619714416\n",
      "val set Loss: 0.0030239863165964684\n",
      "-------epoch  361 -------\n",
      "train set Loss: 0.006179782111430541\n",
      "val set Loss: 0.006020856012279789\n",
      "-------epoch  362 -------\n",
      "train set Loss: 0.005420203730463982\n",
      "val set Loss: 0.003123103427545478\n",
      "-------epoch  363 -------\n",
      "train set Loss: 0.005379231371043716\n",
      "val set Loss: 0.006987731535142909\n",
      "-------epoch  364 -------\n",
      "train set Loss: 0.004988375323009677\n",
      "val set Loss: 0.002901668383856304\n",
      "-------epoch  365 -------\n",
      "train set Loss: 0.005541239976300858\n",
      "val set Loss: 0.003942952510745575\n",
      "-------epoch  366 -------\n",
      "train set Loss: 0.0058029773307498545\n",
      "val set Loss: 0.0028914355740804845\n",
      "-------epoch  367 -------\n",
      "train set Loss: 0.007042114713549381\n",
      "val set Loss: 0.004645597791144003\n",
      "-------epoch  368 -------\n",
      "train set Loss: 0.00625102439080365\n",
      "val set Loss: 0.003681211111446222\n",
      "-------epoch  369 -------\n",
      "train set Loss: 0.005889692305354402\n",
      "val set Loss: 0.0057949853168490035\n",
      "-------epoch  370 -------\n",
      "train set Loss: 0.005795795177109539\n",
      "val set Loss: 0.0040423402582140016\n",
      "-------epoch  371 -------\n",
      "train set Loss: 0.005166146043484332\n",
      "val set Loss: 0.003993200613573815\n",
      "-------epoch  372 -------\n",
      "train set Loss: 0.0051678606090717946\n",
      "val set Loss: 0.004397131007863209\n",
      "-------epoch  373 -------\n",
      "train set Loss: 0.005740247795620235\n",
      "val set Loss: 0.005485875308901693\n",
      "-------epoch  374 -------\n",
      "train set Loss: 0.005791747085168026\n",
      "val set Loss: 0.003198222528832654\n",
      "-------epoch  375 -------\n",
      "train set Loss: 0.006419545108219609\n",
      "val set Loss: 0.004412575586078067\n",
      "-------epoch  376 -------\n",
      "train set Loss: 0.005845187221420928\n",
      "val set Loss: 0.0034332231540853777\n",
      "-------epoch  377 -------\n",
      "train set Loss: 0.005545778406085447\n",
      "val set Loss: 0.0040599923037613435\n",
      "-------epoch  378 -------\n",
      "train set Loss: 0.0055833834107033905\n",
      "val set Loss: 0.004483929874065022\n",
      "-------epoch  379 -------\n",
      "train set Loss: 0.006110139026422985\n",
      "val set Loss: 0.0051222645755236345\n",
      "-------epoch  380 -------\n",
      "train set Loss: 0.007633936854545027\n",
      "val set Loss: 0.006110716300706069\n",
      "-------epoch  381 -------\n",
      "train set Loss: 0.012994131514860783\n",
      "val set Loss: 0.011570585115502277\n",
      "-------epoch  382 -------\n",
      "train set Loss: 0.009535694211081136\n",
      "val set Loss: 0.007532222739731272\n",
      "-------epoch  383 -------\n",
      "train set Loss: 0.00826669938629493\n",
      "val set Loss: 0.006696932405854265\n",
      "-------epoch  384 -------\n",
      "train set Loss: 0.006224118914979045\n",
      "val set Loss: 0.003977084920431177\n",
      "-------epoch  385 -------\n",
      "train set Loss: 0.00656085473485291\n",
      "val set Loss: 0.004504219434844951\n",
      "-------epoch  386 -------\n",
      "train set Loss: 0.007251583773177117\n",
      "val set Loss: 0.005488256846244137\n",
      "-------epoch  387 -------\n",
      "train set Loss: 0.008317804404068738\n",
      "val set Loss: 0.005794084165245295\n",
      "-------epoch  388 -------\n",
      "train set Loss: 0.008705877795582637\n",
      "val set Loss: 0.006050235281387965\n",
      "-------epoch  389 -------\n",
      "train set Loss: 0.008491162415011785\n",
      "val set Loss: 0.007240081361184518\n",
      "-------epoch  390 -------\n",
      "train set Loss: 0.00847110389964655\n",
      "val set Loss: 0.005764350605507691\n",
      "-------epoch  391 -------\n",
      "train set Loss: 0.0067221165122464295\n",
      "val set Loss: 0.005351081412906448\n",
      "-------epoch  392 -------\n",
      "train set Loss: 0.006248496574698947\n",
      "val set Loss: 0.003890017387069141\n",
      "-------epoch  393 -------\n",
      "train set Loss: 0.005177634164865595\n",
      "val set Loss: 0.003354639804456383\n",
      "-------epoch  394 -------\n",
      "train set Loss: 0.0052315250667743386\n",
      "val set Loss: 0.0041346619836986065\n",
      "-------epoch  395 -------\n",
      "train set Loss: 0.006073245116276667\n",
      "val set Loss: 0.00562083744443953\n",
      "-------epoch  396 -------\n",
      "train set Loss: 0.005099090955627617\n",
      "val set Loss: 0.003083895174010346\n",
      "-------epoch  397 -------\n",
      "train set Loss: 0.00577534610274597\n",
      "val set Loss: 0.004281967393277834\n",
      "-------epoch  398 -------\n",
      "train set Loss: 0.00625709502841346\n",
      "val set Loss: 0.0030143583523264774\n",
      "-------epoch  399 -------\n",
      "train set Loss: 0.007201983952254523\n",
      "val set Loss: 0.00480211708539476\n",
      "-------epoch  400 -------\n",
      "train set Loss: 0.0059449039690662175\n",
      "val set Loss: 0.0029345645646875105\n",
      "-------epoch  401 -------\n",
      "train set Loss: 0.005610647671564948\n",
      "val set Loss: 0.0038759205878401795\n",
      "-------epoch  402 -------\n",
      "train set Loss: 0.004845727121282835\n",
      "val set Loss: 0.0029577347449958324\n",
      "save model:epoch 402\n",
      "-------epoch  403 -------\n",
      "train set Loss: 0.004739583114424022\n",
      "val set Loss: 0.0030313994793687016\n",
      "save model:epoch 403\n",
      "-------epoch  404 -------\n",
      "train set Loss: 0.004633113329473418\n",
      "val set Loss: 0.0027770596061600372\n",
      "save model:epoch 404\n",
      "-------epoch  405 -------\n",
      "train set Loss: 0.004642367701599141\n",
      "val set Loss: 0.003911251599978034\n",
      "save model:epoch 405\n",
      "-------epoch  406 -------\n",
      "train set Loss: 0.004574114971910603\n",
      "val set Loss: 0.002815842832205817\n",
      "save model:epoch 406\n",
      "-------epoch  407 -------\n",
      "train set Loss: 0.004836193897062913\n",
      "val set Loss: 0.003969350771512836\n",
      "save model:epoch 407\n",
      "-------epoch  408 -------\n",
      "train set Loss: 0.004896195183682721\n",
      "val set Loss: 0.0029334439507996044\n",
      "save model:epoch 408\n",
      "-------epoch  409 -------\n",
      "train set Loss: 0.005904866861819755\n",
      "val set Loss: 0.004590655715825657\n",
      "-------epoch  410 -------\n",
      "train set Loss: 0.005125817070365884\n",
      "val set Loss: 0.0033889846527017653\n",
      "-------epoch  411 -------\n",
      "train set Loss: 0.005314480152737815\n",
      "val set Loss: 0.005629679731403788\n",
      "-------epoch  412 -------\n",
      "train set Loss: 0.005009247892012354\n",
      "val set Loss: 0.0028859702579211444\n",
      "-------epoch  413 -------\n",
      "train set Loss: 0.005208947838982567\n",
      "val set Loss: 0.00590377389259326\n",
      "-------epoch  414 -------\n",
      "train set Loss: 0.005403318639728241\n",
      "val set Loss: 0.003479491996889313\n",
      "-------epoch  415 -------\n",
      "train set Loss: 0.004926403949502856\n",
      "val set Loss: 0.0026947953253208348\n",
      "-------epoch  416 -------\n",
      "train set Loss: 0.004807253623439465\n",
      "val set Loss: 0.0027946588864627606\n",
      "save model:epoch 416\n",
      "-------epoch  417 -------\n",
      "train set Loss: 0.004686742769408738\n",
      "val set Loss: 0.004004550341051072\n",
      "save model:epoch 417\n",
      "-------epoch  418 -------\n",
      "train set Loss: 0.0047244452143786475\n",
      "val set Loss: 0.002907867223257199\n",
      "save model:epoch 418\n",
      "-------epoch  419 -------\n",
      "train set Loss: 0.004120453021314461\n",
      "val set Loss: 0.0027450223569758236\n",
      "save model:epoch 419\n",
      "-------epoch  420 -------\n",
      "train set Loss: 0.0038981652983056847\n",
      "val set Loss: 0.003022206665870423\n",
      "save model:epoch 420\n",
      "-------epoch  421 -------\n",
      "train set Loss: 0.003940434904470749\n",
      "val set Loss: 0.003024766056720788\n",
      "save model:epoch 421\n",
      "-------epoch  422 -------\n",
      "train set Loss: 0.004810234162723645\n",
      "val set Loss: 0.0042526715551503\n",
      "save model:epoch 422\n",
      "-------epoch  423 -------\n",
      "train set Loss: 0.005899965596036054\n",
      "val set Loss: 0.005630137709279855\n",
      "-------epoch  424 -------\n",
      "train set Loss: 0.007416320885240566\n",
      "val set Loss: 0.006891400708506505\n",
      "-------epoch  425 -------\n",
      "train set Loss: 0.006002499098540284\n",
      "val set Loss: 0.004340773409542938\n",
      "-------epoch  426 -------\n",
      "train set Loss: 0.006525043861183803\n",
      "val set Loss: 0.005855923440928261\n",
      "-------epoch  427 -------\n",
      "train set Loss: 0.005251600591000169\n",
      "val set Loss: 0.002947520697489381\n",
      "-------epoch  428 -------\n",
      "train set Loss: 0.005185287544736639\n",
      "val set Loss: 0.0028979073298008493\n",
      "-------epoch  429 -------\n",
      "train set Loss: 0.005016033980646171\n",
      "val set Loss: 0.0033630688946383693\n",
      "-------epoch  430 -------\n",
      "train set Loss: 0.005082475809322204\n",
      "val set Loss: 0.0031843384300979474\n",
      "-------epoch  431 -------\n",
      "train set Loss: 0.005052497307769954\n",
      "val set Loss: 0.0033223695548561714\n",
      "-------epoch  432 -------\n",
      "train set Loss: 0.005212055730517022\n",
      "val set Loss: 0.004076968296431005\n",
      "-------epoch  433 -------\n",
      "train set Loss: 0.0050940159236779435\n",
      "val set Loss: 0.002956282172817737\n",
      "-------epoch  434 -------\n",
      "train set Loss: 0.005485658708203119\n",
      "val set Loss: 0.004473664254571001\n",
      "-------epoch  435 -------\n",
      "train set Loss: 0.005218517546309158\n",
      "val set Loss: 0.0026672842553428686\n",
      "-------epoch  436 -------\n",
      "train set Loss: 0.004346483438566793\n",
      "val set Loss: 0.004017702478449792\n",
      "save model:epoch 436\n",
      "-------epoch  437 -------\n",
      "train set Loss: 0.004390742411123938\n",
      "val set Loss: 0.0029193141284243516\n",
      "save model:epoch 437\n",
      "-------epoch  438 -------\n",
      "train set Loss: 0.004439502073510084\n",
      "val set Loss: 0.0027746130363084376\n",
      "save model:epoch 438\n",
      "-------epoch  439 -------\n",
      "train set Loss: 0.00551456543202221\n",
      "val set Loss: 0.004585718677844852\n",
      "-------epoch  440 -------\n",
      "train set Loss: 0.006602062049205415\n",
      "val set Loss: 0.0042121674050576985\n",
      "-------epoch  441 -------\n",
      "train set Loss: 0.005105666193121579\n",
      "val set Loss: 0.003890156978741288\n",
      "-------epoch  442 -------\n",
      "train set Loss: 0.0054266809142427515\n",
      "val set Loss: 0.004055540969905754\n",
      "-------epoch  443 -------\n",
      "train set Loss: 0.005278914945374708\n",
      "val set Loss: 0.0029915959166828543\n",
      "-------epoch  444 -------\n",
      "train set Loss: 0.005462766218115576\n",
      "val set Loss: 0.0030020523796944567\n",
      "-------epoch  445 -------\n",
      "train set Loss: 0.004817859792237869\n",
      "val set Loss: 0.002740190325615307\n",
      "save model:epoch 445\n",
      "-------epoch  446 -------\n",
      "train set Loss: 0.004175977061968297\n",
      "val set Loss: 0.0027140891276455172\n",
      "save model:epoch 446\n",
      "-------epoch  447 -------\n",
      "train set Loss: 0.00418082888412755\n",
      "val set Loss: 0.003440021061881756\n",
      "save model:epoch 447\n",
      "-------epoch  448 -------\n",
      "train set Loss: 0.004562222734384704\n",
      "val set Loss: 0.0032790646655485034\n",
      "save model:epoch 448\n",
      "-------epoch  449 -------\n",
      "train set Loss: 0.005868956262565917\n",
      "val set Loss: 0.004008071147836745\n",
      "-------epoch  450 -------\n",
      "train set Loss: 0.008081895323703065\n",
      "val set Loss: 0.0029702989268116653\n",
      "-------epoch  451 -------\n",
      "train set Loss: 0.005595593826146796\n",
      "val set Loss: 0.004570906011698146\n",
      "-------epoch  452 -------\n",
      "train set Loss: 0.004789932569256052\n",
      "val set Loss: 0.002828970735815043\n",
      "save model:epoch 452\n",
      "-------epoch  453 -------\n",
      "train set Loss: 0.005203421788028208\n",
      "val set Loss: 0.0029277969151735306\n",
      "-------epoch  454 -------\n",
      "train set Loss: 0.004864923822751734\n",
      "val set Loss: 0.002846130160226797\n",
      "save model:epoch 454\n",
      "-------epoch  455 -------\n",
      "train set Loss: 0.004673340207373258\n",
      "val set Loss: 0.002538292081832575\n",
      "save model:epoch 455\n",
      "-------epoch  456 -------\n",
      "train set Loss: 0.00440279179776553\n",
      "val set Loss: 0.00399372773244977\n",
      "save model:epoch 456\n",
      "-------epoch  457 -------\n",
      "train set Loss: 0.0045834149813163095\n",
      "val set Loss: 0.0035753785632550716\n",
      "save model:epoch 457\n",
      "-------epoch  458 -------\n",
      "train set Loss: 0.00474124129221309\n",
      "val set Loss: 0.004493892813722293\n",
      "save model:epoch 458\n",
      "-------epoch  459 -------\n",
      "train set Loss: 0.004673314851243049\n",
      "val set Loss: 0.003854404164788624\n",
      "save model:epoch 459\n",
      "-------epoch  460 -------\n",
      "train set Loss: 0.004908114865829702\n",
      "val set Loss: 0.0029961204466720424\n",
      "-------epoch  461 -------\n",
      "train set Loss: 0.004890857688733377\n",
      "val set Loss: 0.003949454306469609\n",
      "save model:epoch 461\n",
      "-------epoch  462 -------\n",
      "train set Loss: 0.005379761569492984\n",
      "val set Loss: 0.005249157741976281\n",
      "-------epoch  463 -------\n",
      "train set Loss: 0.005671184646198526\n",
      "val set Loss: 0.005999535166968902\n",
      "-------epoch  464 -------\n",
      "train set Loss: 0.004680389805289451\n",
      "val set Loss: 0.0035365457297302783\n",
      "save model:epoch 464\n",
      "-------epoch  465 -------\n",
      "train set Loss: 0.004750033411255572\n",
      "val set Loss: 0.004470568295801058\n",
      "save model:epoch 465\n",
      "-------epoch  466 -------\n",
      "train set Loss: 0.005560604213969782\n",
      "val set Loss: 0.0034536763463014117\n",
      "-------epoch  467 -------\n",
      "train set Loss: 0.0060025698132812975\n",
      "val set Loss: 0.004687872792904575\n",
      "-------epoch  468 -------\n",
      "train set Loss: 0.005861852320667822\n",
      "val set Loss: 0.004328649723902345\n",
      "-------epoch  469 -------\n",
      "train set Loss: 0.005807050328003243\n",
      "val set Loss: 0.0033517271610132107\n",
      "-------epoch  470 -------\n",
      "train set Loss: 0.004682681382691953\n",
      "val set Loss: 0.0030050634134871266\n",
      "save model:epoch 470\n",
      "-------epoch  471 -------\n",
      "train set Loss: 0.004489689560432453\n",
      "val set Loss: 0.002576082765396374\n",
      "save model:epoch 471\n",
      "-------epoch  472 -------\n",
      "train set Loss: 0.004208844605309423\n",
      "val set Loss: 0.0028428990578201288\n",
      "save model:epoch 472\n",
      "-------epoch  473 -------\n",
      "train set Loss: 0.004542665856133681\n",
      "val set Loss: 0.004120662381562094\n",
      "save model:epoch 473\n",
      "-------epoch  474 -------\n",
      "train set Loss: 0.0048779891792219135\n",
      "val set Loss: 0.0038846902219423405\n",
      "save model:epoch 474\n",
      "-------epoch  475 -------\n",
      "train set Loss: 0.005353105434041936\n",
      "val set Loss: 0.004839911280820767\n",
      "-------epoch  476 -------\n",
      "train set Loss: 0.006531611902755685\n",
      "val set Loss: 0.006335359939839691\n",
      "-------epoch  477 -------\n",
      "train set Loss: 0.003971391752420459\n",
      "val set Loss: 0.002732829084076608\n",
      "save model:epoch 477\n",
      "-------epoch  478 -------\n",
      "train set Loss: 0.003896496315865079\n",
      "val set Loss: 0.002766353243108218\n",
      "save model:epoch 478\n",
      "-------epoch  479 -------\n",
      "train set Loss: 0.00434980257647112\n",
      "val set Loss: 0.004191819277669613\n",
      "save model:epoch 479\n",
      "-------epoch  480 -------\n",
      "train set Loss: 0.0038626994664082304\n",
      "val set Loss: 0.0032278002957658223\n",
      "save model:epoch 480\n",
      "-------epoch  481 -------\n",
      "train set Loss: 0.004555350217415253\n",
      "val set Loss: 0.004898840406288703\n",
      "save model:epoch 481\n",
      "-------epoch  482 -------\n",
      "train set Loss: 0.004141939309629378\n",
      "val set Loss: 0.00473697865769888\n",
      "save model:epoch 482\n",
      "-------epoch  483 -------\n",
      "train set Loss: 0.007023909746203571\n",
      "val set Loss: 0.00285631032117332\n",
      "-------epoch  484 -------\n",
      "train set Loss: 0.007781342811358627\n",
      "val set Loss: 0.0047480424400419\n",
      "-------epoch  485 -------\n",
      "train set Loss: 0.014300900188391096\n",
      "val set Loss: 0.005541603245850031\n",
      "-------epoch  486 -------\n",
      "train set Loss: 0.012111528221284971\n",
      "val set Loss: 0.002917816396802664\n",
      "-------epoch  487 -------\n",
      "train set Loss: 0.008583061376120894\n",
      "val set Loss: 0.012445576314348727\n",
      "-------epoch  488 -------\n",
      "train set Loss: 0.007909585540182888\n",
      "val set Loss: 0.005302453323868879\n",
      "-------epoch  489 -------\n",
      "train set Loss: 0.005809615976177156\n",
      "val set Loss: 0.005250926439960797\n",
      "-------epoch  490 -------\n",
      "train set Loss: 0.005364089655340649\n",
      "val set Loss: 0.006133236883518596\n",
      "-------epoch  491 -------\n",
      "train set Loss: 0.006667987704277039\n",
      "val set Loss: 0.008023161363477508\n",
      "-------epoch  492 -------\n",
      "train set Loss: 0.0073587177257286385\n",
      "val set Loss: 0.0048087394485871\n",
      "-------epoch  493 -------\n",
      "train set Loss: 0.00590373550541699\n",
      "val set Loss: 0.003801708109676838\n",
      "-------epoch  494 -------\n",
      "train set Loss: 0.004941216296865605\n",
      "val set Loss: 0.003251984419572788\n",
      "-------epoch  495 -------\n",
      "train set Loss: 0.004237721252720803\n",
      "val set Loss: 0.0030324862066966793\n",
      "save model:epoch 495\n",
      "-------epoch  496 -------\n",
      "train set Loss: 0.0056198236985073894\n",
      "val set Loss: 0.00705745373852551\n",
      "-------epoch  497 -------\n",
      "train set Loss: 0.005739294762606733\n",
      "val set Loss: 0.007799153643039365\n",
      "-------epoch  498 -------\n",
      "train set Loss: 0.0063019265106413515\n",
      "val set Loss: 0.002856689917583329\n",
      "-------epoch  499 -------\n",
      "train set Loss: 0.005944616765482351\n",
      "val set Loss: 0.0029007329139858484\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "# checking if GPU is available\n",
    "device = torch.device(\"cpu\")\n",
    "if (torch.cuda.is_available()):\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print('Training on GPU.')\n",
    "else:\n",
    "    print('No GPU available, training on CPU.')\n",
    "\n",
    "# 构建模型\n",
    "model = LSTMModel(input_size=input_size,\n",
    "                  hidden_size=hidden_size,\n",
    "                  output_size=output_size,\n",
    "                  num_layers = num_layers)\n",
    "model = model.to(device) # lstm doesnt work on gpu?\n",
    "# train\n",
    "train_dataset = LoadDataset(train_directory, seq_len=seq_len, features=features)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "# validation\n",
    "val_dataset = LoadDataset(val_directory, seq_len=seq_len, features=features)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 储存路径\n",
    "work_dir = './LSTM'\n",
    "# 添加tensorboard\n",
    "# writer = SummaryWriter(\"{}/logs\".format(work_dir))\n",
    "\n",
    "# model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "# checkponits = epoch // 5\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(epoch):\n",
    "    print(\"-------epoch  {} -------\".format(epoch))\n",
    "    # 训练步骤\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for train_data, train_data_real in train_dataloader:\n",
    "        train_data = torch.squeeze(train_data).to(device)\n",
    "        train_data_real = torch.squeeze(train_data_real).to(device)\n",
    "\n",
    "        output, _ = model(train_data)\n",
    "        output = torch.squeeze(output)\n",
    "        optimizer.zero_grad()\n",
    "        train_loss = criterion(output, train_data_real)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += train_loss.item()\n",
    "    avg_train_loss = total_train_loss/len(train_dataloader)\n",
    "    print(\"train set Loss: {}\".format(avg_train_loss)) # 出现nan可能是seq_len太长了,有些数据集比seq_len短\n",
    "\n",
    "    # 测试步骤\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():#用于在推断或验证阶段，当不需要计算梯度时，以提高效率和减少内存占用\n",
    "        for val_data, val_data_real in val_dataloader:\n",
    "            val_data = torch.squeeze(val_data).to(device)\n",
    "            val_data_real = torch.squeeze(val_data_real).to(device)\n",
    "\n",
    "            val_output, _ = model(val_data)\n",
    "            val_output = torch.squeeze(val_output)\n",
    "            val_loss = criterion(val_output, val_data_real)\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss/len(val_dataloader)\n",
    "    print(\"val set Loss: {}\".format(avg_val_loss))\n",
    "\n",
    "    # save checkpoint\n",
    "    # if epochs % checkponits == 0:\n",
    "    \n",
    "    if avg_train_loss < 0.0025  and avg_val_loss< 0.0025 :\n",
    "        torch.save(model.state_dict(), str('EX_')+save_path[:-4]+'.pth')\n",
    "        print(\"save model:epoch {}\".format(epoch))\n",
    "    elif 0.0025 < avg_train_loss < 0.0036 and 0.0025 < avg_val_loss< 0.0036 :\n",
    "        torch.save(model.state_dict(), str('A_')+save_path[:-4]+'.pth')\n",
    "        print(\"save model:epoch {}\".format(epoch))\n",
    "    elif 0.0036 < avg_train_loss < 0.0049  and 0.0036 < avg_val_loss< 0.0049 :        \n",
    "        torch.save(model.state_dict(), str('B_')+save_path[:-4]+'.pth')\n",
    "        print(\"save model:epoch {}\".format(epoch))\n",
    "    last_train_loss = avg_train_loss\n",
    "    last_val_loss = avg_val_loss\n",
    "# save last1\n",
    "torch.save(model.state_dict(), save_path[:-4]+'last.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
